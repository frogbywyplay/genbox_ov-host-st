Index: fred/gdb/linux-awareness-arm.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ fred/gdb/linux-awareness-arm.c	2009-02-20 10:16:22.000000000 +0000
@@ -0,0 +1,1137 @@
+
+
+#include "defs.h"
+#include "block.h"
+#include "command.h"
+#include "frame.h"
+#include "frame-unwind.h"
+#include "gdb_assert.h"
+#include "gdb_stdint.h"
+#include "gdbarch.h"
+#include "gdbcmd.h"
+#include "gdbcore.h"
+#include "gdbtypes.h"
+#include "gdb_obstack.h"
+#include "inferior.h"
+#include "regcache.h"
+#include "user-regs.h"
+#include "symtab.h"
+#include "target.h"
+#include "top.h"
+#include "value.h"
+
+#include "arm-tdep.h"
+
+#include "linux-awareness.h"
+
+static void
+arm_linux_awareness_load(char *prog, int fromtty);
+
+static unsigned int mmu_enabled;
+
+static int thread_info_regnum;
+static unsigned int has_started;
+static int skip_schedule_frame = 1;
+static unsigned int current_vm_pgd;
+static unsigned int start_vm_pgd;
+
+static struct regcache *cached_regcache;
+static ptid_t cached_regcache_ptid;
+
+/* Addresses used by the ARM specific linux awareness. */
+DECLARE_ADDR(contig_page_data);
+DECLARE_ADDR(do_exit);
+DECLARE_ADDR(init_thread_union);
+DECLARE_ADDR(init_mm);
+DECLARE_ADDR(irq_desc);
+DECLARE_ADDR(max_low_pfn);
+DECLARE_ADDR(mem_map);
+DECLARE_ADDR(min_low_pfn);
+DECLARE_ADDR(per_cpu__kstat);
+DECLARE_ADDR(pmb_init);
+DECLARE_ADDR(restore_all);
+DECLARE_ADDR(ret_from_exception);
+DECLARE_ADDR(ret_from_fork);
+DECLARE_ADDR(ret_from_irq);
+DECLARE_ADDR(swapper_pg_dir);
+DECLARE_ADDR(swapper_space);
+DECLARE_ADDR(ret_fast_syscall);
+DECLARE_ADDR(ret_slow_syscall);
+DECLARE_ADDR(sys_syscall);
+DECLARE_ADDR(work_resched);
+DECLARE_ADDR(cpu_arm926_switch_mm);
+DECLARE_ADDR(cpu_v6_switch_mm);
+
+DECLARE_ADDR(__dabt_svc);
+DECLARE_ADDR(__irq_svc);
+DECLARE_ADDR(__und_svc);
+DECLARE_ADDR(__pabt_svc);
+DECLARE_ADDR(__dabt_usr);
+DECLARE_ADDR(__irq_usr);
+DECLARE_ADDR(__und_usr);
+DECLARE_ADDR(__pabt_usr);
+DECLARE_ADDR(__und_usr_unknown);
+
+/* Fields used by the ARM specific linux awareness. */
+DECLARE_FIELD(hw_interrupt_type, typename);
+DECLARE_FIELD(irq_chip,          name);
+DECLARE_FIELD(irq_desc,          action);
+DECLARE_FIELD(irq_desc,          handler);
+DECLARE_FIELD(irq_desc,          chip);
+DECLARE_FIELD(irq_desc,          name);
+DECLARE_FIELD(irqaction,         name);
+DECLARE_FIELD(irqaction,         next);
+DECLARE_FIELD(kernel_stat,       irqs);
+DECLARE_FIELD(mm_struct,         pgd);
+DECLARE_FIELD(mm_struct,         context);
+DECLARE_FIELD(mm_context_t,      id);
+DECLARE_FIELD(page,              flags);
+DECLARE_FIELD(page,              mapping);
+DECLARE_FIELD(pglist_data,       node_start_pfn);
+DECLARE_FIELD(task_struct,       mm);
+DECLARE_FIELD(task_struct,       active_mm);
+DECLARE_FIELD(task_struct,       thread_info);
+DECLARE_FIELD(task_struct,       thread);
+DECLARE_FIELD(task_struct,       stack);
+DECLARE_FIELD(thread_info,       cpu_context);
+DECLARE_FIELD(thread_info,       task);
+
+/* Struct pt_regs information */
+static int pt_regs_size;
+
+#define CACHE_ALLOC(size) ({ \
+          void* mem = obstack_alloc(&linux_arm_obstack, (size)); \
+          memset(mem, 0, size); \
+          cache_used = 1; \
+          mem; })
+
+/*
+ * This struct defines the way the registers are stored on the
+ * stack during a system call.  Note that sizeof(struct pt_regs)
+ * has to be a multiple of 8.
+ */
+struct pt_regs {
+    uint32_t uregs[18];
+};
+
+static int nr_irqs = 0;
+static int irq_desc_size = 0;
+
+static void
+get_nr_irqs ()
+{
+    struct symbol *sym = lookup_symbol ("irq_desc", NULL,
+					VAR_DOMAIN, NULL, NULL);
+
+    if (!sym
+	|| TYPE_CODE (SYMBOL_TYPE (sym)) != TYPE_CODE_ARRAY)
+	error ("\
+Couldn't find the NR_IRQS kernel setting using the debug info. Use\n\
+'set linux-awareness nr_irqs <n>' and 'set linux-awareness irq_desc_size <n>'\n\
+to workaround.");
+
+    irq_desc_size = TYPE_LENGTH (TYPE_TARGET_TYPE (SYMBOL_TYPE (sym)));
+    nr_irqs = TYPE_LENGTH (SYMBOL_TYPE (sym))/irq_desc_size;
+}
+
+static void
+interrupts_command (char *args, int from_tty)
+{
+    gdb_byte *irq_descs;
+    int i;
+    char buf[65];
+
+    struct name {
+	CORE_ADDR    addr;
+	char         name[65];
+	struct name *next;
+    } *names1 = NULL, *names2 = NULL, *cur;
+
+    struct name *find_name_aux (CORE_ADDR addr, struct name* list) {
+	struct name *n = list;
+
+	while (n) {
+	    if (n->addr == addr)
+		return n;
+	    n = n->next;
+	}
+
+	return NULL;
+    }
+
+    struct name *register_name (CORE_ADDR base, struct field_info* field) {
+	struct name *name = xmalloc (sizeof (struct name));
+	struct name *n;
+	CORE_ADDR addr;
+
+	addr = read_memory_typed_address (base + linux_get_field_offset(field),
+					  builtin_type_void_data_ptr);
+	n = find_name_aux (addr, names2);
+	if (n)
+	    return n;
+
+	read_memory_string (addr, buf, 64);
+	strcpy (name->name, buf);
+	name->addr = base;
+	name->next = names1;
+	names1 = name;
+
+	name = xmalloc (sizeof (struct name));
+	strcpy (name->name, buf);
+	name->addr = addr;
+	name->next = names2;
+	names2 = name;
+
+	return name;
+    }
+
+    struct name *find_name (CORE_ADDR addr, struct field_info* field) {
+	struct name* cur = find_name_aux (addr, names1);
+
+	if (cur)
+	    return cur;
+
+	return register_name (addr, field);
+    }
+
+    void free_names () {
+	while (names1) {
+	    cur = names1->next;
+	    xfree (names1);
+	    names1 = cur;
+	}
+	while (names2) {
+	    cur = names2->next;
+	    xfree (names2);
+	    names2 = cur;
+	}
+    }
+
+    buf[64] = '\0';
+
+    if (!nr_irqs)
+	get_nr_irqs ();
+
+    printf_filtered ("IRQ     Triggered Handler => Action\n");
+    printf_filtered ("-----------------------------------\n");
+
+    irq_descs = xmalloc (nr_irqs*irq_desc_size);
+    read_memory (ADDR (irq_desc), irq_descs, nr_irqs*irq_desc_size);
+
+    for (i = 0; i < nr_irqs; ++i) {
+	CORE_ADDR action = extract_pointer_field (irq_descs + i*irq_desc_size,
+						  irq_desc, action);
+	CORE_ADDR name;
+	int count;
+
+	if (!action)
+	    continue;
+
+	count = read_memory_unsigned_integer (ADDR (per_cpu__kstat) + F_OFFSET (kernel_stat, irqs) + i*F_SIZE (kernel_stat, irqs)/nr_irqs,
+					      F_SIZE (kernel_stat, irqs)/nr_irqs);
+
+	printf_filtered ("%3d     %9u ", i, count);
+	if (detected_version >= V2_6_23) {
+	    CORE_ADDR chip = extract_pointer_field (irq_descs + i*irq_desc_size,
+						    irq_desc, chip);
+
+	    cur = find_name (chip, &FIELD_INFO(irq_chip, name));
+	    printf_filtered ("%14s", cur->name);
+	    cur = find_name (ADDR (irq_desc) + i*irq_desc_size,
+			     &FIELD_INFO(irq_desc, name));
+	    printf_filtered ("-%-8s ", cur->name);
+
+	} else {
+	    CORE_ADDR handler;
+	    handler = extract_pointer_field (irq_descs + i*irq_desc_size,
+					     irq_desc, handler);
+
+	    cur = find_name (handler, &FIELD_INFO(hw_interrupt_type, typename));
+	    printf_filtered ("%s ", cur->name);
+	}
+
+	cur = find_name (action, &FIELD_INFO(irqaction, name));
+	printf_filtered ("=> %s", cur->name);
+	do {
+	    action = read_pointer_field (action,  irqaction, next);
+	    if (!action) break;
+	    cur = find_name (action, &FIELD_INFO(irqaction, name));
+	    printf_filtered (", %s", cur->name);
+	} while (1);
+
+	printf_filtered ("\n");
+    }
+
+    xfree (irq_descs);
+    free_names ();
+}
+
+
+static void
+kthread_frame_this_id (struct frame_info *next_frame, void **this_cache,
+		       struct frame_id *this_id)
+{
+    /* Empty means backtrace stops here. */
+}
+
+static void
+kthread_frame_prev_register (struct frame_info *next_frame,
+			     void **this_cache,
+			     int regnum, int *optimizedp,
+			     enum lval_type *lvalp, CORE_ADDR *addrp,
+			     int *realnump, gdb_byte *valuep)
+{
+}
+
+static int probing = 0;
+
+static int
+kthread_frame_sniffer (const struct frame_unwind *self,
+			  struct frame_info *next_frame,
+			  void **this_cache)
+{
+    struct frame_info *f;
+    CORE_ADDR func;
+
+    /* This is *SO UGLY*... */
+    if (probing & 1)
+	return 0;
+    probing ^= 1;
+    f = get_prev_frame(next_frame);
+    func = frame_pc_unwind(f);
+    probing ^= 1;
+
+    if (HAS_ADDR(do_exit) && func == ADDR(do_exit)) {
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind kthread_frame_unwind = {
+  NORMAL_FRAME,
+  kthread_frame_this_id,
+  kthread_frame_prev_register,
+  NULL,
+  kthread_frame_sniffer
+};
+
+static struct pt_regs *
+ptregs_frame_cache(struct frame_info *next_frame, void **this_cache,
+		   int offset_from_sp)
+{
+    struct frame_info* this_frame = get_prev_frame(next_frame);
+    ULONGEST sp, stack_top;
+    CORE_ADDR regs_addr;
+    struct pt_regs* regs;
+    unsigned long* my_regs;
+    int i;
+
+    if (*this_cache)
+	return *this_cache;
+
+    sp = frame_unwind_register_unsigned(next_frame, 13);
+    regs_addr = sp + offset_from_sp;
+
+    this_frame = get_prev_frame(next_frame);
+    *this_cache = FRAME_OBSTACK_ZALLOC(struct pt_regs);
+    regs = *this_cache;
+    memset(regs, 0, sizeof(struct pt_regs));
+
+    i = 0;
+    my_regs = (unsigned long*)regs;
+    while (i<sizeof(struct pt_regs)/sizeof(unsigned long)) {
+	*my_regs = read_memory_unsigned_integer(regs_addr, 4);
+	regs_addr += 4; ++my_regs; ++i;
+    }
+
+    return regs;
+}
+
+static void
+ptregs_frame_prev_register (struct frame_info *next_frame,
+			    void **this_cache,
+			    int offset_from_sp,
+			    int regnum, int *optimizedp,
+			    enum lval_type *lvalp, CORE_ADDR *addrp,
+			    int *realnump, gdb_byte *valuep)
+{
+    struct pt_regs *cache = ptregs_frame_cache(next_frame, this_cache,
+					       offset_from_sp);
+
+    if (! cache)
+	error("Can't unwind exception frame.");
+
+    *optimizedp = 0;
+    *lvalp = not_lval;
+    *addrp = 0;
+    *realnump = -1;
+
+    switch (regnum) {
+    case 0:
+    case 1:
+    case 2:
+    case 3:
+    case 4:
+    case 5:
+    case 6:
+    case 7:
+    case 8:
+    case 9:
+    case 10:
+    case 11:
+    case 12:
+    case 13:
+    case 14:
+    case 15:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->uregs[regnum]);
+	break;
+    case 25:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->uregs[16]);
+	break;
+    default:
+	*optimizedp = 1;
+	*lvalp = not_lval;
+	*addrp = 0;
+	*realnump = -1;
+	if (valuep != NULL)
+	    get_frame_register(next_frame, regnum, valuep);
+    }
+}
+
+static void
+exception_frame_this_id (struct frame_info *next_frame, void **this_cache,
+			  struct frame_id *this_id)
+{
+    *this_id = frame_id_build (frame_sp_unwind(next_frame),
+			       frame_pc_unwind(next_frame));
+}
+
+static void
+exception_frame_prev_register (struct frame_info *next_frame,
+				void **this_cache,
+				int regnum, int *optimizedp,
+				enum lval_type *lvalp, CORE_ADDR *addrp,
+				int *realnump, gdb_byte *valuep)
+{
+    ptregs_frame_prev_register(next_frame, this_cache, 0,
+			       regnum, optimizedp, lvalp, addrp,
+			       realnump, valuep);
+}
+
+static int
+exception_frame_sniffer (const struct frame_unwind *self,
+			  struct frame_info *next_frame,
+			  void **this_cache)
+{
+    CORE_ADDR func = frame_func_unwind(next_frame, NORMAL_FRAME);
+    CORE_ADDR pc = frame_pc_unwind(next_frame);
+
+    if ((HAS_ADDR(__dabt_svc) && func == ADDR(__dabt_svc))
+	|| (HAS_ADDR(__irq_svc) && func == ADDR(__irq_svc))
+	|| (HAS_ADDR(__pabt_svc) && func == ADDR(__pabt_svc))
+	|| (HAS_ADDR(__und_svc) && func == ADDR(__und_svc))
+	|| (HAS_ADDR(__dabt_usr) && func == ADDR(__dabt_usr))
+	|| (HAS_ADDR(__irq_usr) && func == ADDR(__irq_usr))
+	|| (HAS_ADDR(__pabt_usr) && func == ADDR(__pabt_usr))
+	|| (HAS_ADDR(__und_usr) && func == ADDR(__und_usr))
+	|| (HAS_ADDR(ret_from_exception) && pc == ADDR(ret_from_exception))
+	|| (HAS_ADDR(__und_usr_unknown) && pc == ADDR(__und_usr_unknown))) {
+	linux_read_process_symbols();
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind exception_frame_unwind = {
+  SIGTRAMP_FRAME,
+  exception_frame_this_id,
+  exception_frame_prev_register,
+  NULL,
+  exception_frame_sniffer
+};
+
+static void
+syscall_frame_this_id (struct frame_info *next_frame, void **this_cache,
+		       struct frame_id *this_id)
+{
+    struct pt_regs *cache = ptregs_frame_cache(next_frame, this_cache, 8);
+
+    *this_id = frame_id_build (frame_sp_unwind(next_frame),
+			       frame_func_unwind(next_frame, NORMAL_FRAME));
+}
+
+static void
+syscall_frame_prev_register (struct frame_info *next_frame,
+			     void **this_cache,
+			     int regnum, int *optimizedp,
+			     enum lval_type *lvalp, CORE_ADDR *addrp,
+			     int *realnump, gdb_byte *valuep)
+{
+    ptregs_frame_prev_register(next_frame, this_cache, 8,
+			       regnum, optimizedp, lvalp, addrp,
+			       realnump, valuep);
+}
+
+static int
+syscall_frame_sniffer (const struct frame_unwind *self,
+		       struct frame_info *next_frame,
+		       void **this_cache)
+{
+    CORE_ADDR func;
+
+    if ((frame_relative_level (next_frame) != -1)
+	&& ((HAS_ADDR(work_resched)  && get_frame_pc (next_frame) == ADDR(work_resched))
+	    || (HAS_ADDR(ret_from_fork) && get_frame_pc (next_frame) == ADDR(ret_from_fork)+1)
+	    || (HAS_ADDR(ret_fast_syscall) && get_frame_pc (next_frame) == ADDR(ret_fast_syscall)+1)
+	    || (HAS_ADDR(ret_slow_syscall) && get_frame_pc (next_frame) == ADDR(ret_slow_syscall)+1))) {
+	/* Do that here because.... it should work. :-/  */
+	linux_read_process_symbols();
+    }
+
+    func = frame_pc_unwind(next_frame);
+
+    if ((HAS_ADDR(ret_fast_syscall) && func == ADDR(ret_fast_syscall))
+	|| (HAS_ADDR(ret_slow_syscall) && func == ADDR(ret_slow_syscall))
+	|| (HAS_ADDR(ret_from_fork) && func == ADDR(ret_from_fork))) {
+	deprecated_update_frame_pc_hack (get_prev_frame(next_frame), func+1);
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind syscall_frame_unwind = {
+  NORMAL_FRAME,
+  syscall_frame_this_id,
+  syscall_frame_prev_register,
+  NULL,
+  syscall_frame_sniffer
+};
+
+static int arm_linux_awareness_check()
+{
+    int res = 0;
+
+    switch (detected_version) {
+    case V2_6_24:
+	res =  HAS_FIELD(mm_struct,   pgd)
+	    && HAS_FIELD(task_struct, stack)
+	    && HAS_FIELD(task_struct, thread)
+	    && HAS_FIELD(task_struct, mm)
+	    && HAS_FIELD(thread_info, task)
+	    && HAS_FIELD(thread_info, cpu_context);
+	break;
+    }
+    if (res)
+	arm_linux_awareness_load(NULL, 0);
+    /* Don't include address check here, because most of the addresses
+       aren't fundamental for the awareness layer.  */
+    return res;
+}
+
+static CORE_ADDR current_task_struct;
+static CORE_ADDR current_thread_info;
+
+static CORE_ADDR
+current_thread_info_address()
+{
+    if (! current_thread_info) {
+	if (read_pc() != 0xc0008000 && has_started) {
+	    ULONGEST stack;
+
+	    regcache_cooked_read_unsigned(get_current_regcache(),
+					  thread_info_regnum, &stack);
+	    current_thread_info = stack & ~(8192 - 1); /* `(THREAD_SIZE-1) */
+	} else {
+	    current_thread_info = ADDR(init_thread_union);
+	}
+	DEBUG(VM, 3,"current_thread_info : %x\n", (unsigned int)current_thread_info);
+	if (current_thread_info < 0xc0000000)
+	    error("current_thread_info isn't a kernel address.");
+    }
+
+    return current_thread_info;
+}
+
+static CORE_ADDR
+current_task_struct_address()
+{
+    if (! current_task_struct) {
+	unsigned int mm;
+	CORE_ADDR task_field_addr = current_thread_info_address();
+	current_task_struct = read_unsigned_field(task_field_addr,
+						  thread_info, task);
+
+	if (current_task_struct < 0xc0000000)
+	    error("current_task_struct isn't a kernel address.");
+	DEBUG(VM, 3,"current_task_struct : %x\n",
+	      (unsigned int)current_task_struct);
+
+	mm = read_unsigned_field(current_task_struct, task_struct, mm);
+
+	if (!mm)
+	    mm = read_unsigned_field(current_task_struct,
+				     task_struct, active_mm);
+
+	if (!mm)
+	    start_vm_pgd = ADDR(swapper_pg_dir);
+	else
+	    start_vm_pgd = read_unsigned_field(mm, mm_struct, pgd);
+
+	current_vm_pgd = start_vm_pgd;
+	DEBUG(VM, 3,"start_vm_pgd : %x\n", (unsigned int)start_vm_pgd);
+    }
+
+    return current_task_struct;
+}
+
+static void
+pgtable_command (char *args, int from_tty)
+{
+    CORE_ADDR addr = parse_and_eval_address(args);
+    CORE_ADDR task_struct = current_task_struct_address ();
+    unsigned int mm = read_unsigned_field(task_struct, task_struct, mm);
+    unsigned int pgd;
+    unsigned int pgdval, pte, pteval;
+
+    if (!mm)
+	pgd = ADDR(swapper_pg_dir);
+    else
+	pgd = read_unsigned_field(mm, mm_struct, pgd);
+
+    pgdval = read_memory_unsigned_integer(pgd + ((addr >> 20) << 2), 4);
+    printf_filtered("PGD:\t%s\n", paddr(pgd));
+    printf_filtered("Addr:\t%s\n", paddr(addr));
+    printf_filtered("Tbl:\t%s\n", paddr(pgd | ((addr >> 20) << 2)));
+
+    printf_filtered("PGDVal = %08x\n", pgdval);
+    switch (pgdval & 0x3) {
+    case 0:
+	printf_filtered("FAULT\n"); return;
+	break;
+    case 1:
+	printf_filtered("COARSE\n");
+	printf_filtered("Domain:\t%x\n", (pgdval>>5) & 0xf);
+	printf_filtered("Tbl:\t%s\n", paddr(pgdval >> 10));
+	pte = 0xc0000000 | (pgdval&~0x3ff) | (((addr >> 12) & 0xff) << 2);
+	printf_filtered("Lvl2:\t%s\n", paddr(pte));
+	pteval = read_memory_unsigned_integer(pte, 4);
+	printf_filtered("Lvl2Val:\t%08x\n", pteval);
+	printf_filtered("B %i C %i AP0 %x AP1 %x AP2 %x AP3 %x\n",
+	       (pteval & (1<<2)) != 0,
+	       (pteval & (1<<3)) != 0,
+	       (pteval >> 4) & 3,
+	       (pteval >> 6) & 3,
+	       (pteval >> 8) & 3,
+	       (pteval >> 10) & 3);
+	break;
+    case 2:
+	printf_filtered("SECTION\n");
+	break;
+    case 3:
+	printf_filtered("FINE\n");
+	break;
+    default:
+	gdb_assert("Not reached" && 0);
+    }
+
+}
+
+static int arm_linux_awareness_init()
+{
+    cached_regcache_ptid = minus_one_ptid;
+
+    thread_info_regnum = user_reg_map_name_to_regnum(current_gdbarch,
+						     "r13_svc", -1);
+    frame_unwind_prepend_unwinder(current_gdbarch, &kthread_frame_unwind);
+    frame_unwind_prepend_unwinder(current_gdbarch, &exception_frame_unwind);
+    frame_unwind_prepend_unwinder(current_gdbarch, &syscall_frame_unwind);
+
+    add_com ("proc_interrupts", class_obscure, interrupts_command,
+	     "Print interrupt statistics.");
+
+    add_com ("pgtable", class_obscure, pgtable_command,
+	     "Print page table status for given address.");
+
+    add_setshow_boolean_cmd("skip_schedule_frame",
+			    class_obscure,
+			    &skip_schedule_frame,
+			    "Set whether the debugger should hide the schedule() frame for sleeping tasks",
+			    "Show whether the debugger should hide the schedule() frame for sleeping tasks",
+			    NULL, NULL, NULL,
+			    &set_linux_awareness_cmd_list,
+			    &show_linux_awareness_cmd_list);
+
+    if (target_has_registers)
+	arm_linux_awareness_load(NULL, 0);
+
+    return thread_info_regnum != -1;
+}
+
+static void switch_mm (unsigned int pgd, unsigned int mm)
+{
+    struct regcache *target_regcache;
+    struct target_waitstatus status;
+    static int switching;
+    static char cacheflush[] = "st imb";
+    static const char switch_mm_8815[] =
+	"st imb\n"
+	"st cp15 c2 0 c0  0 0x%x\n"
+	"st cp15 c8 0 c7  0 0";
+
+    static const char switch_mm_8820[] =
+	"st cp15 c7  0 c5  6 0\n"
+	"st cp15 c7  0 c10 4 0\n"
+	"st cp15 c2  0 c0  0 0x%x\n"
+	"st cp15 c13 0 c0  1 0x%x";
+
+    static char comm[1024];
+
+    if (switching)
+	return;
+
+    switching = 1;
+    DEBUG(VM, 2, "Switching TTB to pgd %08x\n", pgd);
+
+    if (HAS_ADDR(cpu_v6_switch_mm)) {
+	// 8820 board
+	sprintf(comm, switch_mm_8820, (unsigned int)(pgd - 0xc0000000),
+		(unsigned int)read_unsigned_embedded_field(mm,
+							   mm_struct, context,
+							   mm_context_t, id));
+    } else {
+	// 8815 board
+	sprintf(comm, switch_mm_8815, (unsigned int)(pgd - 0xc0000000));
+    }
+
+    {
+	char *comm_ptr = comm, *next_comm;
+
+	do {
+	    next_comm = strchr(comm_ptr, '\n');
+	    if (next_comm != NULL) *next_comm = '\0';
+	    execute_command(comm_ptr, 0);
+	    comm_ptr = next_comm+1;
+	} while (next_comm != NULL);
+    }
+
+    DEBUG(VM, 2, "Switching TTB to pgd %08x DONE\n", pgd);
+    switching = 0;
+}
+
+static int linux_arm_address_needs_translation(CORE_ADDR addr)
+{
+    return ((addr & 0xc0000000) != 0xc0000000 && has_started);
+}
+
+void thread_clear_cache()
+{
+    if (has_started && start_vm_pgd && start_vm_pgd != current_vm_pgd) {
+	unsigned int mm = read_unsigned_field(current_task_struct_address(),
+					      task_struct, mm);
+	switch_mm (start_vm_pgd, mm);
+    }
+
+    current_task_struct = 0;
+    current_thread_info = 0;
+
+    cached_regcache_ptid = minus_one_ptid;
+    if (cached_regcache != NULL) {
+	regcache_xfree (cached_regcache);
+	cached_regcache = NULL;
+    }
+
+    current_vm_pgd = 0;
+    start_vm_pgd = 0;
+}
+
+enum page_status translate_memory_address(CORE_ADDR *addr, CORE_ADDR task_struct)
+{
+    unsigned int mm = read_unsigned_field(task_struct, task_struct, mm);
+    unsigned int pgd, index;
+    unsigned int pgdval, pgdkval, pteval;
+
+    if (!mm)
+	pgd = ADDR(swapper_pg_dir);
+    else
+	pgd = read_unsigned_field(mm, mm_struct, pgd);
+
+    if (current_vm_pgd != pgd) {
+	switch_mm (pgd, mm);
+	current_vm_pgd = pgd;
+    }
+
+    pgdval = read_memory_unsigned_integer(pgd + ((*addr >> 20) << 2), 4);
+    DEBUG(VM, 2, "PGD is %08x DONE\n", pgdval);
+
+    if (*addr > 0xbf000000) {
+	if (!(pgdval & 0x1)) {
+	    gdb_byte buf[8];
+
+	    index = *addr >> 21 /* PGDIR_SHIFT */;
+	    read_memory(ADDR(swapper_pg_dir) + 8*index, buf, 8);
+	    if (!buf[(*addr >> 20) & 1 ? 4 : 0] & 0x3)
+		return PAGE_NOPAGE;
+
+	    write_memory(pgd + 8*index, buf, 8);
+	}
+	return PAGE_PRESENT;
+    }
+
+    if (! (pgdval & 0x1))
+	return PAGE_NOPAGE;
+
+    pteval = read_memory_unsigned_integer(0xc0000000 | (pgdval & ~0x3ff)
+					  | ((*addr & 0x0000FF000) >> 10), 4);
+    DEBUG(VM, 2, "PTE is %08x DONE\n", pteval);
+
+    return (pteval & 0x3) ? PAGE_PRESENT : PAGE_NOPAGE;
+}
+
+static CORE_ADDR translate_memory_watch_address(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    return 0;
+}
+
+static int arm_linux_can_write(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    return 0;
+}
+
+static int arm_linux_is_user_address(CORE_ADDR addr)
+{
+    return addr < 0xbf000000;
+}
+
+static int arm_linux_is_kernel_address(CORE_ADDR addr)
+{
+    return !arm_linux_is_user_address(addr);
+}
+
+/* This flushing routine is called only for virtual memory adresses.
+   If we pass access_addr == phys_addr, it means that we want to
+   suppress the alias we may have introduced through our direct access
+   to this physical address.
+
+   Precondition :
+   [access_addr..access_addr+len[ lies on the same physical page. */
+
+static void linux_arm_flush_cache_for_region(CORE_ADDR access_addr,
+					     CORE_ADDR phys_addr,
+					     int len,
+					     int write)
+{
+}
+
+static CORE_ADDR first_pointer_arg_value()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned (get_current_regcache(),0,&ret);
+    return ret;
+}
+
+static CORE_ADDR second_pointer_arg_value()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(),1,&ret);
+    return ret;
+}
+
+static CORE_ADDR third_pointer_arg_value()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(),2,&ret);
+    return ret;
+}
+
+static CORE_ADDR return_address_at_start_of_function()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(),14,&ret);
+    return ret;
+}
+
+static int new_regcache;
+
+static void  fetch_context_register_real(CORE_ADDR task_struct)
+{
+    gdb_byte *thread_info_buffer;
+    gdb_byte *cpu_state_buffer;
+    struct cleanup *clean;
+    struct regcache * regcache;
+    int offset = 0, val, i;
+
+    thread_info_buffer = xmalloc(4);
+    cpu_state_buffer = xmalloc(F_SIZE(thread_info, cpu_context));
+
+    DEBUG(TASK, 3,"fetch_context_register_real (%p,%p)\n",
+	  thread_info_buffer, cpu_state_buffer);
+
+    clean = make_cleanup(xfree, thread_info_buffer);
+    make_cleanup(xfree, cpu_state_buffer);
+
+    read_memory(task_struct+F_OFFSET(task_struct, stack),
+		thread_info_buffer, F_SIZE(task_struct, stack));
+
+    /* We supply all registers at once since what's costly is the
+       number of memory accesses, not the size of the accesses. */
+
+    read_memory(extract_unsigned_integer(thread_info_buffer, 4)
+		+ F_OFFSET(thread_info, cpu_context),
+		cpu_state_buffer, F_SIZE(thread_info, cpu_context));
+
+    new_regcache = 1;
+    regcache = get_current_regcache();
+    regcache_raw_supply(regcache, 4, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 5, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 6, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 7, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 8, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 9, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 10, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 11, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 13, cpu_state_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, 15, cpu_state_buffer+offset);
+    offset += 4;
+
+    for (i = 0; i < gdbarch_num_regs (current_gdbarch); i++)
+	if (! regcache_valid_p(regcache,i) )
+	    /* Mark other registers as unavailable.  */
+	    regcache_invalidate(regcache, i);
+
+    do_cleanups(clean);
+}
+
+static int doing_something_silly = 0;
+
+static int fetch_context_register(int regno, CORE_ADDR task_struct)
+{
+    struct frame_info *f;
+    ULONGEST pc;
+    int arm_num_regs = gdbarch_num_regs (current_gdbarch);
+
+    DEBUG(TASK, 3,"fetch_context_register(%i,%x)\n",
+	  regno, (unsigned int)task_struct);
+
+    gdb_assert( ! doing_something_silly );
+
+    if (cached_regcache && ptid_equal(inferior_ptid, cached_regcache_ptid)) {
+	struct regcache *saved_regcache = get_current_regcache();
+	regcache_cpy_no_passthrough (saved_regcache, cached_regcache);
+	return 1;
+    }
+
+    if (! regcache_valid_p(get_current_regcache(), 15))
+	fetch_context_register_real(task_struct);
+
+    regcache_cooked_read_unsigned(get_current_regcache(),15,&pc);
+
+    /* Don't skip the frames beginning in ret_from_fork. These frames
+       will be handled by the syscall unwinder. */
+    if (skip_schedule_frame && new_regcache
+	&& !(HAS_ADDR (ret_from_fork) && pc == ADDR (ret_from_fork))) {
+	new_regcache = 0;
+
+	doing_something_silly = 1;
+	f = get_current_frame();
+
+	if (f != NULL) {
+	    int i;
+	    gdb_byte buf[12];
+	    int optimized;
+	    CORE_ADDR addr;
+	    int realnum;
+	    enum lval_type lval;
+	    unsigned long *new_registers = xcalloc(arm_num_regs, sizeof(unsigned long));
+	    char *new_registers_valid = xcalloc(arm_num_regs, 1);
+
+	    for (i = 0; i<arm_num_regs; ++i) {
+		frame_register_unwind(f, i, &optimized, &lval, &addr,
+				      &realnum, buf);
+		if (!optimized) {
+		    memcpy(&new_registers[i], buf, 4);
+		    new_registers_valid[i] = 1;
+		}
+	    }
+
+/* 	    registers_changed(); */
+	    reinit_frame_cache();
+
+	    for (i = 0; i<arm_num_regs; ++i) {
+		if (new_registers_valid[i])
+		    regcache_raw_supply(get_current_regcache(), i,&new_registers[i]);
+		else
+		    /* Mark other registers as unavailable. */
+		    regcache_invalidate(get_current_regcache() ,i);
+	    }
+
+	    xfree(new_registers);
+	    xfree(new_registers_valid);
+	}
+
+	doing_something_silly = 0;
+    }
+
+    cached_regcache = regcache_dup_no_passthrough (get_current_regcache());
+    cached_regcache_ptid = inferior_ptid;
+
+    return 1;
+}
+
+
+
+static int store_context_register(int regno, CORE_ADDR task_struct)
+{
+    DEBUG(TASK, 3,"fetch_context_register(%i,%x)\n",
+	  regno, (unsigned int)task_struct);
+
+    return 0;
+}
+
+static CORE_ADDR arm_linux_single_step_destination(CORE_ADDR pc)
+{
+    return arm_get_next_pc (get_current_frame(), pc);
+}
+
+static void arm_linux_clear_cache()
+{
+    thread_clear_cache();
+    has_started = 1;
+}
+
+static void
+arm_linux_awareness_close()
+{
+    arm_linux_clear_cache();
+    has_started = 0;
+}
+
+static void
+arm_linux_awareness_load(char *prog, int fromtty)
+{
+    struct regcache *target_regcache;
+    struct target_waitstatus status;
+
+    static char comm1[] = "st cp15 c3 0 c0 0 0x1d\n";
+    static char comm2[] = "st cp15 c2 0 c0 0 0x4000\n";
+    static char comm3[] = "st cp15 c1 0 c0 0 0x00053177\n";
+    static char comm4[] = "st cp15 c0 0 c0 0\n";
+    static char comm5[] = "st cp15 c2 0 c0 0\n";
+
+    if (mmu_enabled)
+	return;
+
+    {
+	CORE_ADDR start, end;
+	ULONGEST val = 0x00000C1E;
+
+	start = 0x4000; end = start + 0x4000;
+	do {
+	    write_memory_unsigned_integer(start, 4, 0);
+	    start += 4;
+	} while (start != end);
+
+	write_memory_unsigned_integer(0x4000, 4, 0x00000C1E);
+	start = 0x7000; end = 0x7110;
+	do {
+	    write_memory_unsigned_integer(start, 4, val);
+	    val += 0x100000;
+	    start += 4;
+	} while (start != end);
+    }
+
+    execute_command(comm1, 0);
+    execute_command(comm2, 0);
+    execute_command(comm3, 0);
+    execute_command(comm4, 0);
+    printf_unfiltered("TTB is: ");
+    execute_command(comm5, 0);
+
+    mmu_enabled = 1;
+}
+
+static void
+arm_linux_awareness_post_load(char *prog, int fromtty)
+{
+    CORE_ADDR pc = read_pc();
+
+    if (pc > 0xc0000000)
+	/* PC points to a virtual address. */
+	write_pc(pc - 0xc0000000);
+}
+
+static void
+arm_linux_awareness_exec_start()
+{
+    if (!has_started) {
+	if (HAS_ADDR(cpu_v6_switch_mm)) {
+	    static char comm[] = "st cp15 c1 0 c0 0 0x00c0187c";
+	    execute_command(comm, 0);
+	}
+
+	mmu_enabled = 0;
+    }
+}
+
+static void
+arm_linux_awareness_exec_stop()
+{
+
+    struct regcache *regcache = get_current_regcache();
+    ULONGEST cpsr;
+    regcache_cooked_read_unsigned(regcache, 25, &cpsr);
+
+    if (has_started && (cpsr & 0x3) != 0x3) {
+	static char comm[128];
+	sprintf(comm, "st realreg cpsr=0x%08llx", cpsr | 0x3ULL);
+	execute_command(comm, 0);
+    }
+}
+
+struct linux_awareness_ops arm_linux_awareness_ops = {
+    .name = "ARM",
+    .lo_check = arm_linux_awareness_check,
+    .lo_init = arm_linux_awareness_init,
+    .lo_close = arm_linux_awareness_close,
+    .lo_pre_load = arm_linux_awareness_load,
+    .lo_post_load = arm_linux_awareness_post_load,
+    .lo_pre_exec_start = arm_linux_awareness_exec_start,
+    .lo_post_exec_stop = arm_linux_awareness_exec_stop,
+    .lo_address_needs_translation = linux_arm_address_needs_translation,
+    .lo_translate_memory_address = translate_memory_address,
+    .lo_translate_memory_watch_address = translate_memory_watch_address,
+    .lo_can_write = arm_linux_can_write,
+    .lo_is_user_address = arm_linux_is_user_address,
+    .lo_is_kernel_address = arm_linux_is_kernel_address,
+    .lo_flush_cache = linux_arm_flush_cache_for_region,
+    .lo_single_step_destination = NULL,
+    .lo_clear_cache = arm_linux_clear_cache,
+    .lo_first_pointer_arg_value = first_pointer_arg_value,
+    .lo_second_pointer_arg_value = second_pointer_arg_value,
+    .lo_third_pointer_arg_value = third_pointer_arg_value,
+    .lo_return_address_at_start_of_function = return_address_at_start_of_function,
+    .lo_current_task_struct_address = current_task_struct_address,
+    .lo_current_thread_info_address = current_thread_info_address,
+    .lo_fetch_context_register = fetch_context_register,
+    .lo_store_context_register = store_context_register,
+    .page_shift = 12 /* Page shift */
+};
+
+void
+_initialize_linux_awareness_arm (void)
+{
+    linux_awareness_ops = &arm_linux_awareness_ops;
+}
Index: fred/gdb/linux-awareness-sh4.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ fred/gdb/linux-awareness-sh4.c	2009-02-20 10:16:22.000000000 +0000
@@ -0,0 +1,1744 @@
+
+
+#include "defs.h"
+#include "block.h"
+#include "command.h"
+#include "frame.h"
+#include "frame-unwind.h"
+#include "gdb_assert.h"
+#include "gdbarch.h"
+#include "gdbcore.h"
+#include "gdbtypes.h"
+#include "gdb_obstack.h"
+#include "inferior.h"
+#include "regcache.h"
+#include "user-regs.h"
+#include "symtab.h"
+#include "target.h"
+#include "value.h"
+
+#include "sh-tdep.h"
+
+#include "linux-awareness.h"
+
+/* Translation cache */
+static unsigned int last_pid;
+static unsigned int last_page;
+static unsigned int last_translation;
+static unsigned int last_can_write;
+
+/* TLB cache */
+static unsigned int current_tlb_config_virt;
+static unsigned int current_tlb_config_phys;
+static int force_tlb_reprogramming;
+
+static int try_cached_translation(CORE_ADDR *addr)
+{
+    if (last_page
+	&& last_pid == PIDGET(inferior_ptid)
+	&& last_page == (*addr & ~0xfff)
+	&& !force_tlb_reprogramming) {
+	*addr = last_translation | (*addr & 0xfff);
+	return 1;
+    }
+
+    return 0;
+}
+
+static int thread_info_regnum;
+static struct obstack linux_sh4_obstack;
+static unsigned int cache_used;
+static unsigned int has_started;
+static int skip_schedule_frame = 1;
+
+static unsigned long memory_start, memory_end;
+static enum { PMB_UNKNOWN, PMB_ON, PMB_OFF } pmb_mode;
+
+/* Addresses used by the SH4 specific linux awareness. */
+DECLARE_ADDR(contig_page_data);
+DECLARE_ADDR(init_thread_union);
+DECLARE_ADDR(irq_desc);
+DECLARE_ADDR(max_low_pfn);
+DECLARE_ADDR(mem_map);
+DECLARE_ADDR(min_low_pfn);
+DECLARE_ADDR(per_cpu__kstat);
+DECLARE_ADDR(pmb_init);
+DECLARE_ADDR(restore_all);
+DECLARE_ADDR(ret_from_exception);
+DECLARE_ADDR(ret_from_fork);
+DECLARE_ADDR(ret_from_irq);
+DECLARE_ADDR(swapper_pg_dir);
+DECLARE_ADDR(swapper_space);
+DECLARE_ADDR(syscall_call);
+DECLARE_ADDR(work_resched);
+
+/* Fields used by the SH4 specific linux awareness. */
+DECLARE_FIELD(hw_interrupt_type, typename);
+DECLARE_FIELD(irq_chip,          name);
+DECLARE_FIELD(irq_desc,          action);
+DECLARE_FIELD(irq_desc,          handler);
+DECLARE_FIELD(irq_desc,          chip);
+DECLARE_FIELD(irq_desc,          name);
+DECLARE_FIELD(irqaction,         name);
+DECLARE_FIELD(irqaction,         next);
+DECLARE_FIELD(kernel_stat,       irqs);
+DECLARE_FIELD(mm_struct,         pgd);
+DECLARE_FIELD(page,              flags);
+DECLARE_FIELD(page,              mapping);
+DECLARE_FIELD(pglist_data,       node_start_pfn);
+DECLARE_FIELD(task_struct,       mm);
+DECLARE_FIELD(task_struct,       thread_info);
+DECLARE_FIELD(task_struct,       thread);
+DECLARE_FIELD(task_struct,       stack);
+DECLARE_FIELD(thread_info,       task);
+DECLARE_FIELD(thread_struct,     pc);
+DECLARE_FIELD(thread_struct,     sp);
+
+/* Struct pt_regs information */
+static int pt_regs_size;
+
+#define CACHE_ALLOC(size) ({ \
+          void* mem = obstack_alloc(&linux_sh4_obstack, (size)); \
+          memset(mem, 0, size); \
+          cache_used = 1; \
+          mem; })
+
+typedef struct pte {
+    CORE_ADDR address;
+    CORE_ADDR pages[1024];
+} pte_t;
+
+typedef struct pgd {
+    CORE_ADDR address;
+    pte_t*    ptes[1024];
+} pgd_t;
+
+typedef struct user_pgd {
+    CORE_ADDR task_struct;
+    pgd_t pgd;
+    struct user_pgd* next;
+} user_pgd_t;
+
+struct vm_cache
+{
+    pgd_t *kernel_pgd;
+    user_pgd_t *user_pgds;
+} linux_sh4_cache;
+
+user_pgd_t* current_user_pgd;
+
+#define mem_mask  0xE0000000
+#define P0_mask   0x00000000
+#define P1_mask   0x80000000
+#define P2_mask   0xA0000000
+#define P3_mask   0xC0000000
+#define P4_mask   0xE0000000
+
+#define _PAGE_PRESENT 0x100
+#define _PAGE_DIRTY   0x004
+#define _PAGE_RW      0x020
+
+enum registers {
+    R0, R1, R2, R3, R4, R5, R6, R7, R8, R9, R10, R11, R12, R13, R14, R15,
+    PC, PR, GBR, VBR, MACH, MACL, SR,
+    R7B1 = 58
+};
+
+struct pt_regs {
+	unsigned long regs[16];
+	unsigned long pc;
+	unsigned long pr;
+	unsigned long sr;
+	unsigned long gbr;
+	unsigned long mach;
+	unsigned long macl;
+	long tra;
+};
+
+static int in_se_mode()
+{
+    if (pmb_mode)
+	return pmb_mode == PMB_ON;
+
+    if (! HAS_ADDR(pmb_init)
+	|| ! HAS_ADDR(min_low_pfn)
+	|| ! HAS_ADDR(max_low_pfn)){
+	pmb_mode = PMB_OFF;
+	DEBUG(VM, 1, "Not in PMB mode\n");
+	return 0;
+    }
+
+    memory_start = read_memory_unsigned_integer(ADDR(min_low_pfn), 4) << 12;
+    memory_end = read_memory_unsigned_integer(ADDR(max_low_pfn), 4) << 12;
+    pmb_mode = PMB_ON;
+    return 1;
+}
+
+static int nr_irqs = 0;
+static int irq_desc_size = 0;
+
+static void
+get_nr_irqs ()
+{
+    struct symbol *sym = lookup_symbol ("irq_desc", NULL,
+					VAR_DOMAIN, NULL, NULL);
+
+    if (!sym
+	|| TYPE_CODE (SYMBOL_TYPE (sym)) != TYPE_CODE_ARRAY)
+	error ("\
+Couldn't find the NR_IRQS kernel setting using the debug info. Use\n\
+'set linux-awareness nr_irqs <n>' and 'set linux-awareness irq_desc_size <n>'\n\
+to workaround.");
+
+    irq_desc_size = TYPE_LENGTH (TYPE_TARGET_TYPE (SYMBOL_TYPE (sym)));
+    nr_irqs = TYPE_LENGTH (SYMBOL_TYPE (sym))/irq_desc_size;
+}
+
+static void
+interrupts_command (char *args, int from_tty)
+{
+    gdb_byte *irq_descs;
+    int i;
+    char buf[65];
+
+    struct name {
+	CORE_ADDR    addr;
+	char         name[65];
+	struct name *next;
+    } *names1 = NULL, *names2 = NULL, *cur;
+
+    struct name *find_name_aux (CORE_ADDR addr, struct name* list) {
+	struct name *n = list;
+
+	while (n) {
+	    if (n->addr == addr)
+		return n;
+	    n = n->next;
+	}
+
+	return NULL;
+    }
+
+    struct name *register_name (CORE_ADDR base, struct field_info* field) {
+	struct name *name = xmalloc (sizeof (struct name));
+	struct name *n;
+	CORE_ADDR addr;
+
+	addr = read_memory_typed_address (base + linux_get_field_offset(field),
+					  builtin_type_void_data_ptr);
+	n = find_name_aux (addr, names2);
+	if (n)
+	    return n;
+
+	read_memory_string (addr, buf, 64);
+	strcpy (name->name, buf);
+	name->addr = base;
+	name->next = names1;
+	names1 = name;
+
+	name = xmalloc (sizeof (struct name));
+	strcpy (name->name, buf);
+	name->addr = addr;
+	name->next = names2;
+	names2 = name;
+
+	return name;
+    }
+
+    struct name *find_name (CORE_ADDR addr, struct field_info* field) {
+	struct name* cur = find_name_aux (addr, names1);
+
+	if (cur)
+	    return cur;
+
+	return register_name (addr, field);
+    }
+
+    void free_names () {
+	while (names1) {
+	    cur = names1->next;
+	    xfree (names1);
+	    names1 = cur;
+	}
+	while (names2) {
+	    cur = names2->next;
+	    xfree (names2);
+	    names2 = cur;
+	}
+    }
+
+    buf[64] = '\0';
+
+    if (!nr_irqs)
+	get_nr_irqs ();
+
+    printf_filtered ("IRQ     Triggered Handler => Action\n");
+    printf_filtered ("-----------------------------------\n");
+
+    irq_descs = xmalloc (nr_irqs*irq_desc_size);
+    read_memory (ADDR (irq_desc), irq_descs, nr_irqs*irq_desc_size);
+
+    for (i = 0; i < nr_irqs; ++i) {
+	CORE_ADDR action = extract_pointer_field (irq_descs + i*irq_desc_size,
+						  irq_desc, action);
+	CORE_ADDR name;
+	int count;
+
+	if (!action)
+	    continue;
+
+	count = read_memory_unsigned_integer (ADDR (per_cpu__kstat) + F_OFFSET (kernel_stat, irqs) + i*F_SIZE (kernel_stat, irqs)/nr_irqs,
+					      F_SIZE (kernel_stat, irqs)/nr_irqs);
+
+	printf_filtered ("%3d     %9u ", i, count);
+	if (detected_version >= V2_6_23) {
+	    CORE_ADDR chip = extract_pointer_field (irq_descs + i*irq_desc_size,
+						    irq_desc, chip);
+
+	    cur = find_name (chip, &FIELD_INFO(irq_chip, name));
+	    printf_filtered ("%14s", cur->name);
+	    cur = find_name (ADDR (irq_desc) + i*irq_desc_size,
+			     &FIELD_INFO(irq_desc, name));
+	    printf_filtered ("-%-8s ", cur->name);
+
+	} else {
+	    CORE_ADDR handler;
+	    handler = extract_pointer_field (irq_descs + i*irq_desc_size,
+					     irq_desc, handler);
+
+	    cur = find_name (handler, &FIELD_INFO(hw_interrupt_type, typename));
+	    printf_filtered ("%s ", cur->name);
+	}
+
+	cur = find_name (action, &FIELD_INFO(irqaction, name));
+	printf_filtered ("=> %s", cur->name);
+	do {
+	    action = read_pointer_field (action,  irqaction, next);
+	    if (!action) break;
+	    cur = find_name (action, &FIELD_INFO(irqaction, name));
+	    printf_filtered (", %s", cur->name);
+	} while (1);
+
+	printf_filtered ("\n");
+    }
+
+    xfree (irq_descs);
+    free_names ();
+}
+
+static void
+exception_frame_this_id (struct frame_info *next_frame, void **this_cache,
+			  struct frame_id *this_id)
+{
+    *this_id = frame_id_build (frame_sp_unwind(next_frame),
+			       frame_pc_unwind(next_frame));
+}
+
+static struct pt_regs *
+exception_frame_cache(struct frame_info *next_frame, void **this_cache)
+{
+    struct frame_info* this_frame;
+    CORE_ADDR pc;
+    CORE_ADDR regs_addr;
+    struct block* b;
+    struct symbol* sym;
+    struct value* val;
+    struct pt_regs* regs;
+    int i;
+    unsigned long* my_regs;
+
+    if (*this_cache)
+	return *this_cache;
+
+    regs_addr = frame_sp_unwind(next_frame);
+
+    *this_cache = FRAME_OBSTACK_ZALLOC(struct pt_regs);
+    regs = *this_cache;
+    memset(regs, 0, sizeof(struct pt_regs));
+
+    i = 0;
+    my_regs = (unsigned long*)regs;
+    while (i<sizeof(struct pt_regs)/sizeof(unsigned long)) {
+	*my_regs = read_memory_unsigned_integer(regs_addr, 4);
+	regs_addr += 4; ++my_regs; ++i;
+    }
+
+    return regs;
+}
+
+static void
+exception_frame_prev_register (struct frame_info *next_frame,
+				void **this_cache,
+				int regnum, int *optimizedp,
+				enum lval_type *lvalp, CORE_ADDR *addrp,
+				int *realnump, gdb_byte *valuep)
+{
+    struct pt_regs *cache = exception_frame_cache(next_frame, this_cache);
+
+    if (! cache)
+	error("Can't unwind exception frame.");
+
+    *optimizedp = 0;
+    *lvalp = not_lval;
+    *addrp = 0;
+    *realnump = -1;
+
+    switch (regnum) {
+    case R0:
+    case R1:
+    case R2:
+    case R3:
+    case R4:
+    case R5:
+    case R6:
+    case R7:
+    case R8:
+    case R9:
+    case R10:
+    case R11:
+    case R12:
+    case R13:
+    case R14:
+    case R15:
+        if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->regs[regnum-R0]);
+	break;
+    case PC:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->pc);
+	break;
+    case PR:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->pr);
+	break;
+    case SR:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->sr);
+	break;
+    case GBR:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->gbr);
+	break;
+    case MACH:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->mach);
+	break;
+    case MACL:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->macl);
+	break;
+    default:
+	*optimizedp = 1;
+	*lvalp = not_lval;
+	*addrp = 0;
+	*realnump = -1;
+	get_frame_register(next_frame, regnum, valuep);
+    }
+}
+
+static int
+exception_frame_sniffer (const struct frame_unwind *self,
+			  struct frame_info *next_frame,
+			  void **this_cache)
+{
+    CORE_ADDR func = frame_pc_unwind(next_frame);
+
+    if ((HAS_ADDR(ret_from_irq) && func == ADDR(ret_from_irq))
+	|| (HAS_ADDR(ret_from_exception) && func == ADDR(ret_from_exception))
+	|| (HAS_ADDR(restore_all) && func == ADDR(restore_all))) {
+	linux_read_process_symbols();
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind exception_frame_unwind = {
+  SIGTRAMP_FRAME,
+  exception_frame_this_id,
+  exception_frame_prev_register,
+  NULL,
+  exception_frame_sniffer
+};
+
+static struct pt_regs *
+syscall_frame_cache(struct frame_info *next_frame, void **this_cache)
+{
+    struct frame_info* this_frame = get_prev_frame(next_frame);
+    ULONGEST sp, stack_top;
+    CORE_ADDR regs_addr;
+    struct pt_regs* regs;
+    unsigned long* my_regs;
+    int i;
+
+    if (*this_cache)
+	return *this_cache;
+
+    regcache_cooked_read_unsigned(get_current_regcache(),R15,&sp);
+    /* SP should be near the top of the stack which is on a page
+       boundary. In fact, SP should certainly be pointing at the saved
+       registers, but this seems more flexible if the asm in entry.S
+       changes. */
+    stack_top = (sp + 4096) & ~0xFFF;
+    regs_addr = stack_top - sizeof(struct pt_regs);
+
+    /* The location of struct pt_regs upon syscall has changed between
+       STLinux 2.0 and STLinux 2.2. */
+    if (detected_version == V2_6_11)
+	regs_addr -= 4;
+
+    this_frame = get_prev_frame(next_frame);
+    *this_cache = FRAME_OBSTACK_ZALLOC(struct pt_regs);
+    regs = *this_cache;
+    memset(regs, 0, sizeof(struct pt_regs));
+
+    i = 0;
+    my_regs = (unsigned long*)regs;
+    while (i<sizeof(struct pt_regs)/sizeof(unsigned long)) {
+	*my_regs = read_memory_unsigned_integer(regs_addr, 4);
+	regs_addr += 4; ++my_regs; ++i;
+    }
+
+    return regs;
+}
+
+static void
+syscall_frame_this_id (struct frame_info *next_frame, void **this_cache,
+		       struct frame_id *this_id)
+{
+    struct pt_regs *cache = syscall_frame_cache(next_frame, this_cache);
+
+    *this_id = frame_id_build (frame_sp_unwind(next_frame), /* was : cache->regs[15], */
+			       frame_func_unwind(next_frame, NORMAL_FRAME));
+}
+
+static void
+syscall_frame_prev_register (struct frame_info *next_frame,
+			     void **this_cache,
+			     int regnum, int *optimizedp,
+			     enum lval_type *lvalp, CORE_ADDR *addrp,
+			     int *realnump, gdb_byte *valuep)
+{
+    struct pt_regs *cache = syscall_frame_cache(next_frame, this_cache);
+
+    if (! cache)
+	error("Can't unwind exception frame.");
+
+    *optimizedp = 0;
+    *lvalp = not_lval;
+    *addrp = 0;
+    *realnump = -1;
+
+    switch (regnum) {
+    case R0:
+    case R1:
+    case R2:
+    case R3:
+    case R4:
+    case R5:
+    case R6:
+    case R7:
+    case R8:
+    case R9:
+    case R10:
+    case R11:
+    case R12:
+    case R13:
+    case R14:
+    case R15:
+        if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->regs[regnum-R0]);
+	break;
+    case PC:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->pc);
+	break;
+    case PR:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->pr);
+	break;
+    case SR:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->sr);
+	break;
+    case GBR:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->gbr);
+	break;
+    case MACH:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->mach);
+	break;
+    case MACL:
+	if (valuep != NULL)
+	    store_unsigned_integer (valuep, 4, cache->macl);
+	break;
+    default:
+	*optimizedp = 1;
+	*lvalp = not_lval;
+	*addrp = 0;
+	*realnump = -1;
+	get_frame_register(next_frame, regnum, valuep);
+    }
+}
+
+static int
+syscall_frame_sniffer (const struct frame_unwind *self,
+		       struct frame_info *next_frame,
+		       void **this_cache)
+{
+    CORE_ADDR func;
+    if ((frame_relative_level (next_frame) != -1)
+	&& ((HAS_ADDR(work_resched)  && get_frame_func (next_frame) == ADDR(work_resched))
+	    || (HAS_ADDR(ret_from_fork) && get_frame_func (next_frame) == ADDR(ret_from_fork))
+	    || (HAS_ADDR(syscall_call) && get_frame_func (next_frame) == ADDR(syscall_call)))) {
+	/* Do that here because.... it should work. :-/  */
+	linux_read_process_symbols();
+    }
+
+    func = frame_func_unwind(next_frame, NORMAL_FRAME);
+
+    if ((HAS_ADDR(syscall_call) && func == ADDR(syscall_call))
+	|| (HAS_ADDR(ret_from_fork) && func == ADDR(ret_from_fork))) {
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind syscall_frame_unwind = {
+  NORMAL_FRAME,
+  syscall_frame_this_id,
+  syscall_frame_prev_register,
+  NULL,
+  syscall_frame_sniffer
+};
+
+static int sh4_linux_awareness_check()
+{
+    int res = 0;
+
+    switch (detected_version) {
+    case V2_6_11:
+    case V2_6_17:
+	res =  HAS_FIELD(mm_struct,         pgd)
+	    && HAS_FIELD(task_struct,       thread_info)
+	    && HAS_FIELD(task_struct,       thread)
+	    && HAS_FIELD(task_struct,       mm)
+	    && HAS_FIELD(thread_info,       task)
+	    && HAS_FIELD(thread_struct,     pc)
+	    && HAS_FIELD(thread_struct,     sp);
+	break;
+    case V2_6_23:
+	res =  HAS_FIELD(mm_struct,         pgd)
+	    && HAS_FIELD(task_struct,       stack)
+	    && HAS_FIELD(task_struct,       thread)
+	    && HAS_FIELD(task_struct,       mm)
+	    && HAS_FIELD(thread_info,       task)
+	    && HAS_FIELD(thread_struct,     pc)
+	    && HAS_FIELD(thread_struct,     sp);
+	break;
+    }
+
+    /* Don't include address check here, because most of the addresses
+       aren't fundamental for the awareness layer.  */
+    return res;
+}
+
+static void detect_cache_layout();
+
+static int sh4_linux_awareness_init()
+{
+    obstack_init(&linux_sh4_obstack);
+
+    thread_info_regnum = user_reg_map_name_to_regnum(current_gdbarch,
+						     "r7b1", 4);
+    DEBUG(INIT, 5, "The current_thread_info regnum is %i\n", thread_info_regnum);
+
+    frame_unwind_prepend_unwinder(current_gdbarch, &exception_frame_unwind);
+    frame_unwind_prepend_unwinder(current_gdbarch, &syscall_frame_unwind);
+
+    add_com ("proc_interrupts", class_obscure, interrupts_command,
+	     "Print interrupt statistics.");
+
+    add_setshow_boolean_cmd("skip_schedule_frame",
+			    class_obscure,
+			    &skip_schedule_frame,
+			    "Set whether the debugger should hide the schedule() frame for sleeping tasks",
+			    "Show whether the debugger should hide the schedule() frame for sleeping tasks",
+			    NULL, NULL, NULL,
+			    &set_linux_awareness_cmd_list,
+			    &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd("force_tlb_reprogramming",
+			    class_obscure,
+			    &force_tlb_reprogramming,
+			    "Set whether the debugger should systematicaly reprogram the TLB to access virtual memory instead of accessing the physical address.",
+			    "Set whether the debugger should systematicaly reprogram the TLB to access virtual memory instead of accessing the physical address.",
+			    NULL, NULL, NULL,
+			    &set_linux_awareness_cmd_list,
+			    &show_linux_awareness_cmd_list);
+
+    return thread_info_regnum != -1;
+}
+
+void translate_memory_address_clear_cache()
+{
+    if (current_tlb_config_phys) {
+	current_tlb_config_phys = current_tlb_config_virt = 0;
+	/* Flush the first TLB entry */
+	write_memory_unsigned_integer(0xF6000000, 4, 0);
+    }
+
+    if (cache_used) {
+	obstack_free(&linux_sh4_obstack, 0);
+	obstack_init(&linux_sh4_obstack);
+	linux_sh4_cache.kernel_pgd = NULL;
+	linux_sh4_cache.user_pgds = NULL;
+	current_user_pgd = NULL;
+	cache_used = 0;
+    }
+}
+
+static int
+get_start_pfn(unsigned int *start_pfn)
+{
+    CORE_ADDR pagedata = HAS_ADDR(contig_page_data) ?
+	ADDR(contig_page_data) : (CORE_ADDR)-1;
+
+    if (pagedata == (CORE_ADDR)-1)
+	return 0;
+
+    *start_pfn = read_unsigned_field(pagedata, pglist_data, node_start_pfn);
+    return 1;
+}
+
+static CORE_ADDR
+struct_page_from_phys_addr(CORE_ADDR addr)
+{
+    unsigned int pfn = (addr & ~P1_mask) >> 12;
+    unsigned int start_pfn;
+
+    if (! HAS_ADDR(mem_map)
+	|| ! get_start_pfn(&start_pfn))
+	return (CORE_ADDR)-1;
+
+    return read_memory_typed_address(ADDR(mem_map) + 4*(pfn-start_pfn),
+				     builtin_type_void_data_ptr);
+}
+
+static unsigned int get_address_pte_value(CORE_ADDR addr,
+					  pte_t *pte)
+{
+    unsigned int offset;
+    unsigned int page_addr;
+
+    gdb_assert(pte != NULL);
+
+    offset = ((unsigned int)addr << 10) >> 22;
+    page_addr = pte->pages[offset];
+
+    if (page_addr == 0) {
+	page_addr = read_memory_unsigned_integer(pte->address+offset*4, 4);
+	DEBUG(VM, 3,
+	      "Reading page address for %x ( *(unsigned int*)0x%s ) -> %x\n",
+	      (unsigned int)addr, paddr (pte->address+offset*4),
+	      (unsigned int)page_addr);
+
+	pte->pages[offset] = page_addr;
+    }
+
+    return page_addr;
+}
+
+static pte_t *get_address_pte(CORE_ADDR addr,
+			     pgd_t *pgd)
+{
+    unsigned int  offset;
+    pte_t        *pte = NULL;
+
+    gdb_assert(pgd != NULL);
+
+    offset = ((unsigned int)addr) >> 22;
+    pte = pgd->ptes[offset];
+
+    if (pte == NULL) {
+	pte = CACHE_ALLOC(sizeof(pte_t));
+
+	pte->address = read_memory_unsigned_integer(pgd->address+offset*4, 4);
+	DEBUG(VM, 3,
+	      "Reading PTE address for %x ( *(unsigned int*)%s ) -> %x\n",
+	      (unsigned int)addr, paddr (pgd->address+offset*4),
+	      (unsigned int)pte->address);
+
+	/* When using the TLB optimization patch
+	   ( https://bugzilla.stlinux.com/attachment.cgi?id=334 ) the
+	   PTE doesn't contain the PAGE_PRESENT flag and it is directly a
+	   P1 address. */
+
+	if ((pte->address & P1_mask) != P1_mask)
+	    if (! (pte->address & _PAGE_PRESENT) )
+		return NULL;
+
+	pte->address &= ~0xFFF;
+	pte->address |= P1_mask;
+
+	pgd->ptes[offset] = pte;
+    }
+
+    return pte;
+}
+
+static enum page_status translate_address_through_pte(CORE_ADDR *addr,
+						      pte_t *pte)
+{
+    unsigned int page_addr;
+    unsigned int page_offset;
+    enum page_status res = PAGE_UNKNOWN;
+    page_offset = ((unsigned int)*addr) & 0xFFF;
+    page_addr = get_address_pte_value(*addr, pte);
+
+    if (!(page_addr & _PAGE_PRESENT)) {
+	if (!page_addr) {
+	    res = PAGE_NOPAGE;
+	} else {
+	    CORE_ADDR struct_page;
+	    struct_page = struct_page_from_phys_addr(page_addr);
+
+	    if (struct_page == (CORE_ADDR)-1
+		|| !HAS_ADDR(swapper_space))
+		res = PAGE_UNKNOWN;
+	    else if ((detected_version >= V2_6_17 &&
+		      /* PG_swapcache is the bit 15 in the page flags. */
+		      read_unsigned_field(struct_page, page, flags) & (1<<15))
+		     || (detected_version < V2_6_17 &&
+			 read_unsigned_field(struct_page, page, mapping) == ADDR(swapper_space)))
+		res = PAGE_SWAPPED;
+	    else
+		res = PAGE_NOTMAPPED;
+	}
+
+	page_addr &= ~0xFFF;
+
+	DEBUG(VM, 2, "addr = %x => P1 address : %x (%s)\n",
+	      (unsigned int)*addr,
+	      page_addr + page_offset,
+	      ( res == PAGE_NOPAGE ? "PAGE_NOPAGE"
+		: ( res == PAGE_SWAPPED ? "PAGE_SWAPPED"
+		    : ( res == PAGE_NOPAGE ? "PAGE_NOTMAPPED"
+			: ( res == PAGE_UNKNOWN ? "PAGE_UNKNOWN" : "??" ))))
+	      );
+
+	return res;
+    }
+
+    if (in_se_mode() || force_tlb_reprogramming) {
+	if (page_addr >= memory_start
+	    && page_addr < memory_end
+	    && !force_tlb_reprogramming) {
+	    page_addr -= memory_start;
+	} else {
+	    CORE_ADDR tlb_addr;
+	    int valid, dirty;
+	    unsigned long virt, phys;
+
+	    valid = (page_addr & _PAGE_PRESENT) != 0;
+	    dirty = (page_addr & _PAGE_DIRTY) != 0;
+	    virt = (*addr & (~0x3ffLL)) | (valid<<8) | (dirty<<9);
+	    phys = page_addr & ~(1<<9);
+
+	    /* This must be IO memory.
+	       page_addr contains the bus address, but we don't know
+	       if there's currently a TLB entry for this address. */
+
+	    /* Check if we already setup the TLB for this mapping. */
+	    if (current_tlb_config_phys
+		&& current_tlb_config_phys == phys
+		&& current_tlb_config_virt == virt)
+		return PAGE_PRESENT;
+
+	    /* Flush any existing TLB entry correspnding to this
+	       address. This prevents a multimapping fault from
+	       happening.
+	       We achieve that using an associative write to the UTLB
+	       memory mapped data array. */
+	    tlb_addr = 0xF6000000 | (1<<7); /* Bit 7 means associative write.*/
+	    write_memory_unsigned_integer(tlb_addr, 4, *addr & (~0x3ffLL));
+
+	    /* Add a TLB entry for this page */
+	    /* Address array => VPN + valid bit + dirty bit */
+	    tlb_addr = 0xF6000000;
+	    write_memory_unsigned_integer(tlb_addr, 4, virt);
+	    /* Data array => PPN + flags */
+	    tlb_addr = 0xF7000000;
+	    write_memory_unsigned_integer(tlb_addr, 4, phys);
+
+	    current_tlb_config_virt = virt;
+	    current_tlb_config_phys = phys;
+
+	    DEBUG(VM, 2, "addr = %x => Reprogrammed TLB (PAGE_PRESENT)\n",
+		  (unsigned int)*addr);
+
+	    /* Access the page through its virtual address. */
+	    return PAGE_PRESENT;
+	}
+    }
+
+    page_addr += P1_mask;
+    res = PAGE_PRESENT;
+    page_addr &= ~0xFFF;
+
+    DEBUG(VM, 2, "addr = %x => P1 address : %x (PAGE_PRESENT)\n",
+	  (unsigned int)*addr,
+	  page_addr + page_offset);
+
+    *addr = page_addr + page_offset;
+
+    return res;
+}
+
+static enum page_status translate_address_through_pgd(CORE_ADDR *addr,
+						      pgd_t *pgd)
+{
+    unsigned int      offset;
+    pte_t            *pte;
+    enum page_status  res;
+    CORE_ADDR         orig = *addr;
+
+    DEBUG(VM, 2, "Trying to translate %x\n", (unsigned int)*addr);
+
+    pte = get_address_pte(*addr, pgd);
+
+    if (pte == NULL) {
+	return PAGE_NOPAGE;
+    }
+
+    res = translate_address_through_pte(addr, pte);
+
+    if (res == PAGE_PRESENT && orig != *addr) {
+	last_page = orig & ~0xfff;
+	last_pid  = PIDGET(inferior_ptid);
+	last_translation = *addr & ~0xfff;
+	last_can_write = get_address_pte_value(orig, pte) & _PAGE_RW;
+    }
+
+    return res;
+}
+
+static pgd_t* get_kernel_pgd()
+{
+    if (linux_sh4_cache.kernel_pgd == NULL) {
+	linux_sh4_cache.kernel_pgd = CACHE_ALLOC(sizeof(pgd_t));
+	linux_sh4_cache.kernel_pgd->address = ADDR(swapper_pg_dir);
+    }
+
+    return linux_sh4_cache.kernel_pgd;
+}
+
+static pgd_t* find_user_pgd(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    user_pgd_t* u_pgd = linux_sh4_cache.user_pgds;
+    unsigned int mm_struct_address;
+    unsigned int pgd_address;
+
+    if (current_user_pgd && current_user_pgd->task_struct == task_struct)
+	return &current_user_pgd->pgd;
+
+    while (u_pgd != NULL) {
+	if (u_pgd->task_struct == task_struct)
+	    break;
+
+	u_pgd = u_pgd->next;
+    }
+
+    if (u_pgd != NULL) {
+	current_user_pgd = u_pgd;
+	return &current_user_pgd->pgd;
+    }
+
+    if ( (task_struct & mem_mask) != P1_mask) {
+	DEBUG(VM, 1, "Task struct should be at a P1 address.");
+	return NULL;
+    }
+    mm_struct_address = read_unsigned_field(task_struct, task_struct, mm);
+    if (mm_struct_address == 0) {
+	DEBUG(VM, 1, "No userspace address allowed in a kernel thread.");
+	return NULL;
+    }
+    if ( (mm_struct_address & mem_mask) != P1_mask) {
+	DEBUG(VM, 1, "mm struct should be at a P1 address.");
+	return NULL;
+    }
+    pgd_address = read_unsigned_field(mm_struct_address, mm_struct, pgd);
+    if ( (pgd_address & mem_mask) != P1_mask) {
+	DEBUG(VM, 1, "pgd should be at a P1 address.");
+	return NULL;
+    }
+
+    /* Allocate new cache */
+    u_pgd = CACHE_ALLOC(sizeof(user_pgd_t));
+    u_pgd->task_struct = task_struct;
+    u_pgd->pgd.address = pgd_address;
+    current_user_pgd = u_pgd;
+
+    u_pgd->next = linux_sh4_cache.user_pgds;
+    linux_sh4_cache.user_pgds = u_pgd;
+
+    return &current_user_pgd->pgd;
+}
+
+static pgd_t* get_address_pgd(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    switch (addr & mem_mask) {
+    case P3_mask:
+	return get_kernel_pgd();
+    case P1_mask:
+    case P2_mask:
+    case P4_mask:
+	gdb_assert(0 && "No pgd for non-translatable addresses.");
+    default:
+	return find_user_pgd(addr, task_struct);
+    }
+
+    return NULL;
+}
+
+static int linux_sh4_address_needs_translation(CORE_ADDR addr)
+{
+    addr &= mem_mask;
+    return addr != P1_mask
+	&& addr != P2_mask
+	&& addr != P4_mask;
+}
+
+enum page_status translate_memory_address(CORE_ADDR *addr, CORE_ADDR task_struct)
+{
+    pgd_t *pgd;
+
+    DEBUG(VM, 3, "Asking to translate %x (mem %x)\n",
+	  (unsigned int)*addr, (unsigned int)(*addr) & mem_mask);
+
+    if (! linux_sh4_address_needs_translation(*addr))
+	return PAGE_PRESENT;
+
+    if (try_cached_translation(addr)) {
+	DEBUG(VM, 3, "Cached translation: %s\n", paddr (*addr));
+	return PAGE_PRESENT;
+    }
+
+    pgd = get_address_pgd(*addr, task_struct);
+
+    if (pgd == NULL)
+	return PAGE_UNKNOWN;;
+
+    return translate_address_through_pgd(addr, pgd);
+}
+
+static CORE_ADDR translate_watch_address_pgd(CORE_ADDR addr,
+					     pgd_t *pgd)
+{
+    unsigned int  offset;
+    pte_t        *pte;
+    CORE_ADDR    res;
+
+    pte = get_address_pte(addr, pgd);
+
+    if (pte != NULL) {
+	offset = ((unsigned int)addr << 10) >> 22;
+	return pte->address+offset*4;
+    }
+
+    /* The PTE isn't mapped */
+    offset = ((unsigned int)addr) >> 22;
+    return pgd->address+offset*4;
+}
+
+static CORE_ADDR translate_memory_watch_address(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    pgd_t *pgd;
+
+    if (! linux_sh4_address_needs_translation(addr))
+	return 0;
+
+    if (try_cached_translation(&addr))
+	return 0;
+
+    pgd = get_address_pgd(addr, task_struct);
+
+    if (pgd == NULL)
+	return 0;
+
+    return translate_watch_address_pgd(addr, pgd);
+}
+
+static int sh4_linux_can_write(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    pgd_t *pgd;
+    pte_t *pte;
+
+    if (! linux_sh4_address_needs_translation(addr))
+	return 1;
+
+    if (try_cached_translation(&addr))
+	return last_can_write;
+
+    pgd = get_address_pgd(addr, task_struct);
+
+    if (pgd == NULL)
+	return 0;
+
+    pte = get_address_pte(addr, pgd);
+
+    if (pte == NULL)
+	return 0;
+
+    if (get_address_pte_value(addr, pte) & _PAGE_RW)
+	return 1;
+
+    return 0;
+}
+
+static int sh4_linux_is_user_address(CORE_ADDR addr)
+{
+    return !(addr & 0x80000000);
+}
+
+static int sh4_linux_is_kernel_address(CORE_ADDR addr)
+{
+    return !sh4_linux_is_user_address(addr);
+}
+
+static int cache_layout_known = 0;
+
+struct cache_info {
+	unsigned int ways;
+	unsigned int sets;
+	unsigned int linesz;
+	unsigned int way_incr;
+	unsigned int entry_shift;
+	unsigned int entry_mask;
+} i_cache_info, o_cache_info;
+
+static void print_cache_info(const char* name, const struct cache_info* info)
+{
+    DEBUG(VM, 3,
+	  "%s info:\n"
+	  "sets: %i\tlinesz: %i\n"
+	  "ways: %i\tway_incr: 0x%x\n"
+	  "entry_shift: %i\tentry_mask: 0x%x\n",
+	  name, info->sets, info->linesz,
+	  info->ways, info->way_incr,
+	  info->entry_shift, info->entry_mask);
+}
+
+static unsigned int cache_size(unsigned int s)
+{
+    switch (s) {
+    case 0x1: return (1<<12);
+    case 0x2: return (1<<13);
+    case 0x4: return (1<<14);
+    case 0x8: return (1<<15);
+    case 0x9: return (1<<16);
+    default: error("Invalid cache size : 0x%x", s);
+    };
+}
+
+static void detect_cache_layout()
+{
+    unsigned int PVR, CVR, CCR, RAMCR;
+    unsigned int size;
+
+    enum { SH4_1XX, SH4_2XX, SH4_3XX } variant;
+
+    PVR = read_memory_unsigned_integer(0xff000030, 4);
+    CVR = read_memory_unsigned_integer(0xff000040, 4);
+    CCR = read_memory_unsigned_integer(0xFF00001C, 4);
+
+    PVR >>= 16; PVR &= 0xFF;
+
+    switch (PVR) {
+    case 0x80:
+    case 0x81:
+	variant = SH4_1XX;
+	break;
+    case 0x06:
+	variant = SH4_2XX;
+	break;
+    case 0x90:
+	variant = SH4_3XX;
+	break;
+    default:
+	error("Couldn't detect the ST40 variant, got 0x%x.", PVR);
+    }
+
+    /* FIXME : hardcoded cachecline size ? */
+    o_cache_info.linesz = i_cache_info.linesz = 32;
+    o_cache_info.entry_shift = i_cache_info.entry_shift = 5;
+    o_cache_info.ways = i_cache_info.ways = 1;
+
+    if (variant == SH4_2XX
+	&& CCR >> 31) {
+	o_cache_info.ways = i_cache_info.ways = 2;
+    } else if (variant == SH4_3XX) {
+	RAMCR = read_memory_unsigned_integer(0xFF000074, 4);
+	o_cache_info.ways = (RAMCR & (1<<6)) ? 2 : 4;
+	i_cache_info.ways = (RAMCR & (1<<7)) ? 2 : 4;
+    }
+
+    i_cache_info.sets = cache_size((CVR>>20) & 0xF) / i_cache_info.linesz;
+    o_cache_info.sets = cache_size((CVR>>16) & 0xF) / o_cache_info.linesz;
+
+    i_cache_info.sets /= i_cache_info.ways;
+    o_cache_info.sets /= o_cache_info.ways;
+
+    i_cache_info.entry_mask = (i_cache_info.sets-1) << i_cache_info.entry_shift;
+    o_cache_info.entry_mask = (o_cache_info.sets-1) << o_cache_info.entry_shift;
+
+    i_cache_info.way_incr = i_cache_info.sets << i_cache_info.entry_shift;
+    o_cache_info.way_incr = o_cache_info.sets << o_cache_info.entry_shift;
+
+    cache_layout_known = 1;
+
+    print_cache_info("O-Cache", &o_cache_info);
+    print_cache_info("I-Cache", &i_cache_info);
+}
+
+/* This flushing routine is called only for virtual memory adresses.
+   If we pass access_addr == phys_addr, it means that we want to
+   suppress the alias we may have introduced through our direct access
+   to this physical address.
+
+   Precondition :
+   [access_addr..access_addr+len[ lies on the same physical page. */
+
+static void linux_sh4_flush_cache_for_region(CORE_ADDR access_addr,
+					     CORE_ADDR phys_addr,
+					     int len,
+					     int write)
+{
+    unsigned long start_addr, end_addr, cur_phys_addr, val;
+    unsigned int i;
+
+    if (!cache_layout_known)
+	detect_cache_layout();
+
+    DEBUG(VM, 4, "Asking to flush O-Cache for access=%llx phys=%llx (+%d)\n",
+	  (ULONGEST)access_addr, (ULONGEST)phys_addr, len);
+
+    start_addr = access_addr & ~(o_cache_info.linesz-1);
+    end_addr = (access_addr+len) & ~(o_cache_info.linesz-1);
+    cur_phys_addr = phys_addr & ~(o_cache_info.linesz-1);
+
+    /* The cache tags are bus addresses, no memory space identifier */
+    cur_phys_addr -= P1_mask;
+
+    if (in_se_mode()) {
+	/* When in SE mode, we come here for RAM pages that were
+	   translated from a P0 or p3 mapping to a P1 mapping. BUT, in
+	   SE mode P1 addresses are virtual ones mapped to physical
+	   ones through the PMB. To use the right cache tags, we need to get
+	   a real physical address. */
+	cur_phys_addr += memory_start;
+    }
+
+    /* OCache */
+    while (start_addr <= end_addr) {
+	unsigned long cache_addr = 0xF4000000 | (start_addr & o_cache_info.entry_mask);
+	unsigned long cache_data;
+	for (i=0; i < o_cache_info.ways; ++i) {
+	    cache_data = read_memory_unsigned_integer(cache_addr, 4);
+
+	    DEBUG(VM, 4, "Cache address : %8lx => %8lx (tag %lx)\n",
+		  cache_addr, cache_data, (cache_data & ~0x3FF));
+	    DEBUG(VM, 4, "      phys_addr             %8lx (tag %lx)\n",
+		  cur_phys_addr, (cur_phys_addr & 0xFFFFFC00));
+
+	    if ((cache_data & 0x1) /* valid */
+		&& (write
+		    || (cache_data & 0x2) /* dirty */
+		    || (phys_addr == access_addr) /* Aliased cachelines */)
+		&& ((cache_data & ~0x3FF) == (cur_phys_addr & 0xFFFFFC00))) {
+		DEBUG(VM, 3, "Flushing O-Cache for access=%llx phys=%llx\n",
+		      (ULONGEST)start_addr, (ULONGEST)cur_phys_addr);
+		write_memory_unsigned_integer(cache_addr, 4, 0);
+	    }
+
+	    cache_addr += o_cache_info.way_incr;
+	}
+
+	start_addr += o_cache_info.linesz;
+	cur_phys_addr += o_cache_info.linesz;
+    }
+
+#if 0
+    /* ICache */
+    /* The I-Cache is cleared for each write by the SHDEBUG layer. No
+       need to fiddle with it for now. */
+
+#define CCR		0xff00001c	/* Address of Cache Control Register */
+#define CCR_CACHE_OCE	0x0001	/* Operand Cache Enable */
+#define CCR_CACHE_WT	0x0002	/* Write-Through (for P0,U0,P3) (else writeback)*/
+#define CCR_CACHE_CB	0x0004	/* Copy-Back (for P1) (else writethrough) */
+#define CCR_CACHE_OCI	0x0008	/* OC Invalidate */
+#define CCR_CACHE_ORA	0x0020	/* OC RAM Mode */
+#define CCR_CACHE_OIX	0x0080	/* OC Index Enable */
+#define CCR_CACHE_ICE	0x0100	/* Instruction Cache Enable */
+#define CCR_CACHE_ICI	0x0800	/* IC Invalidate */
+#define CCR_CACHE_IIX	0x8000	/* IC Index Enable */
+#define CCR_CACHE_EMODE	0x80000000	/* EMODE Enable */
+
+    val = read_memory_unsigned_integer(CCR, 4);
+    val |= CCR_CACHE_ICI;
+    write_memory_unsigned_integer(CCR, 4, val);
+#endif
+}
+
+static CORE_ADDR first_pointer_arg_value()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(), ARG0_REGNUM, &ret);
+    return ret;
+}
+
+static CORE_ADDR second_pointer_arg_value()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(), ARG0_REGNUM+1, &ret);
+    return ret;
+}
+
+static CORE_ADDR third_pointer_arg_value()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(), ARG0_REGNUM+2, &ret);
+    return ret;
+}
+
+static CORE_ADDR return_address_at_start_of_function()
+{
+    ULONGEST ret;
+    regcache_cooked_read_unsigned(get_current_regcache(), PR_REGNUM, &ret);
+    return ret;
+}
+
+static CORE_ADDR current_task_struct;
+static ULONGEST current_thread_info;
+
+void thread_clear_cache()
+{
+    current_task_struct = 0;
+    current_thread_info = 0;
+}
+
+static CORE_ADDR
+current_thread_info_address()
+{
+    if (! current_thread_info) {
+	if (has_started)
+	    regcache_cooked_read_unsigned(get_current_regcache(), thread_info_regnum, &current_thread_info);
+	else
+	    current_thread_info = ADDR(init_thread_union);
+	DEBUG(VM, 3,"current_thread_info : %x\n", (unsigned int)current_thread_info);
+    }
+
+    return current_thread_info;
+}
+
+static CORE_ADDR
+current_task_struct_address()
+{
+    if (! current_task_struct) {
+	CORE_ADDR task_field_addr = current_thread_info_address();
+	current_task_struct = read_unsigned_field(task_field_addr,
+						  thread_info, task);
+	DEBUG(VM, 3,"current_task_struct : %x\n",
+	      (unsigned int)current_task_struct);
+    }
+
+    return current_task_struct;
+}
+
+static int new_regcache;
+
+static CORE_ADDR  fetch_context_register_real(CORE_ADDR task_struct)
+{
+    gdb_byte *thread_info_buffer;
+    gdb_byte *stack_buffer;
+    gdb_byte *thread_struct_buffer;
+    struct cleanup *clean;
+    struct regcache * regcache;
+    int offset = 0, val, i;
+    CORE_ADDR pc;
+
+    thread_struct_buffer = xmalloc(F_SIZE(task_struct, thread));
+    thread_info_buffer = xmalloc(4);
+    stack_buffer = xmalloc(9*4);
+
+    clean = make_cleanup(xfree, thread_struct_buffer);
+    make_cleanup(xfree, thread_info_buffer);
+    make_cleanup(xfree, stack_buffer);
+
+    read_memory(task_struct+F_OFFSET(task_struct, thread),
+		thread_struct_buffer, F_SIZE(task_struct, thread));
+
+    if (detected_version == V2_6_23)
+	read_memory(task_struct+F_OFFSET(task_struct, stack),
+		    thread_info_buffer, F_SIZE(task_struct, stack));
+    else
+	read_memory(task_struct+F_OFFSET(task_struct, thread_info),
+		    thread_info_buffer, F_SIZE(task_struct, thread_info));
+
+    /* We supply all registers at once since what's costly is the
+       number of memory accesses, not the size of the accesses. */
+
+    read_memory(extract_unsigned_integer(thread_struct_buffer
+					 +F_OFFSET(thread_struct, sp), 4),
+		stack_buffer, 36);
+
+    new_regcache = 1;
+
+    /* The frame info for schedule doesn't take into account the SP
+       modifications in the switch_to macro (see asm/system.h). Thus
+       we need to point SP to its value after the macro has finished
+       to get correct backtracing. */
+    /* R15 - SP */
+    val = extract_unsigned_integer(thread_struct_buffer+F_OFFSET(thread_struct, sp), 4);
+    val += 9*4;
+    store_unsigned_integer(thread_struct_buffer+F_OFFSET(thread_struct, sp), 4, val);
+    regcache = get_current_regcache();
+    regcache_raw_supply(regcache, R15, thread_struct_buffer+F_OFFSET(thread_struct, sp));
+    /* PC */
+    regcache_raw_supply(regcache, PC, thread_struct_buffer+F_OFFSET(thread_struct, pc));
+    pc = extract_typed_address (thread_struct_buffer+F_OFFSET(thread_struct, pc),
+				builtin_type_void_data_ptr);
+
+    regcache_raw_supply(regcache, R14, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, R13, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, R12, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, R11, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, R10, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, R9, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, R8, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, PR, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(regcache, GBR, stack_buffer+offset);
+    offset += 4;
+
+    /* R7B1 */
+    regcache_raw_supply(regcache, R7B1, thread_info_buffer);
+
+    for (i = 0; i < gdbarch_num_regs (current_gdbarch); i++)
+	if (! regcache_valid_p(regcache,i))
+	    /* Mark other registers as unavailable.  */
+	    regcache_invalidate(regcache, i);
+
+    do_cleanups(clean);
+
+    return pc;
+}
+
+static int doing_something_silly = 0;
+
+static int fetch_context_register(int regno, CORE_ADDR task_struct)
+{
+    struct frame_info *f;
+    struct regcache * regcache;
+    ULONGEST pc;
+
+    DEBUG(TASK, 3,"fetch_context_register(%i,%x)\n",
+	  regno, (unsigned int)task_struct);
+
+    gdb_assert( ! doing_something_silly );
+
+    if (! regcache_valid_p(get_current_regcache(), PC))
+	pc = fetch_context_register_real(task_struct);
+    else
+      regcache_cooked_read_unsigned(get_current_regcache(), PC, &pc);
+
+    /* Don't skip the frames beginning in ret_from_fork. These frames
+       will be handled by the syscall unwinder. */
+    if (skip_schedule_frame && new_regcache
+	&& !(HAS_ADDR (ret_from_fork) && pc == ADDR (ret_from_fork))) {
+	new_regcache = 0;
+
+	doing_something_silly = 1;
+	f = get_current_frame();
+
+	if (f != NULL) {
+	    int i;
+	    gdb_byte buf[4];
+	    int optimized;
+	    CORE_ADDR addr;
+	    int realnum;
+	    enum lval_type lval;
+	    unsigned long *new_registers = xcalloc(SH_NUM_REGS, sizeof(unsigned long));
+	    char *new_registers_valid = xcalloc(SH_NUM_REGS, 1);
+
+	    for (i = 0; i<SH_NUM_REGS; ++i) {
+		frame_register_unwind(f, i, &optimized, &lval, &addr,
+				      &realnum, buf);
+		if (!optimized) {
+		    memcpy(&new_registers[i], buf, 4);
+		    new_registers_valid[i] = 1;
+		}
+	    }
+
+	    regcache = get_current_regcache();
+	    regcache_raw_collect(regcache, R7B1, &new_registers[R7B1]);
+	    new_registers_valid[R7B1] = 1;
+
+/*	    registers_changed();*/
+	    reinit_frame_cache();
+
+	    for (i = 0; i<SH_NUM_REGS; ++i) {
+		if (new_registers_valid[i])
+		    regcache_raw_supply(regcache, i,&new_registers[i]);
+		else
+		    /* Mark other registers as unavailable. */
+		    regcache_invalidate(regcache, i);
+	    }
+
+	    xfree(new_registers);
+	    xfree(new_registers_valid);
+	}
+
+	doing_something_silly = 0;
+    }
+
+    return 1;
+}
+
+
+
+static int store_context_register_real(int regno, CORE_ADDR task_struct)
+{
+    gdb_byte buf[4];
+    int offset = 0;
+
+    /* A new fork has pt_regs on the stack from a fork() call (?????) */
+    /* if (p->thread.pc == (unsigned long)ret_from_fork) { */
+    /* 	kregs = (struct pt_regs*)p->thread.sp; */
+    /* 	for (count = 0; count < 16; count++) */
+    /* 	    *(gdb_regs++) = kregs->regs[count]; */
+
+    /* 	*(gdb_regs++) = kregs->pc; */
+    /* 	*(gdb_regs++) = kregs->pr; */
+    /* 	*(gdb_regs++) = kregs->gbr; */
+    /* 	*(gdb_regs++) = vbr_val; */
+    /* 	*(gdb_regs++) = kregs->mach; */
+    /* 	*(gdb_regs++) = kregs->macl; */
+    /* 	*(gdb_regs++) = kregs->sr; */
+    /* 	return; */
+    /*     } */
+
+    /*
+     * Otherwise we have to collect the thread registers from the stack
+     * built by switch function (see include/asm-sh/system.h)
+     */
+
+    if (skip_schedule_frame)
+	return 0;
+
+    switch (regno) {
+    case GBR:
+	offset -= 4;
+    case PR:
+	offset -= 4;
+    case R8:
+	offset -= 4;
+    case R9:
+	offset -= 4;
+    case R10:
+	offset -= 4;
+    case R11:
+	offset -= 4;
+    case R12:
+	offset -= 4;
+    case R13:
+	offset -= 4;
+    case R14:
+	offset += read_memory_unsigned_integer(task_struct+F_OFFSET(task_struct, thread)+F_OFFSET(thread_struct, sp), 4);
+	break;
+    default:
+	return 0;
+    }
+
+    regcache_raw_collect(get_current_regcache(), regno, buf);
+    target_write_memory(offset, buf, 4);
+    return 1;
+}
+
+static int store_context_register(int regno, CORE_ADDR task_struct)
+{
+    DEBUG(TASK, 3,"fetch_context_register(%i,%x)\n",
+	  regno, (unsigned int)task_struct);
+
+    if (regno == -1) {
+	for (regno = R8; regno <= GBR; ++regno)
+	    store_context_register_real(regno, task_struct);
+    }
+
+    if (regno < R8 || regno > GBR)
+	return 0;
+
+    return store_context_register_real(regno, task_struct);
+}
+
+
+/* Macros for single step instruction identification */
+#define OPCODE_BT(op)         (((op) & 0xff00) == 0x8900)
+#define OPCODE_BF(op)         (((op) & 0xff00) == 0x8b00)
+#define OPCODE_BTF_DISP(op)   (((op) & 0x80) ? (((op) | 0xffffff80) << 1) : \
+			      (((op) & 0x7f ) << 1))
+#define OPCODE_BFS(op)        (((op) & 0xff00) == 0x8f00)
+#define OPCODE_BTS(op)        (((op) & 0xff00) == 0x8d00)
+#define OPCODE_BRA(op)        (((op) & 0xf000) == 0xa000)
+#define OPCODE_BRA_DISP(op)   (((op) & 0x800) ? (((op) | 0xfffff800) << 1) : \
+			      (((op) & 0x7ff) << 1))
+#define OPCODE_BRAF(op)       (((op) & 0xf0ff) == 0x0023)
+#define OPCODE_BRAF_REG(op)   (((op) & 0x0f00) >> 8)
+#define OPCODE_BSR(op)        (((op) & 0xf000) == 0xb000)
+#define OPCODE_BSR_DISP(op)   (((op) & 0x800) ? (((op) | 0xfffff800) << 1) : \
+			      (((op) & 0x7ff) << 1))
+#define OPCODE_BSRF(op)       (((op) & 0xf0ff) == 0x0003)
+#define OPCODE_BSRF_REG(op)   (((op) >> 8) & 0xf)
+#define OPCODE_JMP(op)        (((op) & 0xf0ff) == 0x402b)
+#define OPCODE_JMP_REG(op)    (((op) >> 8) & 0xf)
+#define OPCODE_JSR(op)        (((op) & 0xf0ff) == 0x400b)
+#define OPCODE_JSR_REG(op)    (((op) >> 8) & 0xf)
+#define OPCODE_RTS(op)        ((op) == 0xb)
+#define OPCODE_RTE(op)        ((op) == 0x2b)
+
+#define SR_T_BIT_MASK           0x1
+
+
+static CORE_ADDR sh4_linux_single_step_destination(CORE_ADDR pc)
+{
+    short op = read_memory_unsigned_integer(pc, 2);
+    struct frame_info *frame = get_current_frame();
+    CORE_ADDR addr;
+
+    /* BT */
+    if (OPCODE_BT(op)) {
+	if (get_frame_register_unsigned(frame, SR) & SR_T_BIT_MASK)
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 2;
+    }
+
+    /* BTS */
+    else if (OPCODE_BTS(op)) {
+	if (get_frame_register_unsigned(frame, SR) & SR_T_BIT_MASK)
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 4;	/* Not in delay slot */
+    }
+
+    /* BF */
+    else if (OPCODE_BF(op)) {
+	if (!(get_frame_register_unsigned(frame, SR) & SR_T_BIT_MASK))
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 2;
+    }
+
+    /* BFS */
+    else if (OPCODE_BFS(op)) {
+	if (!(get_frame_register_unsigned(frame, SR) & SR_T_BIT_MASK))
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 4;	/* Not in delay slot */
+    }
+
+    /* BRA */
+    else if (OPCODE_BRA(op))
+	addr = pc + 4 + OPCODE_BRA_DISP(op);
+
+    /* BRAF */
+    else if (OPCODE_BRAF(op))
+	addr = pc + 4 + get_frame_register_unsigned(frame, OPCODE_BRAF_REG(op));
+
+    /* BSR */
+    else if (OPCODE_BSR(op))
+	addr = pc + 4 + OPCODE_BSR_DISP(op);
+
+    /* BSRF */
+    else if (OPCODE_BSRF(op))
+	addr = pc + 4 + get_frame_register_unsigned(frame, OPCODE_BSRF_REG(op));
+
+    /* JMP */
+    else if (OPCODE_JMP(op))
+	addr = get_frame_register_unsigned(frame, OPCODE_JMP_REG(op));
+
+    /* JSR */
+    else if (OPCODE_JSR(op))
+	addr = get_frame_register_unsigned(frame, OPCODE_JSR_REG(op));
+
+    /* RTS */
+    else if (OPCODE_RTS(op))
+	addr = get_frame_register_unsigned(frame, PR);
+
+    /* RTE */
+    else if (OPCODE_RTE(op))
+	addr = get_frame_register_unsigned(frame, R15);
+
+    /* Other */
+    else
+	addr = pc + 2;
+
+    return addr & 0xFFFFFFFF;
+}
+
+static void sh4_linux_clear_cache()
+{
+    thread_clear_cache();
+    translate_memory_address_clear_cache();
+    has_started = 1;
+}
+
+static void
+sh4_linux_awareness_close()
+{
+    sh4_linux_clear_cache();
+    cache_layout_known = 0;
+    has_started = 0;
+    pmb_mode = PMB_UNKNOWN;
+}
+
+struct linux_awareness_ops sh4_linux_awareness_ops = {
+    .name = "SH4",
+    .lo_check = sh4_linux_awareness_check,
+    .lo_init = sh4_linux_awareness_init,
+    .lo_close = sh4_linux_awareness_close,
+    .lo_address_needs_translation = linux_sh4_address_needs_translation,
+    .lo_translate_memory_address = translate_memory_address,
+    .lo_translate_memory_watch_address = translate_memory_watch_address,
+    .lo_can_write = sh4_linux_can_write,
+    .lo_is_user_address = sh4_linux_is_user_address,
+    .lo_is_kernel_address = sh4_linux_is_kernel_address,
+    .lo_flush_cache = linux_sh4_flush_cache_for_region,
+    .lo_single_step_destination = sh4_linux_single_step_destination,
+    .lo_clear_cache = sh4_linux_clear_cache,
+    .lo_first_pointer_arg_value = first_pointer_arg_value,
+    .lo_second_pointer_arg_value = second_pointer_arg_value,
+    .lo_third_pointer_arg_value = third_pointer_arg_value,
+    .lo_return_address_at_start_of_function = return_address_at_start_of_function,
+    .lo_current_task_struct_address = current_task_struct_address,
+    .lo_current_thread_info_address = current_thread_info_address,
+    .lo_fetch_context_register = fetch_context_register,
+    .lo_store_context_register = store_context_register,
+    .page_shift = 12 /* Page shift */
+};
+
+void
+_initialize_linux_awareness_sh4 (void)
+{
+    linux_awareness_ops = &sh4_linux_awareness_ops;
+}
Index: fred/gdb/linux-awareness.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ fred/gdb/linux-awareness.c	2009-02-20 10:16:22.000000000 +0000
@@ -0,0 +1,6196 @@
+
+
+#include "defs.h"
+#include <ctype.h>
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <fcntl.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include "ui-out.h"
+#include "arch-utils.h"
+#include "block.h"
+#include "breakpoint.h"
+#include "cli/cli-decode.h"
+#include "cli/cli-script.h"
+#include "command.h"
+#include "completer.h"
+#include "dictionary.h"
+#include "event-loop.h"
+#include "exceptions.h"
+#include "exec.h"
+#include "frame.h"
+#include "gdb.h"
+#include "gdb_assert.h"
+#include "gdbcmd.h"
+#include "gdbcore.h"
+#include "gdbthread.h"
+#include "gdbtypes.h"
+#include "inferior.h"
+#include "objfiles.h"
+#include "observer.h"
+#include "regcache.h"
+#include "solib.h"
+#include "solist.h"
+#include "symtab.h"
+#include "target.h"
+
+#include "bfd.h"
+#include "libbfd.h"
+#include "elf-bfd.h"
+
+#include "linux-awareness.h"
+
+static int r32, r38, r48;
+
+/*************************** Copied from breakpoint.c *************************/
+
+extern struct breakpoint *breakpoint_chain;
+extern int breakpoint_count;
+
+struct breakpoint *set_raw_breakpoint (struct symtab_and_line, enum bptype);
+void set_breakpoint_count (int);
+
+#define ALL_BREAKPOINTS(B)  for (B = breakpoint_chain; B; B = B->next)
+
+#define ALL_BREAKPOINTS_SAFE(B,TMP)	\
+	for (B = breakpoint_chain;	\
+	     B ? (TMP=B->next, 1): 0;	\
+	     B = TMP)
+
+static int
+breakpoint_enabled (struct breakpoint *b)
+{
+  return (b->enable_state == bp_enabled);
+}
+
+/******************************************************************************/
+
+enum kernel_autodetection {
+    NOT_LINUX,
+    LINUX_WITHOUT_DEBUGINFO,
+    LINUX_WITH_DEBUGINFO
+};
+
+enum stlinux_version detected_version;
+
+struct linux_awareness_ops *linux_awareness_ops;
+
+static char **module_search_path;
+static char **target_root_prefix;
+
+static char *utsname_release;
+struct depmod_cache {
+    char *filename;
+    char *modname; /* points into filename */
+};
+static struct depmod_cache *depmod_cache;
+static int    depmod_cache_length, depmod_cache_capacity;
+static time_t depmod_cache_timestamp;
+
+static char linux_awareness_doc[] = "";
+
+struct target_ops linux_aware_ops;
+
+struct target_so_ops linux_aware_so_ops;
+
+static int use_linux_awareness;
+
+static int loaded;
+static int enable_vm_translation = 1;
+static int enable_task_awareness = 1;
+static int linux_awareness_auto_activate_p = 1;
+static int auto_debug_process = 1;
+static unsigned int log_chunk_size = 128;
+static int stick_to_kernelspace;
+
+static CORE_ADDR singlestep_dest = ~(CORE_ADDR)0;
+static ptid_t singlestep_ptid;
+static CORE_ADDR saved_singlestep_dest;
+static ptid_t saved_singlestep_ptid;
+static CORE_ADDR normal_stop_pc;
+static CORE_ADDR normal_stop_sp;
+static int normal_stop_preempt_count;
+
+static int waiting_on_bp;
+static struct breakpoint *step_bp;
+static int force_hw_singlestep;
+
+static ptid_t current_ptid;
+static int    running;
+static int    seen_module_unload;
+
+static CORE_ADDR disable_breakpoint_at_pc;
+
+static int _inhibit_thread_register_awareness;
+
+struct cmd_list_element *set_linux_awareness_cmd_list;
+struct cmd_list_element *show_linux_awareness_cmd_list;
+
+static int global_loglevel;
+struct debug_domain linux_aware_debug_domains_info[] = {
+    { "debug-vm", 0 },
+    { "debug-task", 0 },
+    { "debug-module", 0 },
+    { "debug-target", 0 },
+    { "debug-init", 0 },
+    { "debug-user", 0 },
+    { NULL, 0 }
+};
+
+struct field_info *field_info;
+struct addr_info *addr_info;
+
+DECLARE_ADDR(module_finalize);
+DECLARE_ADDR(module_arch_cleanup);
+DECLARE_ADDR(modules);
+DECLARE_ADDR(init_task);
+DECLARE_ADDR(do_exit);
+DECLARE_ADDR(try_to_unmap);
+DECLARE_ADDR(search_binary_handler);
+DECLARE_ADDR(log_end);
+DECLARE_ADDR(log_start);
+DECLARE_ADDR(log_buf_len);
+DECLARE_ADDR(__log_buf);
+DECLARE_ADDR(shm_ids);
+DECLARE_ADDR(sem_ids);
+DECLARE_ADDR(msg_ids);
+DECLARE_ADDR(ioport_resource);
+DECLARE_ADDR(iomem_resource);
+DECLARE_ADDR(linux_banner);
+DECLARE_ADDR(saved_command_line);
+DECLARE_ADDR(totalram_pages);
+DECLARE_ADDR(pgdat_list);
+DECLARE_ADDR(contig_page_data);
+DECLARE_ADDR(all_bdevs);
+DECLARE_ADDR(swapper_space);
+DECLARE_ADDR(nr_swap_pages);
+DECLARE_ADDR(totalswap_pages);
+DECLARE_ADDR(nr_swapfiles);
+DECLARE_ADDR(swap_info);
+DECLARE_ADDR(per_cpu__page_states);
+DECLARE_ADDR(totalhigh_pages);
+DECLARE_ADDR(nr_pagecache);
+DECLARE_ADDR(vm_committed_space);
+DECLARE_ADDR(sysctl_overcommit_ratio);
+DECLARE_ADDR(vmlist);
+DECLARE_ADDR(nr_huge_pages);
+DECLARE_ADDR(last_pid);
+DECLARE_ADDR(system_utsname);
+DECLARE_ADDR(init_uts_ns);
+DECLARE_ADDR(init_pid_ns);
+DECLARE_ADDR(vm_stat);
+
+/* Structure fields used by the generic part of the linux awareness layer. */
+DECLARE_FIELD(block_device,     bd_list);
+DECLARE_FIELD(block_device,     bd_inode);
+DECLARE_FIELD(dentry,           d_parent);
+DECLARE_FIELD(dentry,           d_name);
+DECLARE_FIELD(dentry,           d_flags);
+DECLARE_FIELD(Elf32_Ehdr,       e_shnum);
+DECLARE_FIELD(Elf32_Ehdr,       e_shstrndx);
+DECLARE_FIELD(Elf32_Shdr,       sh_addr);
+DECLARE_FIELD(Elf32_Shdr,       sh_name);
+DECLARE_FIELD(Elf32_Shdr,       sh_flags);
+DECLARE_FIELD(Elf32_Shdr,       sh_link);
+DECLARE_FIELD(Elf32_Shdr,       sh_type);
+DECLARE_FIELD(file,             f_dentry);
+DECLARE_FIELD(file,             f_path);
+DECLARE_FIELD(file_system_type, name);
+DECLARE_FIELD(inode,            i_mapping);
+DECLARE_FIELD(ipc_id_ary,       size);
+DECLARE_FIELD(ipc_id_ary,       p);
+DECLARE_FIELD(ipc_ids,          in_use);
+DECLARE_FIELD(ipc_ids,          entries);
+DECLARE_FIELD(ipc_namespace,    ids);
+DECLARE_FIELD(kern_ipc_perm,    deleted);
+DECLARE_FIELD(kern_ipc_perm,    key);
+DECLARE_FIELD(kern_ipc_perm,    uid);
+DECLARE_FIELD(kern_ipc_perm,    gid);
+DECLARE_FIELD(kern_ipc_perm,    cuid);
+DECLARE_FIELD(kern_ipc_perm,    cgid);
+DECLARE_FIELD(kern_ipc_perm,    mode);
+DECLARE_FIELD(kern_ipc_perm,    seq);
+DECLARE_FIELD(list_head,        next);
+DECLARE_FIELD(mm_struct,        mmap);
+DECLARE_FIELD(mm_struct,        arg_start);
+DECLARE_FIELD(mm_struct,        arg_end);
+DECLARE_FIELD(mm_struct,        env_start);
+DECLARE_FIELD(mm_struct,        env_end);
+DECLARE_FIELD(mnt_namespace,    list);
+DECLARE_FIELD(module,           list);
+DECLARE_FIELD(module,           name);
+DECLARE_FIELD(module,           init);
+DECLARE_FIELD(module,           module_init);
+DECLARE_FIELD(module,           module_core);
+DECLARE_FIELD(module,           init_size);
+DECLARE_FIELD(module,           core_size);
+DECLARE_FIELD(msg_queue,        q_cbytes);
+DECLARE_FIELD(msg_queue,        q_qnum);
+DECLARE_FIELD(namespace,        list);
+DECLARE_FIELD(nsproxy,          ipc_ns);
+DECLARE_FIELD(nsproxy,          mnt_ns);
+DECLARE_FIELD(new_utsname,      release);
+DECLARE_FIELD(page_state,       nr_dirty);
+DECLARE_FIELD(page_state,       nr_mapped);
+DECLARE_FIELD(page_state,       nr_writeback);
+DECLARE_FIELD(page_state,       nr_slab);
+DECLARE_FIELD(page_state,       nr_page_table_pages);
+DECLARE_FIELD(path,             dentry);
+DECLARE_FIELD(pglist_data,      node_zones);
+DECLARE_FIELD(pglist_data,      pgdat_next);
+DECLARE_FIELD(pid_namespace,    last_pid);
+DECLARE_FIELD(qstr,             len);
+DECLARE_FIELD(qstr,             name);
+DECLARE_FIELD(resource,         name);
+DECLARE_FIELD(resource,         start);
+DECLARE_FIELD(resource,         end);
+DECLARE_FIELD(resource,         parent);
+DECLARE_FIELD(resource,         child);
+DECLARE_FIELD(resource,         sibling);
+DECLARE_FIELD(sem_array,        sem_nsems);
+DECLARE_FIELD(shmid_kernel,     shm_nattch);
+DECLARE_FIELD(shmid_kernel,     shm_segsz);
+DECLARE_FIELD(super_block,      s_type);
+DECLARE_FIELD(super_block,      s_flags);
+DECLARE_FIELD(swap_info_struct, flags);
+DECLARE_FIELD(swap_info_struct, inuse_pages);
+DECLARE_FIELD(task_struct,      mm);
+DECLARE_FIELD(task_struct,      children);
+DECLARE_FIELD(task_struct,      sibling);
+DECLARE_FIELD(task_struct,      pid);
+DECLARE_FIELD(task_struct,      tgid);
+DECLARE_FIELD(task_struct,      comm);
+DECLARE_FIELD(task_struct,      namespace);
+DECLARE_FIELD(task_struct,      nsproxy);
+DECLARE_FIELD(task_struct,      prio);
+DECLARE_FIELD(thread_info,      preempt_count);
+DECLARE_FIELD(uts_namespace,    name);
+DECLARE_FIELD(vm_area_struct,   vm_next);
+DECLARE_FIELD(vm_area_struct,   vm_file);
+DECLARE_FIELD(vm_area_struct,   vm_flags);
+DECLARE_FIELD(vm_area_struct,   vm_start);
+DECLARE_FIELD(vm_area_struct,   vm_end);
+DECLARE_FIELD(vm_area_struct,   vm_pgoff);
+DECLARE_FIELD(vm_struct,        next);
+DECLARE_FIELD(vm_struct,        size);
+DECLARE_FIELD(vfsmount,         mnt_list);
+DECLARE_FIELD(vfsmount,         mnt_parent);
+DECLARE_FIELD(vfsmount,         mnt_devname);
+DECLARE_FIELD(vfsmount,         mnt_mountpoint);
+DECLARE_FIELD(vfsmount,         mnt_flags);
+DECLARE_FIELD(vfsmount,         mnt_sb);
+DECLARE_FIELD(zone,             free_pages);
+DECLARE_FIELD(zone,             nr_active);
+DECLARE_FIELD(zone,             nr_inactive);
+
+/* Data which we have to change only when the image changes */
+
+static int init_module_return_resolved;
+
+/* solib emulation data */
+
+static struct breakpoint *shlib_event_load_bp;
+static struct breakpoint *shlib_event_init_bp;
+static struct breakpoint *shlib_event_free_bp;
+static struct breakpoint *thread_event_do_exit_bp;
+static struct breakpoint *thread_event_low_mem_bp;
+static struct breakpoint *thread_event_do_exec_bp;
+static struct breakpoint *thread_event_do_exec_return_bp;
+
+static struct observer *normal_stop_observer;
+
+struct lm_info {
+    char module_name[SO_NAME_MAX_PATH_SIZE];
+    CORE_ADDR this_module;
+    CORE_ADDR init;
+    CORE_ADDR module_init;
+    CORE_ADDR module_core;
+    ULONGEST  init_size;
+    ULONGEST  core_size;
+
+    ULONGEST  computed_core_size;
+    ULONGEST  computed_init_size;
+    int needs_relocated_file;
+
+    char *real_file;
+    char *relocated_file;
+
+    unsigned int shnum;
+    struct {
+	unsigned int nameidx;
+	char name[32];
+	CORE_ADDR addr;
+    } * sections;
+
+    int so_list_updated;
+    struct so_list *mod;
+};
+
+struct lm_info_list {
+    struct lm_info *info;
+    struct lm_info_list *next;
+};
+
+struct lm_info_list *lm_infos;
+struct lm_info *last_loaded;
+
+struct module_bfd_copy_info {
+    bfd             *old;
+    bfd             *new;
+    struct lm_info  *lm_info;
+    asection       **sec_mapping;
+};
+
+struct translation_info {
+    CORE_ADDR *addr;
+    CORE_ADDR task_struct;
+};
+
+static CORE_ADDR last_warned;
+
+static int last_pid;
+static int thread_list_needs_clearing;
+
+struct process {
+    struct process *next;
+    CORE_ADDR       task_struct_address;
+    unsigned int    pid;
+    unsigned int    tgid;
+    unsigned int    prio;
+    CORE_ADDR       mm;
+    char          *comm;
+} *processes = NULL;
+
+struct debugged_user_process {
+    struct debugged_user_process *next;
+
+    int             pid;
+    int             tgid;
+    int             gdb_thread_id;
+    CORE_ADDR       task_struct_address;
+    struct objfile *objfiles;
+    struct objfile *main_objfile;
+};
+
+struct waited_exe {
+    struct waited_exe   *next;
+    char                *name;
+    struct command_line *cmds;
+};
+
+static const struct objfile_data *linux_user_process_objfile_data_key;
+static int has_userspace_breakpoint;
+struct debugged_user_process *user_processes;
+struct debugged_user_process *current_user_process;
+struct process *current_process;
+
+struct waited_exe *waited_exes;
+
+static const char *fallback_tmpdirs[] = { "/tmp", "/var/tmp", "." };
+static const char *tmpdir = NULL;
+
+static unsigned int resetting_bps_after_init;
+static enum kernel_autodetection autodetection = NOT_LINUX;
+
+static void (*deprecated_call_command_chain) (struct cmd_list_element *c,
+					      char *cmd, int from_tty);
+static void (*deprecated_create_breakpoint_chain) (struct breakpoint *bpt);
+static void (*deprecated_delete_breakpoint_chain) (struct breakpoint *bpt);
+static void (*deprecated_context_chain) (int id);
+
+static void thread_list_clear_cache ();
+static CORE_ADDR get_current_task_struct ();
+static void delete_temp_files ();
+static struct process* thread_list_contains_pid (unsigned int pid);
+static void linux_aware_objfile_relocate (struct objfile *objfile,
+					  CORE_ADDR init_start,
+					  CORE_ADDR init_end,
+					  CORE_ADDR core_start,
+					  CORE_ADDR core_end);
+
+static void normal_stop_callback (struct bpstats *bs);
+
+static int linux_aware_software_single_step  (struct frame_info *frame);
+
+static void switch_to_user_process (struct process *ps);
+static void delete_user_process (int thread_id);
+static void debug_process_command (char *args, int from_tty);
+
+static struct process *get_gdb_process ();
+
+struct monitored_page;
+static void add_bpt_to_monitored_page (struct monitored_page *page,
+				       struct breakpoint *bpt);
+static struct monitored_page *find_monitored_page (CORE_ADDR addr);
+static struct monitored_page *create_monitored_page (CORE_ADDR addr,
+						     struct breakpoint *bp);
+static char *read_dentry (CORE_ADDR dentry);
+static void check_exec_actions();
+
+int
+linux_init_addr (struct addr_info *addr, int check)
+{
+    if (addr->sym)
+	return 1;
+
+    addr->sym = lookup_minimal_symbol (addr->name, NULL, NULL);
+
+    if (addr->sym) {
+	DEBUG (INIT, 2, "Checking for address of '%s' : OK\n", addr->name);
+    } else {
+	DEBUG (INIT, 1, "Checking for address of '%s' : NOT FOUND\n",
+	       addr->name);
+	if (!check)
+	    error ("Couldn't find address of %s", addr->name);
+	return 0;
+    }
+
+    /* Chain initialized entries for cleanup. */
+    addr->next = addr_info;
+    addr_info = addr;
+
+    DEBUG (INIT, 2, "%s address is %s\n", addr->name,
+	   paddr (SYMBOL_VALUE_ADDRESS(addr->sym)));
+    return 1;
+}
+
+static int
+find_struct_field (struct type *type, char *field, int *offset, int *size)
+{
+    int i;
+
+    for (i=0; i<TYPE_NFIELDS (type); ++i) {
+	if (! strcmp(FIELD_NAME (TYPE_FIELDS (type)[i]), field))
+	    break;
+    }
+
+    if (i >= TYPE_NFIELDS (type))
+	return 0;
+
+    *offset = FIELD_BITPOS (TYPE_FIELDS (type)[i])/TARGET_CHAR_BIT;
+    *size = TYPE_LENGTH (check_typedef (TYPE_FIELDS (type)[i].type));
+    return 1;
+}
+
+int
+linux_init_field (struct field_info *field, int check)
+{
+    if (field->type != NULL)
+	return 1;
+
+    field->type = lookup_symbol (field->struct_name,
+				 NULL, STRUCT_DOMAIN, 0, NULL);
+    if (field->type) {
+	DEBUG (INIT, 2, "Checking for 'struct %s' : OK\n",
+	       field->struct_name);
+    } else {
+	field->type = lookup_symbol (field->struct_name,
+				     NULL, VAR_DOMAIN, 0, NULL);
+
+	if (field->type
+	    && TYPE_CODE(check_typedef(SYMBOL_TYPE(field->type)))
+	         != TYPE_CODE_STRUCT)
+	    field->type = NULL;
+
+	if (field->type != NULL)
+	    DEBUG (INIT, 2, "Checking for 'struct %s' : TYPEDEF\n",
+		   field->struct_name);
+	else
+	    DEBUG (INIT, 1, "Checking for 'struct %s' : NOT FOUND\n",
+		   field->struct_name);
+    }
+
+    if (field->type == NULL
+	|| !find_struct_field (check_typedef(SYMBOL_TYPE (field->type)),
+			       field->field_name,
+			       &field->offset, &field->size)) {
+	field->type = NULL;
+	if (!check)
+	    error ("No such field %s::%s\n", field->struct_name,
+		   field->field_name);
+
+	return 0;
+    }
+
+    /* Chain initialized entries for cleanup. */
+    field->next = field_info;
+    field_info = field;
+
+    DEBUG (INIT, 2, "%s::%s => offset %i  size %i\n", field->struct_name,
+	   field->field_name, field->offset, field->size);
+    return 1;
+}
+
+static void
+fields_and_addrs_clear ()
+{
+    struct field_info *next_field = field_info;
+    struct addr_info *next_addr = addr_info;
+
+    while (next_field) {
+	next_field = field_info->next;
+	field_info->type = NULL;
+	field_info->next = NULL;
+	field_info = next_field;
+    }
+
+    while (next_addr) {
+	next_addr = addr_info->next;
+	addr_info->sym = NULL;
+	addr_info->next = NULL;
+	addr_info = next_addr;
+    }
+}
+
+static int
+thread_awareness_inhibited ()
+{
+    return !enable_task_awareness || _inhibit_thread_register_awareness;
+}
+
+static void
+thread_awareness_inhibit ()
+{
+    ++_inhibit_thread_register_awareness;
+}
+
+static void
+thread_awareness_exhibit ()
+{
+    --_inhibit_thread_register_awareness;
+}
+
+static ptid_t
+linux_aware_pid_to_ptid (int pid)
+{
+    return ptid_build (pid, 1, 1);
+}
+
+static int
+translate_memory_address_safe (CORE_ADDR *addr, int silent)
+{
+    if (!enable_vm_translation)
+	return 1;
+
+    if (!linux_awareness_ops->lo_address_needs_translation (*addr))
+	return 1;
+
+    {
+	CORE_ADDR saved_addr = *addr;
+	CORE_ADDR task_struct = get_current_task_struct ();
+	CORE_ADDR page = *addr & ~((1<<linux_awareness_ops->page_shift)-1);
+	enum page_status res;
+
+	thread_awareness_inhibit();
+	res = linux_awareness_ops->lo_translate_memory_address (addr,
+								task_struct);
+	thread_awareness_exhibit();
+
+	if (res == PAGE_PRESENT)
+	    return 1;
+
+	if (! silent
+	    && last_warned != page) {
+	    printf_filtered("Error translating memory addresses: ");
+	    switch (res) {
+	    case PAGE_SWAPPED:
+		printf_filtered("page 0x%s is swapped out.\n", paddr (page));
+		break;
+	    case PAGE_NOTMAPPED:
+		printf_filtered("page 0x%s is not mapped to memory.\n",
+				paddr (page));
+		break;
+	    case PAGE_NOPAGE:
+		printf_filtered("page 0x%s is not allocated yet.\n",
+				paddr (page));
+		break;
+	    case PAGE_UNKNOWN:
+		printf_filtered("Error walking page tables for page 0x%s.\n",
+				paddr (page));
+		break;
+	    default:
+		printf_filtered("Unexpected return value for page 0x%s.\n",
+				paddr (page));
+		break;
+	    }
+	    last_warned = page;
+	}
+
+	*addr = saved_addr;
+    }
+
+    return 0;
+}
+
+static int
+page_writable (CORE_ADDR addr)
+{
+    if (!enable_vm_translation)
+	return 1;
+
+    return linux_awareness_ops->lo_can_write (addr, get_current_task_struct ());
+}
+
+
+
+static void
+get_module_section_layout (struct lm_info *info,
+			   CORE_ADDR hdr, CORE_ADDR sechdrs)
+{
+    unsigned int i;
+    unsigned int shnum;
+    unsigned int stridx;
+    unsigned int sec_size;
+    CORE_ADDR sechdr;
+    CORE_ADDR strtab = 0;
+    CORE_ADDR strsize = 0;
+    struct field_info *sec_field = &FIELD_INFO(Elf32_Shdr,sh_addr);
+
+    if (sec_field->type == NULL)
+	linux_init_field (sec_field, 0);
+
+    sec_size = TYPE_LENGTH(check_typedef(SYMBOL_TYPE(sec_field->type)));
+    shnum = read_unsigned_field (hdr, Elf32_Ehdr, e_shnum);
+    info->shnum = shnum;
+    info->sections = xcalloc(sizeof(info->sections[0]), shnum);
+
+    stridx = read_unsigned_field (hdr, Elf32_Ehdr, e_shstrndx);
+    strtab = read_unsigned_field (sechdrs + stridx*sec_size,
+				  Elf32_Shdr, sh_addr);
+    sechdr = sechdrs;
+    for (i = 0; i < shnum; ++i, sechdr += sec_size) {
+	unsigned int type = read_unsigned_field (sechdr, Elf32_Shdr, sh_type);
+	unsigned int flags;
+
+	if (type == SHT_SYMTAB || type == SHT_STRTAB)
+	    continue; // Do nothing
+
+	flags = read_unsigned_field (sechdr, Elf32_Shdr, sh_flags);
+	if (flags & SHF_ALLOC) {
+	    info->sections[i].nameidx = read_unsigned_field (sechdr,
+							     Elf32_Shdr,
+							     sh_name);
+	    info->sections[i].addr = read_unsigned_field (sechdr,
+							  Elf32_Shdr, sh_addr);
+	}
+    }
+
+    for (i = 0; i < shnum; ++i) {
+	if (info->sections[i].addr == 0)
+	    continue;
+
+	read_memory (strtab + info->sections[i].nameidx,
+		     info->sections[i].name, 32);
+    }
+}
+
+
+/*****************************************************************************/
+/*               Copied and adapted from kernel/module.c                     */
+/*****************************************************************************/
+
+#define ALIGN(x,a) (((x)+(a)-1)&~((a)-1))
+
+/* Update size with this section: return offset. */
+static long
+get_offset (unsigned long *size, Elf_Internal_Shdr *sechdr)
+{
+	long ret;
+
+	ret = ALIGN (*size, sechdr->sh_addralign ?: 1);
+	*size = ret + sechdr->sh_size;
+	return ret;
+}
+
+/* This isn't true for ia64 and alpha. But we don't care... */
+#define ARCH_SHF_SMALL 0
+
+/* We reproduce the layout algorithm used by the kernel for the
+   module sections.  If we find that our sizes differ from the one
+   stored within the kernel memory, we try to read the layout from
+   there.  This is usefull if you point your debugger to a module
+   with debug info, but you load the same module with the debug info
+   stripped (stripping the debug info will reduce the size of loaded
+   sections like .strtab).  We don't systematically load the layout
+   from memory as it's simply too slow. */
+static void
+layout_sections (bfd* file, struct lm_info *lm_info)
+{
+    static unsigned long const masks[][2] = {
+	/* NOTE: all executable code must be the first section
+	 * in this array; otherwise modify the text_size
+	 * finder in the two loops below */
+	{ SHF_EXECINSTR | SHF_ALLOC, ARCH_SHF_SMALL },
+	{ SHF_ALLOC, SHF_WRITE | ARCH_SHF_SMALL },
+	{ SHF_WRITE | SHF_ALLOC, ARCH_SHF_SMALL },
+	{ ARCH_SHF_SMALL | SHF_ALLOC, 0 }
+    };
+    unsigned int m, i;
+
+    unsigned long core_size = 0;
+    unsigned long init_size = 0;
+    unsigned int sec_count = file->section_count;
+    asection *bfd_sec;
+    Elf_Internal_Shdr **sechdrs = elf_elfsections (file);
+    Elf_Internal_Ehdr *hdr = elf_elfheader (file);
+
+    unsigned long *offsets = alloca(hdr->e_shnum * sizeof (unsigned long));
+    memset (offsets, 0xFF, hdr->e_shnum * sizeof (unsigned long));
+
+    /* Is this kosher ? Maybe we should copy the flags in a local
+       array before we modify these. */
+    for (i = 0; i < hdr->e_shnum; ++i) {
+	Elf_Internal_Shdr *s = sechdrs[i];
+	int ix = elf_elfheader(file)->e_shstrndx;
+	char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+
+	if (! strcmp (name, ".modinfo"))
+	    s->sh_flags &= ~SHF_ALLOC;
+	else if (! strcmp (name, ".symtab"))
+	    s->sh_flags |= SHF_ALLOC;
+	else if (! strcmp (name, ".strtab"))
+	    s->sh_flags |= SHF_ALLOC;
+    }
+
+    DEBUG (MODULE, 4, "Core section allocation\n");
+    for (m = 0; m < ARRAY_SIZE (masks); ++m) {
+	for (i = 0; i < hdr->e_shnum; ++i) {
+	    Elf_Internal_Shdr *s = sechdrs[i];
+	    int ix = elf_elfheader(file)->e_shstrndx;
+	    char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+
+	    if ((s->sh_flags & masks[m][0]) != masks[m][0]
+		|| (s->sh_flags & masks[m][1])
+		|| offsets[i] != ~0UL
+		|| strncmp (name, ".init", 5) == 0)
+		continue;
+	    offsets[i] = get_offset (&core_size, s) + lm_info->module_core;
+	}
+    }
+
+    lm_info->computed_core_size = core_size;
+
+    DEBUG (MODULE, 4, "Init section allocation\n");
+    for (m = 0; m < ARRAY_SIZE(masks); ++m) {
+	for (i = 0; i < hdr->e_shnum; ++i) {
+	    Elf_Internal_Shdr *s = sechdrs[i];
+	    int ix = elf_elfheader(file)->e_shstrndx;
+	    char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+	    if ((s->sh_flags & masks[m][0]) != masks[m][0]
+		|| (s->sh_flags & masks[m][1])
+		|| offsets[i] != ~0UL
+		|| strncmp(name, ".init", 5) != 0)
+		continue;
+	    offsets[i] = get_offset(&init_size, s) + lm_info->module_init;
+	}
+    }
+
+    lm_info->computed_init_size = init_size;
+
+    if (lm_info->computed_core_size != lm_info->core_size) {
+	CORE_ADDR current_pc = read_pc ();
+
+	if (shlib_event_load_bp != NULL
+	    && current_pc == shlib_event_load_bp->loc->address
+	    && last_loaded == lm_info) {
+	    CORE_ADDR elf_hdr, elf_sechdrs, ptr;
+
+	    printf_filtered ("\
+The module loaded by the kernel hasn't the same sections as the module\n\
+the debugger has opened. Reading the section layout from kernel memory.\n");
+
+	    elf_hdr = linux_awareness_ops->lo_first_pointer_arg_value ();
+	    elf_sechdrs = linux_awareness_ops->lo_second_pointer_arg_value ();
+	    ptr = linux_awareness_ops->lo_third_pointer_arg_value ();
+
+	    get_module_section_layout (lm_info, elf_hdr, elf_sechdrs);
+	} else {
+	    warning("\
+The module loaded by the kernel hasn't the same sections as the\n\
+module the debugger has opened. Unfortunately the section layout isn't\n\
+available anymore in the kernel's memory. The debugger has to be active at\n\
+module load time to handle such cacses.");
+	}
+    } else {
+	lm_info->shnum = hdr->e_shnum;
+	lm_info->sections = xcalloc(sizeof(lm_info->sections[0]), hdr->e_shnum);
+
+	for (i = 0; i < hdr->e_shnum; ++i) {
+	    Elf_Internal_Shdr *s = sechdrs[i];
+	    int ix = elf_elfheader(file)->e_shstrndx;
+	    char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+	    if (offsets[i] != ~0UL) {
+		lm_info->sections[i].addr = offsets[i];
+		strncpy(lm_info->sections[i].name, name, 32);
+	    }
+	}
+    }
+
+    DEBUG (MODULE, 4, "Remapping on BFD section:\n");
+    for (i = 0; i < hdr->e_shnum; ++i) {
+	Elf_Internal_Shdr *s = sechdrs[i];
+	int ix = elf_elfheader(file)->e_shstrndx;
+	char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+	asection* sect = bfd_get_section_by_name (file, name);
+
+	if (sect == NULL || offsets[i] == ~0UL)
+	    continue;
+
+	if (strncmp (sect->name, ".init.", 6) == 0
+	    || strncmp (sect->name, ".exit.", 6) == 0)
+	    lm_info->needs_relocated_file = 1;
+	else if (strcmp (name, ".strtab") == 0
+		 || strcmp (name, ".symtab") == 0)
+	    s->sh_flags &= ~SHF_ALLOC;
+    }
+}
+
+/****************************************************************************/
+
+static struct bp_location *
+bp_location_from_shadow_contents(struct bp_target_info *info)
+{
+    struct bp_location *bp_loc;
+
+    if (singlestep_dest == info->placed_address)
+	return NULL;
+
+    bp_loc = (struct bp_location *)((char*)info - offsetof(struct bp_location,
+							   target_info));
+    if (bp_loc->address != info->placed_address
+	|| bp_loc->requested_address != info->placed_address) {
+	warning ("Unknown bp location passed to target.");
+	return NULL;
+    }
+
+    return bp_loc;
+}
+
+static int
+linux_aware_insert_breakpoint (struct bp_target_info *info)
+{
+    struct bp_location *bp_loc;
+    ptid_t saved_ptid = inferior_ptid;
+    int res;
+    CORE_ADDR addr = info->placed_address;
+    bp_loc = bp_location_from_shadow_contents (info);
+    DEBUG (TARGET, 2,"inserting bp at 0x%x %s\n",
+	   (unsigned int)addr,
+	   bp_loc == NULL ? "(SS)" : "");
+
+    if (!loaded)
+	return linux_aware_ops.beneath->to_insert_breakpoint (info);
+
+    if (info->placed_address == ~(CORE_ADDR)0)
+	return 0;
+
+    if (disable_breakpoint_at_pc == addr) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    /* Choose the right inferior_ptid so that the address translation
+       works. */
+    if (bp_loc != NULL && bp_loc->owner->thread != -1) {
+	inferior_ptid = thread_id_to_pid(bp_loc->owner->thread);
+    } else if (bp_loc == NULL && info->placed_address == singlestep_dest) {
+	inferior_ptid = singlestep_ptid;
+    }
+
+    if (! translate_memory_address_safe (&addr, 1)) {
+	inferior_ptid = saved_ptid;
+	DEBUG (TARGET, 2,"error inserting bp at 0x%x\n", (unsigned int)addr);
+	return 1;
+    }
+
+    if (info->placed_address != addr) {
+	thread_awareness_inhibit();
+	linux_awareness_ops->lo_flush_cache (info->placed_address, addr, 2, 1);
+	DEBUG (TARGET, 2,"\t real addr 0x%x\n", (unsigned int)addr);
+    }
+
+    /* Pass translated address down, but keep original address in
+       info->placed_address */
+    {
+        CORE_ADDR saved_addr = info->placed_address;
+	info->placed_address = addr;
+        res = linux_aware_ops.beneath->to_insert_breakpoint (info);
+	info->placed_address = saved_addr;
+    }
+
+    if (info->placed_address != addr) {
+	linux_awareness_ops->lo_flush_cache (addr, addr, 2, 1);
+	thread_awareness_exhibit();
+    }
+
+    inferior_ptid = saved_ptid;
+    return res;
+}
+
+static int
+linux_aware_remove_breakpoint(struct bp_target_info *info)
+{
+    struct bp_location *bp_loc;
+    ptid_t saved_ptid = inferior_ptid;
+    int res;
+    CORE_ADDR addr = info->placed_address;
+    CORE_ADDR requested_addr = addr;
+    bp_loc = bp_location_from_shadow_contents (info);
+
+    DEBUG (TARGET, 2,"removing bp at 0x%x %s\n",
+	   (unsigned int)addr,
+	   bp_loc == NULL ? "(SS)" : "");
+
+    if (addr == ~(CORE_ADDR)0)
+	return 0;
+
+    if (disable_breakpoint_at_pc == addr) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    if (bp_loc != NULL && bp_loc->owner->thread != -1)
+	inferior_ptid = thread_id_to_pid (bp_loc->owner->thread);
+    else if (bp_loc == NULL
+	     && requested_addr == singlestep_dest)
+	inferior_ptid = singlestep_ptid;
+
+    if (! translate_memory_address_safe (&addr, 1)) {
+	DEBUG (TARGET, 2,"\tError translating address\n");
+	inferior_ptid = saved_ptid;
+
+	if (bp_loc != NULL
+	    && bp_loc->owner->thread != -1
+	    && linux_awareness_ops->lo_is_user_address (bp_loc->address)) {
+	    warning ("\
+The page containing breakpoint %i seems to have been unmapped from memory\n\
+You'll have to reset the breakpoint.", bp_loc->owner->number);
+	    disable_breakpoint (bp_loc->owner);
+	}
+
+	return 1;
+    }
+
+    if (requested_addr != addr) {
+	thread_awareness_inhibit();
+	linux_awareness_ops->lo_flush_cache (requested_addr, addr, 2, 1);
+	DEBUG (TARGET, 2,"\t real addr 0x%x\n", (unsigned int)addr);
+    }
+
+    /* Pass the translated address down, but keep the original value in
+       info->placed_address. */
+    {
+        CORE_ADDR saved_addr = info->placed_address;
+	info->placed_address = addr;
+        res = linux_aware_ops.beneath->to_remove_breakpoint (info);
+	info->placed_address = saved_addr;
+    }
+
+    if (requested_addr != addr) {
+	linux_awareness_ops->lo_flush_cache (addr, addr, 2, 1);
+	thread_awareness_exhibit();
+    }
+
+    inferior_ptid = saved_ptid;
+    return res;
+}
+
+static int
+linux_aware_insert_hw_breakpoint(struct bp_target_info *info)
+{
+    DEBUG (TARGET, 2,"inserting hw bp at 0x%x\n",
+    								(unsigned int)info->placed_address);
+
+    if (disable_breakpoint_at_pc == info->placed_address) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    return linux_aware_ops.beneath->to_insert_hw_breakpoint (info);
+}
+
+static int
+linux_aware_remove_hw_breakpoint(struct bp_target_info *info)
+{
+    DEBUG (TARGET, 2,"removing hw bp at 0x%x\n",
+    								(unsigned int)info->placed_address);
+
+    if (disable_breakpoint_at_pc == info->placed_address) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    return linux_aware_ops.beneath->to_remove_hw_breakpoint (info);
+}
+
+static void
+sanitize_target_root_prefix ()
+{
+    char *dir = *target_root_prefix + strlen (*target_root_prefix) - 1;
+    while (dir > *target_root_prefix && isspace (*dir)) {
+	*dir-- = '\0';
+    }
+}
+
+static CORE_ADDR cache_task_struct;
+static int cache_pid;
+static CORE_ADDR cache_start;
+static CORE_ADDR cache_end;
+static unsigned int cache_pgoff;
+static FILE *cached_file;
+
+static int
+read_from_file(CORE_ADDR file, CORE_ADDR start, unsigned int pgoffset,
+	       CORE_ADDR addr, int len, gdb_byte *myaddr, FILE *file_desc)
+{
+    char *filename;
+    unsigned int in_page_offset =  addr & ((1<<linux_awareness_ops->page_shift) - 1);
+    unsigned int page_len = (1<<linux_awareness_ops->page_shift) - in_page_offset;
+
+    pgoffset += (addr - start) >> linux_awareness_ops->page_shift;
+
+    if (file_desc == NULL) {
+	CORE_ADDR dentry;
+
+	if (detected_version >= V2_6_23)
+	    dentry = read_pointer_embedded_field(file,
+						 path, dentry,
+						 file, f_path);
+	else
+	    dentry = read_pointer_field (file, file, f_dentry);
+	filename = read_dentry (dentry);
+
+	if (filename == NULL)
+	    return -1;
+
+	filename = xrealloc (filename,
+			     strlen (filename) + strlen (*target_root_prefix) + 1);
+	memmove (filename + strlen (*target_root_prefix),
+		 filename,
+		 strlen (filename)+1);
+	memcpy (filename, *target_root_prefix, strlen(*target_root_prefix));
+
+	DEBUG(VM, 2 , "Trying to read %s from %s\n", paddr (addr), filename);
+
+	file_desc = fopen (filename, "r");
+	xfree (filename);
+
+	if (file_desc == NULL)
+	    return -1;
+    }
+
+    /* Never cross a page boundary.  */
+    len = len > page_len ? page_len : len;
+
+    if (fseek(file_desc, in_page_offset + pgoffset*(1<<linux_awareness_ops->page_shift), SEEK_SET)) {
+	fclose(file_desc);
+	return -1;
+    }
+
+    if ((len = fread(myaddr, len, 1, file_desc)) <= 0) {
+	fclose(file_desc);
+	return -1;
+    }
+
+    if (cached_file != NULL
+	&& cached_file != file_desc) {
+	fclose(cached_file);
+    }
+
+    cached_file = file_desc;
+    return len;
+}
+
+static int
+get_file_mapped_data(CORE_ADDR addr, gdb_byte *myaddr, int len)
+{
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task_struct = ps->task_struct_address;
+    enum page_status stat;
+    CORE_ADDR memaddr = addr;
+    CORE_ADDR mm, mmap;
+
+    if (cache_task_struct == task_struct
+	&& cache_pid == ps->pid
+	&& cache_start <= addr
+	&& cache_end > addr) {
+	int res;
+	res = read_from_file(0, cache_start, cache_pgoff, addr, len, myaddr, cached_file);
+	if (res < 0) {
+	    cache_task_struct = 0;
+	    cache_pid = 0;
+	    cache_start = 0;
+	    cache_end = 0;
+	    cached_file = NULL; /* fclosed by read_from_file.  */
+	}
+	return res;
+    }
+
+
+    stat = linux_awareness_ops->lo_translate_memory_address (&memaddr, task_struct);
+
+    sanitize_target_root_prefix();
+    if (**target_root_prefix == '\0')
+	return -1;
+
+    DEBUG(VM, 2 , "Looking if we can read %s from a file\n", paddr (addr));
+
+    if (stat != PAGE_NOPAGE && stat != PAGE_NOTMAPPED)
+	return -1;
+
+    mm = read_pointer_field (task_struct, task_struct, mm);
+
+    if (!mm)
+	/* Kernel thread maps file?!...  */
+	return -1;
+
+    mmap = read_pointer_field (mm, mm_struct, mmap);
+    while (mmap) {
+	CORE_ADDR file;
+
+#define VM_READ		0x00000001	/* currently active flags */
+#define VM_WRITE	0x00000002
+#define VM_EXEC		0x00000004
+#define VM_SHARED	0x00000008
+
+#define VM_MAYREAD	0x00000010	/* limits for mprotect() etc */
+#define VM_MAYWRITE	0x00000020
+#define VM_MAYEXEC	0x00000040
+#define VM_MAYSHARE	0x00000080
+
+#define VM_GROWSDOWN	0x00000100	/* general info on the segment */
+#define VM_GROWSUP	0x00000200
+
+	CORE_ADDR start, end;
+
+	start = read_pointer_field (mmap, vm_area_struct, vm_start);
+	end = read_pointer_field (mmap, vm_area_struct, vm_end);
+
+	if (start > addr
+	    || end <= addr) {
+	    mmap = read_pointer_field (mmap, vm_area_struct, vm_next);
+	    continue;
+	}
+
+	file = read_pointer_field (mmap, vm_area_struct, vm_file);
+
+	if (file) {
+	    int res;
+	    unsigned int pgoff = read_unsigned_field(mmap, vm_area_struct, vm_pgoff);
+	    res = read_from_file(file, start, pgoff, addr, len, myaddr, NULL);
+
+	    if (res > 0) {
+		cache_task_struct = task_struct;
+		cache_pid = ps->pid;
+		cache_start = start;
+		cache_end = end;
+		cache_pgoff = pgoff;
+	    }
+
+	    return res;
+	} else {
+	    return -1;
+	}
+#undef VM_READ
+#undef VM_WRITE
+#undef VM_EXEC
+#undef VM_SHARED
+
+#undef VM_MAYREAD
+#undef VM_MAYWRITE
+#undef VM_MAYEXEC
+#undef VM_MAYSHARE
+
+#undef VM_GROWSDOWN
+#undef VM_GROWSUP
+    }
+
+    return -1;
+}
+
+static int
+linux_aware_deprecated_xfer_memory (CORE_ADDR memaddr,
+				    gdb_byte *myaddr,
+				    int len, int write,
+				    struct mem_attrib *attrib,
+				    struct target_ops *target)
+{
+    int res = 0;
+    CORE_ADDR page_end, orig_addr = memaddr;
+    int page_incr = 1 << linux_awareness_ops->page_shift;
+
+    DEBUG (TARGET, 3,
+	   "linux_aware_deprecated_xfer_memory: %s %i bytes %s %s\n",
+	   (write ? "writing" : "reading"),
+	   len, (write ? "to" : "from"),
+	   paddr(memaddr));
+
+    if (!write && memaddr < 4096) {
+	memset (myaddr, 0, len);
+	return len;
+    }
+
+    if (loaded)
+	if (! translate_memory_address_safe (&memaddr, 1)) {
+
+	    if (!write) {
+		res = get_file_mapped_data(memaddr, myaddr, len);
+
+		if (res >= 0)
+		    return res;
+	    }
+
+	    /* Emit warnings now. This shouldn't be too wasteful if
+	       the target side does right caching.  */
+	    translate_memory_address_safe (&memaddr, 0);
+
+	    /* Don't report an error, but do what GDB would do on
+	       memory access error : read zero and do nothing on
+	       write. The error has been reported to the user. If we
+	       report an error, then the target beneath will be called
+	       and do uselss things. See target.c:target_xfer_memory */
+	    if (!write)
+		memset (myaddr, 0, len);
+
+	    return len;
+	}
+
+    /* Read at most one page. The underlying memory access code will
+       handle the loop for us. */
+    page_end = (orig_addr & ~(CORE_ADDR)(page_incr-1)) + page_incr;
+    len = min (len, page_end-orig_addr);
+
+    if (orig_addr != memaddr
+	&& (write || page_writable (orig_addr)))
+	linux_awareness_ops->lo_flush_cache (orig_addr, memaddr, len, write);
+
+    DEBUG (TARGET, 3,
+	   "linux_aware_deprecated_xfer_memory: really %s %i bytes %s %s\n",
+	   (write ? "writing" : "reading"),
+	   len, (write ? "to" : "from"),
+	   paddr(memaddr));
+
+    res = linux_aware_ops.beneath->deprecated_xfer_memory (memaddr, myaddr,
+							   len, write,
+							   attrib, target);
+    if (orig_addr != memaddr)
+	linux_awareness_ops->lo_flush_cache (memaddr, memaddr, len, write);
+    return res;
+}
+
+static void
+make_shlib_bps_pending ()
+{
+    struct breakpoint *bp;
+
+    ALL_BREAKPOINTS (bp)
+	if (bp->loc == NULL || bp->loc->shlib_disabled ) {
+	    bp->enable_state = bp_enabled;
+	} else if (bp->loc->address == ~(CORE_ADDR)0) {
+	    /* Here we totally disable the breakpoint. This is
+	       necessary for breakpoints in init sections: as long as
+	       the corresponding module stays loaded, the debug info
+	       is still present (mangled to ~(CORE_ADDR)0, but still
+	       present). With the debug info present, each module load
+	       will cause the pending breakpoint to be resolved and
+	       will print misleading messages.
+
+	       The breakpoints get re-enabled when their
+	       corresponding module is loaded again. See _wait()
+	       function. */
+	    bp->enable_state = bp_disabled;
+	}
+}
+
+static void
+disable_userspace_breakpoints ()
+{
+    struct breakpoint *bp;
+    int disabled = 0;
+
+    ALL_BREAKPOINTS (bp)
+	if (bp->loc
+	    && bp->enable_state == bp_enabled
+	    && bp->loc->loc_type == bp_loc_software_breakpoint
+	    && linux_awareness_ops->lo_is_user_address (bp->loc->address)) {
+	    bp->enable_state = bp_disabled;
+	    ++disabled;
+	}
+
+    if (disabled)
+	warning("\
+Your target system is getting low on memory. Userspace debugging will\n\
+become unreliable due to code memory getting unmapped. All the userspace\n\
+breakpoints have been disabled.");
+}
+
+static void
+linux_aware_resume (ptid_t pid, int step, enum target_signal sig)
+{
+    DEBUG (TARGET, 1,"Resuming %i with sig %i (step %i)\n",
+	   (int)ptid_get_pid(pid), (int)sig, step);
+
+    if (linux_awareness_ops->lo_pre_exec_start) {
+	thread_awareness_inhibit ();
+	linux_awareness_ops->lo_pre_exec_start ();
+	thread_awareness_exhibit ();
+    }
+    if (!loaded)
+	return linux_aware_ops.beneath->to_resume (pid, step, sig);
+
+    if (seen_module_unload) {
+	seen_module_unload = 0;
+	make_shlib_bps_pending();
+    }
+
+/*     if (!step_bp && saved_singlestep_dest */
+/* 	&& !force_hw_singlestep && singlestep_dest == ~(CORE_ADDR)0) { */
+/* 	ptid_t saved_ptid = inferior_ptid; */
+/* 	/\* The debugger thinks it just needs to continue, it has */
+/* 	   forgotten about the ongoing step.  Force the singlestep bp */
+/* 	   insertion.  *\/ */
+
+/* 	struct symtab_and_line sr_sal; */
+/* 	inferior_ptid = saved_singlestep_ptid; */
+/* 	step_bp = create_thread_event_breakpoint(saved_singlestep_dest); */
+/* 	step_bp->thread = pid_to_thread_id(saved_singlestep_ptid); */
+/* 	if (!step_bp->loc->duplicate) { */
+/* 	    *target_insert_breakpoint(&step_bp->loc->target_info); */
+/* 	    step_bp->loc->inserted = 1; */
+/* 	} */
+/* 	inferior_ptid = saved_ptid; */
+/*     } */
+
+    if (!force_hw_singlestep || waiting_on_bp) {
+	if (!has_userspace_breakpoint
+	    && thread_list_needs_clearing
+	    && thread_event_do_exit_bp != NULL) {
+	    delete_breakpoint(thread_event_do_exit_bp);
+	    thread_event_do_exit_bp = NULL;
+	}
+
+	if (thread_list_needs_clearing)
+	    thread_list_clear_cache ();
+
+	thread_awareness_inhibit ();
+	linux_awareness_ops->lo_clear_cache ();
+	thread_awareness_exhibit ();
+    }
+
+    stick_to_kernelspace = 0;
+    last_warned = (CORE_ADDR)-1;
+
+    /* Forget about normal_stop_pc, it should just be used for the
+       initial step from a bp.  */
+    normal_stop_pc = 0;
+    running = 1;
+
+    if ( step
+	|| (force_hw_singlestep && !waiting_on_bp)) {
+	DEBUG (TARGET, 1,"Really singlesteping\n");
+	linux_aware_ops.beneath->to_resume (pid_to_ptid (-1), 1, TARGET_SIGNAL_0);
+    } else {
+	linux_aware_ops.beneath->to_resume (pid_to_ptid (-1), 0, TARGET_SIGNAL_0);
+    }
+
+    force_hw_singlestep = 0;
+}
+
+static void
+linux_aware_load (char *prog, int fromtty) {
+
+    DEBUG (TARGET, 3,"linux_aware_load %s\n", prog);
+    /* Force the loaded variable to 0 before load, so that the user
+       can't crash the debugger by putting 'set linux-awareness loaded
+       1' in his .shgdbinit file */
+    loaded = 0;
+    if (linux_awareness_ops->lo_pre_load)
+	linux_awareness_ops->lo_pre_load(prog, fromtty);
+    linux_aware_ops.beneath->to_load (prog, fromtty);
+    if (linux_awareness_ops->lo_post_load)
+	linux_awareness_ops->lo_post_load(prog, fromtty);
+    loaded = 1;
+
+    DEBUG (TARGET, 3,"end linux_aware_load %s\n", prog);
+}
+
+static void
+linux_aware_attach (char *prog, int fromtty) {
+
+    DEBUG (TARGET, 3,"linux_aware_attach %s\n", prog);
+
+    if (linux_aware_ops.beneath
+	&& linux_aware_ops.beneath->to_attach != NULL
+	&& linux_aware_ops.beneath->to_attach != find_default_attach)
+	linux_aware_ops.beneath->to_attach (prog, fromtty);
+
+    loaded = 1;
+    DEBUG (TARGET, 3,"end linux_aware_attach %s\n", prog);
+}
+
+static int
+linux_aware_can_run () {
+
+    DEBUG (TARGET, 3,"linux_aware_can_run\n");
+    return (use_linux_awareness && loaded);
+}
+
+static CORE_ADDR
+get_module_section_addr (struct lm_info *info, const char *name)
+{
+    unsigned int i;
+
+    for (i = 0; i < info->shnum; ++i) {
+	if (strcmp (name, info->sections[i].name) == 0)
+	    return info->sections[i].addr;
+    }
+
+    return 0;
+}
+
+static void
+set_section_offsets (bfd *abfd, asection *sectp, void *dummy)
+{
+    struct lm_info *info = (struct lm_info *) dummy;
+    CORE_ADDR addr;
+
+    addr = get_module_section_addr (info, bfd_get_section_name (abfd, sectp));
+
+    if (addr != 0) {
+	DEBUG (MODULE, 2, "Setting vma of %s to %s\n",
+	       bfd_get_section_name (abfd, sectp), paddr(addr));
+
+	/*  We want the file we create to be totally relocated with a
+	    base address of 0. As info->module_core should be the
+	    smallest address, we substract it here. This way the
+	    module file we create looks like a real shared library to
+	    GDB, which just has to offset all the debug information by
+	    info->module_core. */
+	bfd_set_section_vma (abfd, sectp, addr - info->module_core);
+    }
+}
+
+static void
+create_sections (bfd *abfd, asection *sectp, void *i)
+{
+    struct module_bfd_copy_info *info = (struct module_bfd_copy_info *)i;
+    asection *sec;
+
+    flagword flags = bfd_get_section_flags (abfd, sectp);
+
+    if (! (flags & (SEC_ALLOC | SEC_DEBUGGING)))
+	return;
+
+    if (strcmp (bfd_get_section_name (abfd, sectp), ".modinfo") == 0)
+	return;
+
+    DEBUG (MODULE, 3, "Adding section %s to new file.\n",
+	   bfd_get_section_name (abfd, sectp));
+    sec = bfd_make_section (info->new, bfd_get_section_name (abfd, sectp));
+    /* We'll get rid of relocations. */
+    bfd_set_section_flags (info->new, sec, flags & ~SEC_RELOC);
+    bfd_set_section_vma (info->new, sec, bfd_get_section_vma(abfd, sectp));
+    bfd_set_section_alignment (info->new, sec,
+			       bfd_get_section_alignment (abfd, sectp));
+    bfd_set_section_size (info->new, sec, bfd_section_size (abfd, sectp));
+
+    info->sec_mapping[sectp->index] = sec;
+}
+
+static void
+create_symbols (struct module_bfd_copy_info *info)
+{
+    long storage_needed;
+    asymbol **symbol_table;
+    asymbol **new_symbol_table, *new_sym;
+    int cur_new_sym = 0;
+    long number_of_symbols;
+    long i;
+
+    storage_needed = bfd_get_symtab_upper_bound (info->old);
+    if (storage_needed < 0)
+	error ("Error reading old symtab.");
+
+    if (storage_needed == 0)
+	return;
+
+    symbol_table = xmalloc (storage_needed);
+    new_symbol_table = xmalloc (storage_needed);
+    memset (new_symbol_table, 0, storage_needed);
+
+    number_of_symbols = bfd_canonicalize_symtab (info->old, symbol_table);
+    if (number_of_symbols < 0)
+	error ("Error reading old symbols.");
+
+    for (i = 0; i < number_of_symbols; i++) {
+	asymbol* sym = symbol_table[i];
+
+	/* The section symbols will get recreated by the BFD. */
+	if (sym->flags & BSF_SECTION_SYM)
+	    continue;
+
+	      /* Skip names that don't exist (shouldn't happen), or names
+	         that are null strings (may happen). */
+	if (sym->name == NULL || *sym->name == '\0')
+	    continue;
+
+	if (sym->section == &bfd_und_section)
+	    continue;
+
+	if (info->sec_mapping[sym->section->index] == 0) {
+	    DEBUG (MODULE, 4,
+		   "Ignoring symbol %s because of missing section.\n",
+		   bfd_asymbol_name (sym));
+	    continue;
+	}
+
+	new_sym = bfd_make_empty_symbol (info->new);
+	new_symbol_table[cur_new_sym] = new_sym;
+	new_sym->name = bfd_asymbol_name (sym);
+	new_sym->section = info->sec_mapping[sym->section->index];
+	new_sym->flags = sym->flags;
+
+	/* The symbols already got their value offset by the section
+	   load address when we applied set_section_offsets on
+	   info->old. We will recreate a file were the sections will
+	   have the same load offsets, but we don't want this offset
+	   to be added twice. Thus we substract it here. */
+	new_sym->value = bfd_asymbol_value (sym) - bfd_get_section_vma(info->new, new_sym->section);
+
+	DEBUG (MODULE, 2, "Adding sym %s to new file with value 0x%s\n",
+	       new_symbol_table[cur_new_sym]->name,
+	       paddr (new_symbol_table[cur_new_sym]->value));
+
+	++cur_new_sym;
+    }
+
+    bfd_set_symtab (info->new, new_symbol_table, cur_new_sym);
+    xfree (symbol_table);
+}
+
+static void
+set_section_contents (bfd *abfd, asection *sectp, void *i)
+{
+    bfd_byte *buf;
+    struct cleanup *clean;
+    struct module_bfd_copy_info *info = (struct module_bfd_copy_info *)i;
+
+    if (info->sec_mapping[sectp->index] == 0)
+	return;
+
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_HAS_CONTENTS ))
+	return;
+
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_RELOC )
+	|| ! (bfd_get_section_flags (abfd, sectp) & SEC_DEBUGGING )) {
+
+	bfd_byte *buf = xmalloc (bfd_get_section_size (sectp));
+	struct cleanup *clean = make_cleanup (xfree, buf);
+	if (! bfd_get_section_contents (abfd, sectp,
+					buf, 0, bfd_get_section_size (sectp)))
+	    error ("Can't read non-relocated section contents.");
+
+	if (! bfd_set_section_contents (info->new,
+					info->sec_mapping[sectp->index],
+					buf,
+					0,
+					bfd_get_section_size (sectp)))
+	    error ("Can't set section contents: %s.",
+		   bfd_errmsg (bfd_get_error ()));
+
+	do_cleanups (clean);
+	return;
+    }
+
+    DEBUG (MODULE, 2, "Relocating %s\n", bfd_get_section_name (abfd, sectp));
+
+    buf = xmalloc (bfd_get_section_size (sectp));
+    clean = make_cleanup (xfree, buf);
+
+    if (bfd_simple_get_relocated_section_contents (abfd, sectp,
+						   buf, NULL) == NULL)
+	error ("Can't relocate section contents.");
+
+    if (! bfd_set_section_contents (info->new,
+				    info->sec_mapping[sectp->index],
+				    buf,
+				    0,
+				    bfd_get_section_size (sectp)))
+	error ("Can't relocate section contents.");
+
+    do_cleanups (clean);
+}
+
+static int
+make_temporary_bfd (bfd *abfd, struct lm_info *lm_info, char **temp_pathname)
+{
+    struct module_bfd_copy_info info;
+    bfd *newbfd;
+    char *tmpname;
+    char *filename;
+    int fd = -1, len;
+
+    xasprintf (&tmpname, "gdb-module-%s-XXXXXX", lm_info->module_name);
+    xasprintf (&filename, "%s/%s", tmpdir, tmpname);
+    len = strlen (filename);
+
+    if (len >=  SO_NAME_MAX_PATH_SIZE)
+	warning ("Can't create temporary file in '%s': "
+		 "dirname too long.", tmpdir);
+    else
+	fd = mkstemp (filename);
+
+    if (fd == -1) {
+	int i;
+	for (i = 0; fd == -1 && i < ARRAY_SIZE (fallback_tmpdirs); ++i) {
+	    xfree (filename);
+	    xasprintf (&filename, "%s/%s", fallback_tmpdirs[i], tmpname);
+	    len = strlen (filename);
+	    if (len >=  SO_NAME_MAX_PATH_SIZE)
+		warning ("Can't create temporary file in '%s': "
+			 "dirname too long.", tmpdir);
+	    else
+		fd = mkstemp (filename);
+	}
+	if (fd == -1) {
+	    xfree (tmpname); xfree (filename);
+	    return fd;
+	}
+    }
+
+    close (fd);
+    *temp_pathname = xstrdup (filename);
+    newbfd = bfd_openw (filename, bfd_get_target (abfd));
+
+    if (! newbfd) {
+	error ("Can't open newbfd.");
+    }
+
+    bfd_set_format (newbfd, bfd_object);
+    bfd_set_arch_mach (newbfd, bfd_get_arch (abfd), bfd_get_mach (abfd));
+
+    /* Make the generated file a shred object, so that GDB doesn't try
+       to randomly layout the relocatable sections. */
+    if (!bfd_set_file_flags (newbfd, bfd_get_file_flags (newbfd) | DYNAMIC))
+	warning ("Could not set temporary file flags to DYNAMIC.");
+
+    info.old = abfd;
+    info.new = newbfd;
+    info.lm_info = lm_info;
+    info.sec_mapping = xmalloc (sizeof(asection *)
+				* bfd_count_sections (info.old));
+    memset(info.sec_mapping, 0,
+	   sizeof(asection *) * bfd_count_sections (info.old));
+
+    bfd_map_over_sections (info.old, set_section_offsets, lm_info);
+    bfd_map_over_sections (info.old, create_sections, &info);
+    create_symbols (&info);
+
+    /* Create a PT_LOAD segment in the output file so that the BFD
+       doesn't complain when writing the results to the disk. */
+    {
+	struct elf_segment_map *m;
+	unsigned int i, j;
+	asection *hdrpp;
+	bfd_size_type amt;
+
+	amt = sizeof (struct elf_segment_map);
+	amt += (bfd_count_sections(info.new)) * sizeof (asection *);
+	m = bfd_zalloc (info.new, amt);
+	gdb_assert (m != NULL);
+	m->next = NULL;
+	m->p_type = PT_LOAD;
+	for (i = 0, j = 0, hdrpp = info.new->sections; i < bfd_count_sections(info.new); i++, hdrpp = hdrpp->next)
+	    if (bfd_get_section_flags(info.new, hdrpp) & SEC_LOAD)
+		m->sections[j++] = hdrpp;
+	m->count = j;
+
+	elf_tdata (info.new)->segment_map = m;
+    }
+    bfd_map_over_sections (info.old, set_section_contents, &info);
+
+    bfd_close (info.new);
+
+    fd = open (filename, O_RDONLY);
+
+    xfree (info.sec_mapping);
+    xfree (tmpname);
+    xfree (filename);
+
+    return fd;
+}
+
+static struct lm_info *
+find_lm_info (const char *name)
+{
+    struct lm_info_list *list = lm_infos;
+
+    while (list != NULL) {
+	if (! strcmp (name, list->info->module_name))
+	    break;
+	list = list->next;
+    }
+
+    return list ? list->info : NULL;;
+}
+
+static void
+free_depmod_cache ()
+{
+    int i;
+
+    for (i = 0; i < depmod_cache_length; ++i)
+	xfree(depmod_cache[i].filename);
+
+    xfree(depmod_cache);
+    depmod_cache_length = depmod_cache_capacity = 0;
+    depmod_cache = NULL;
+}
+
+static void
+grow_depmod_cache ()
+{
+    if (depmod_cache == NULL) {
+	depmod_cache = xmalloc (64*sizeof(struct depmod_cache));
+	depmod_cache_capacity = 64;
+	return;
+    }
+
+    depmod_cache_capacity *= 2;
+    depmod_cache = xrealloc(depmod_cache,
+			    depmod_cache_capacity*sizeof(struct depmod_cache));
+    if (depmod_cache == NULL)
+	error ("grow_depmod_cache (): your system ran out of memory.");
+}
+
+static void
+build_depmod_cache ()
+{
+    struct stat depmod_stat;
+    char depmod_file[PATH_MAX];
+    FILE *file;
+    size_t n;
+    struct depmod_cache *cache;
+    char *ptr;
+
+    xsnprintf (depmod_file, PATH_MAX, "%s/lib/modules/%s/modules.dep",
+	       *target_root_prefix, utsname_release);
+
+    if (stat (depmod_file, &depmod_stat) < 0
+	|| depmod_stat.st_mtime == depmod_cache_timestamp)
+	return;
+
+    file = fopen (depmod_file, "r");
+    if (file == NULL)
+	return;
+
+    depmod_cache_timestamp = depmod_stat.st_mtime;
+
+    do {
+	if (depmod_cache_length >= depmod_cache_capacity)
+	    grow_depmod_cache ();
+
+	cache = depmod_cache + depmod_cache_length;
+	cache->filename = NULL;
+	if (getline (&cache->filename, &n, file) < 0)
+	    break;
+
+	ptr = strchr(cache->filename, ':');
+	if (ptr == NULL)
+	    continue;
+	*ptr = '\0';
+	while (*ptr != '/' && ptr != cache->filename)
+	    --ptr;
+
+	cache->modname = ptr+1;
+	++depmod_cache_length;
+    } while (1);
+}
+
+static int
+lookup_module_dep (const char *string,
+		   int mode, int prot,
+		   char **opened)
+{
+    int i;
+    const char *found = NULL;
+    build_depmod_cache ();
+
+    for (i = 0; i < depmod_cache_length; ++i) {
+	if (strcmp (string, depmod_cache[i].modname))
+	    continue;
+	/* skip initial '/' in filename */
+	found = depmod_cache[i].filename+1;
+	break;
+    }
+
+    if (found == NULL)
+	return -1;
+
+    return openp (*target_root_prefix, 0, found, mode, prot, opened);
+}
+
+static char *
+get_utsname_release_from_file ()
+{
+    static char release[256];
+    int i = 0;
+    CORE_ADDR release_addr;
+    asection* data;
+
+    if (HAS_ADDR(system_utsname) && HAS_FIELD(new_utsname, release))
+	release_addr = ADDR (system_utsname)
+	    + F_OFFSET(new_utsname, release);
+    else if (HAS_ADDR(init_uts_ns)
+	     && HAS_FIELD(uts_namespace, name)
+	     && HAS_FIELD(new_utsname, release))
+	release_addr = ADDR (init_uts_ns)
+	    + F_OFFSET(uts_namespace, name)
+	    + F_OFFSET(new_utsname, release);
+    else
+	return NULL;
+
+    data = bfd_get_section_by_name (exec_bfd, ".rodata");
+
+    if (data != NULL
+	&& release_addr >= bfd_get_section_vma (exec_bfd, data)
+	&& release_addr < bfd_get_section_vma (exec_bfd,data)
+                          + bfd_get_section_size(data))
+	goto section_found;
+
+    data = bfd_get_section_by_name (exec_bfd, ".data");
+
+    if (data == NULL
+	|| release_addr < bfd_get_section_vma (exec_bfd, data)
+	|| release_addr >= bfd_get_section_vma (exec_bfd,data)
+	                   + bfd_get_section_size(data))
+	return NULL;
+
+ section_found:
+    bfd_seek (exec_bfd, data->filepos + release_addr
+	                - bfd_get_section_vma (exec_bfd, data), SEEK_SET);
+
+    while (i<256) {
+	bfd_bread (release + i, 1, exec_bfd);
+	if (release[i++] == '\0')
+	    break;
+    }
+
+    return release;
+}
+
+static int
+module_openp (const char *path, int opts, const char *string,
+	      int mode, int prot,
+	      char **filename_opened)
+{
+    int res;
+
+    sanitize_target_root_prefix();
+    if (utsname_release == NULL || **target_root_prefix == '\0')
+	return openp (path, opts, string, mode, prot, filename_opened);
+
+    /* Try first in the module_search_path */
+    res = openp (path, opts, string, mode, prot, filename_opened);
+
+    if (res >= 0)
+	return res;
+
+    /* Now look for modules.dep */
+    return lookup_module_dep(string, mode, prot, filename_opened);
+}
+
+/* This function implements the walking of the decision tree
+   representing all the possible names for the module names FILENAME. */
+static int
+try_to_open_alternate_names (char *file, char **temp_pathname)
+{
+    int *tree;
+    int nb_chars, allocated_chars;
+    int level = 0;
+    char *filename;
+
+    void add_char (int pos) {
+
+	if (nb_chars == allocated_chars) {
+	    allocated_chars *= 2;
+	    tree = xrealloc (tree, sizeof (int)*allocated_chars);
+	}
+
+	tree[nb_chars] = pos;
+	filename[pos] = '\0';
+	++nb_chars;
+    }
+
+    void gather_chars () {
+	char *c = filename;
+
+	while (*c) {
+	    if (*c == '_') add_char (c-filename);
+	    ++c;
+	}
+    }
+
+    filename = alloca(strlen(file) + 1);
+    strcpy(filename, file);
+    allocated_chars = 4;
+    tree = xmalloc (sizeof (int)*4);
+    nb_chars = 0;
+
+    gather_chars ();
+
+    if (! nb_chars) {
+	xfree (tree);
+	return module_openp (*module_search_path, OPF_TRY_CWD_FIRST,
+			     filename, O_RDONLY, 0, temp_pathname);
+    }
+
+    while (level >= 0) {
+	switch (filename[tree[level]]) {
+	case 0: filename[tree[level]] = '_'; ++level; break;
+	case '_': filename[tree[level]] = '-'; ++level; break;
+	case '-': filename[tree[level]] = ','; ++level; break;
+	case ',': filename[tree[level]] = 0; --level; break;
+	}
+
+	if (level == nb_chars) {
+	    int res = module_openp (*module_search_path, OPF_TRY_CWD_FIRST,
+				    filename, O_RDONLY, 0, temp_pathname);
+	    if (res >= 0) {
+		xfree (tree);
+		return res;
+	    }
+	    --level;
+	}
+    }
+
+    xfree (tree);
+    return -1;
+}
+
+static int
+linux_aware_find_and_open_solib(char *in_soname,
+				unsigned o_flags,
+				char **temp_pathname)
+{
+    int found_file = -1;
+    char realfile[SO_NAME_MAX_PATH_SIZE];
+    char soname[SO_NAME_MAX_PATH_SIZE];
+    bfd *abfd;
+    struct lm_info *lm_info;
+    char *c;
+    strcpy (soname, in_soname+1);
+    soname[strlen(soname)-1] = '\0';
+
+    /* This hack tries to minimize the chance that GDB finds a binary
+       file named like the module in its default search (in
+       solib.c:solib_open).  */
+    if (*in_soname != '[' || in_soname[strlen(in_soname+1)] != ']') {
+	warning ("\
+linux_aware_find_and_open_solib: Passed module name wasn't generated by \
+linux_aware_so_ops!");
+	return -1;
+    }
+
+    strcpy(realfile, soname);
+    strcat(realfile, ".ko");
+
+    while ((c = strchr(realfile, ',')))
+	*c = '_';
+
+    while ((c = strchr(realfile, '-')))
+	*c = '_';
+
+    found_file = try_to_open_alternate_names (realfile, temp_pathname);
+
+    if ( found_file < 0 ) {
+	error("\
+You just loaded the '%s' module.\n\
+The debugger searched for '%s' in module-search-path,\n\
+but didn't find the module file.\n\
+Current module-search-path is:\n%s\n", soname, realfile, *module_search_path);
+    }
+
+    abfd = bfd_openr (*temp_pathname, gnutarget);
+    if (!abfd) {
+	close (found_file);
+	error ("Could not open `%s' as an executable file: %s",
+	       *temp_pathname, bfd_errmsg (bfd_get_error ()));
+    }
+
+    if (!bfd_check_format (abfd, bfd_object)) {
+	error ("\"%s\": not in executable format: %s.",
+	       *temp_pathname, bfd_errmsg (bfd_get_error ()));
+    }
+
+    lm_info = find_lm_info (soname);
+    layout_sections (abfd, lm_info);
+
+    if (lm_info->sections == NULL)
+	return -1;
+
+    printf_unfiltered("[New module '%s' (%s)]\n", soname, *temp_pathname);
+
+    if (! lm_info->needs_relocated_file ) {
+	bfd_close (abfd);
+	return found_file;
+    }
+
+    lm_info->real_file = xmalloc (strlen (*temp_pathname)+1);
+    strcpy (lm_info->real_file, *temp_pathname);
+    found_file = make_temporary_bfd (abfd, lm_info, temp_pathname);
+
+    if (found_file >= 0) {
+	lm_info->relocated_file = xmalloc (strlen (*temp_pathname)+1);
+	strcpy (lm_info->relocated_file, *temp_pathname);
+	xfree (*temp_pathname);
+	*temp_pathname = lm_info->relocated_file;
+    }
+
+    bfd_close (abfd);
+    return found_file;
+}
+
+static void
+linux_aware_relocate_section_addresses (struct so_list *so,
+					struct section_table *sec)
+{
+    unsigned int offset;
+    DEBUG (MODULE, 3,
+	   "linux_aware_relocate_section_addresses (%s:%s) <= %s->%s\n",
+	   so->so_name, sec->the_bfd_section->name,
+	   paddr (sec->addr), paddr (sec->endaddr));
+
+    if (so->lm_info->sections == NULL)
+	error("\
+GDB has opened '%s' as the binary file for module '%s'.\
+This is certainly wrong, and will cause troubles for the rest of this \
+debugging session. Please move that file out of the way.",
+	      so->so_name, so->so_original_name);
+
+    /* This one is in GDB's list */
+    so->lm_info->mod = so;
+
+    if (so->lm_info->needs_relocated_file) {
+	/* Just do as if our handcrafted file was a real shared
+	   library. */
+	sec->endaddr += so->lm_info->module_core;
+	sec->addr += so->lm_info->module_core;
+	return;
+    }
+
+    /* Put the symbols from the .modinfo section at the end of the
+       memory so that they don't interfer with real symbols.
+       We can't simply let the offset be 0: the issue is that
+       symfile.c:syms_from_objfile re-initializes the 0 offsets to the
+       lower initialized offset. Thus we get offset(.modinfo) ==
+       offset(.text) and a lot of issues stem from that. */
+    if (!strcmp (".modinfo", sec->the_bfd_section->name))
+	offset = ~0UL - sec->the_bfd_section->size;
+    else
+	offset = get_module_section_addr(so->lm_info,
+					 sec->the_bfd_section->name);
+
+    sec->addr += offset;
+    sec->endaddr += offset;
+    DEBUG (MODULE, 4,
+	   "linux_aware_relocate_section_addresses (%s:%s) => %s->%s\n",
+	   so->so_name, sec->the_bfd_section->name,
+	   paddr ( sec->addr), paddr (sec->endaddr));
+}
+
+static void
+linux_aware_free_lm_info (struct lm_info *info)
+{
+    xfree (info->sections);
+    if (info->relocated_file != NULL)
+	unlink (info->relocated_file);
+    xfree (info->relocated_file);
+    xfree (info->real_file);
+
+    if (info->mod)
+	info->mod->lm_info = NULL;
+
+    xfree (info);
+}
+
+static void
+delete_temp_files ()
+{
+    struct lm_info_list *list = lm_infos, *next;
+
+    while (list != NULL) {
+	next = list->next;
+	linux_aware_free_lm_info (list->info);
+	xfree (list);
+	list = next;
+    }
+
+    lm_infos = NULL;
+}
+
+static void
+linux_aware_remove_lm_info_from_list_by_addr (CORE_ADDR this_module, int notif)
+{
+    struct lm_info_list *list = lm_infos, *prev = NULL;
+
+    while (list) {
+	if (list->info->this_module == this_module)
+	    break;
+
+	prev = list;
+	list = list->next;
+    }
+
+    if (list == NULL)
+	return;
+
+    DEBUG (MODULE, 4,
+	   "Really deleting module '%s'.\n", list->info->module_name);
+    if (notif)
+	printf_filtered("[Unloading module '%s']\n", list->info->module_name);
+
+    if (prev != NULL)
+	prev->next = list->next;
+    else
+	lm_infos = list->next;
+
+    if (last_loaded == list->info)
+	last_loaded = NULL;
+
+    linux_aware_free_lm_info (list->info);
+    xfree (list);
+}
+
+
+static int
+linux_aware_lm_info_exists (struct lm_info *info)
+{
+    struct lm_info_list *list = lm_infos;
+
+    while (list) {
+	if (info == list->info)
+	    break;
+
+	list = list->next;
+    }
+
+    return list != NULL;
+}
+
+
+static void
+linux_aware_free_so (struct so_list *so)
+{
+    DEBUG (MODULE, 3, "linux_aware_free_so(%s)\n", so->so_name);
+
+    if (so->lm_info
+	&& linux_aware_lm_info_exists (so->lm_info)
+	&& so->lm_info->mod == so)
+	linux_aware_remove_lm_info_from_list_by_addr (so->lm_info->this_module,
+						      0);
+}
+
+static void
+linux_aware_clear_solib (void)
+{
+    DEBUG (MODULE, 3, "linux_aware_clear_solib\n");
+    delete_temp_files ();
+}
+
+static void
+linux_aware_solib_create_inferior_hook (void)
+{
+    CORE_ADDR addr;
+    DEBUG (MODULE, 3, "linux_aware_solib_create_inferior_hook\n");
+
+    if (HAS_ADDR (module_finalize)) {
+	addr = ADDR (module_finalize);
+	shlib_event_load_bp = create_solib_event_breakpoint (addr);
+    }
+
+    if (HAS_ADDR (module_arch_cleanup)) {
+	addr = ADDR (module_arch_cleanup);
+	shlib_event_free_bp = create_solib_event_breakpoint (addr);
+    }
+}
+
+static void
+linux_aware_special_symbol_handling (void)
+{
+    struct lm_info_list *list = lm_infos;
+    struct obj_section *sect;
+    DEBUG (MODULE, 3, "linux_aware_special_symbol_handling\n");
+
+    while (list != NULL) {
+	struct lm_info *info = list->info;
+
+	if (! info->so_list_updated) {
+	    if (info->needs_relocated_file) {
+		strcpy (info->mod->so_name, info->real_file);
+
+		if (info->computed_init_size
+		    && !info->init_size) {
+
+		    /* This combination means that we've loaded the
+		       debug information after the init step of the
+		       module has happened. Can occur when the user
+		       sets a correct module-search-path after the
+		       module load has been notified. */
+
+		    DEBUG (MODULE, 2, "Relocating symbols for %s\n",
+			   info->module_name);
+		    linux_aware_objfile_relocate (info->mod->objfile,
+						  0,
+						  info->computed_init_size,
+						  info->module_core,
+						  info->module_core
+						  + info->core_size);
+		}
+
+		info->so_list_updated = 1;
+	    }
+	}
+	list = list->next;
+    }
+}
+
+static void
+add_module_from_struct_module (unsigned long addr,
+			       struct lm_info_list **list)
+{
+    char original_name[SO_NAME_MAX_PATH_SIZE];
+    struct lm_info *info;
+    struct lm_info_list *elt;
+
+    read_memory_string (addr + F_OFFSET (module, name),
+			original_name,
+			SO_NAME_MAX_PATH_SIZE);
+
+    DEBUG (MODULE, 3, "Adding module '%s' ?\n", original_name);
+
+    info = find_lm_info (original_name);
+
+    if (info == NULL) {
+	DEBUG (MODULE, 3, "Allocation new lm_info for '%s'\n", original_name);
+    	info = XZALLOC (struct lm_info);
+
+	strcpy (info->module_name, original_name);
+	info->this_module = addr;
+	info->init = read_unsigned_field(addr, module, init);
+	info->module_init = read_unsigned_field(addr, module, module_init);
+	info->module_core = read_unsigned_field(addr, module, module_core);
+	info->init_size = read_unsigned_field(addr, module, init_size);
+	info->core_size = read_unsigned_field(addr, module, core_size);
+    }
+
+    elt = xmalloc (sizeof (struct lm_info_list));
+    elt->info = info;
+    elt->next = *list;
+    *list = elt;
+}
+
+static void
+remove_module_from_struct_module (unsigned long addr)
+{
+    char name[SO_NAME_MAX_PATH_SIZE];
+    DEBUG (MODULE, 3, "Trying to remove module at %lx\n", addr);
+
+    linux_aware_remove_lm_info_from_list_by_addr (addr, 1);
+    DEBUG (MODULE, 3, "Removing done...\n");
+}
+
+static void
+linux_read_module_list ()
+{
+    CORE_ADDR next;
+    struct lm_info_list *new_list = NULL;
+
+    if (! HAS_ADDR (modules))
+	return;
+
+    for (next = read_memory_typed_address (ADDR (modules),
+					   builtin_type_void_data_ptr);
+	 next != ADDR (modules);
+	 next = read_memory_typed_address (next, builtin_type_void_data_ptr)) {
+	CORE_ADDR addr = next;
+	if (!translate_memory_address_safe (&addr, 1))
+	    error ("\
+The debugger can't read the module list. The linux awareness\n\
+layer's view of the kernel is seriously compromised.");
+
+	add_module_from_struct_module (next - F_OFFSET (module, list),
+				       &new_list);
+    }
+    /* lm_infos will be discarded anyway. Just free the list
+       containers, and not the lm_infos which have been be reused. */
+    while (lm_infos) {
+	struct lm_info_list *next = lm_infos->next;
+	xfree (lm_infos);
+	lm_infos = next;
+    }
+
+    lm_infos = new_list;
+}
+
+static struct so_list *
+so_list_from_lm_infos ()
+{
+    struct so_list *res = NULL, *cur;
+    struct lm_info_list *list = lm_infos;
+
+    while (list != NULL) {
+	cur = XZALLOC (struct so_list);
+	cur->next = res;
+	res = cur;
+
+	cur->lm_info = list->info;
+	xsnprintf(cur->so_original_name, sizeof(cur->so_original_name),
+		  "[%s]", list->info->module_name);
+	xsnprintf(cur->so_name, sizeof(cur->so_name),
+		  "[%s]", list->info->module_name);
+
+	list = list->next;
+    }
+
+    return res;
+}
+
+/* Copied from buildsym.c:compare_line_numbers */
+static int
+compare_line_numbers (const void *ln1p, const void *ln2p)
+{
+  struct linetable_entry *ln1 = (struct linetable_entry *) ln1p;
+  struct linetable_entry *ln2 = (struct linetable_entry *) ln2p;
+
+  /* Note: this code does not assume that CORE_ADDRs can fit in ints.
+     Please keep it that way.  */
+  if (ln1->pc < ln2->pc)
+    return -1;
+
+  if (ln1->pc > ln2->pc)
+    return 1;
+
+  /* If pc equal, sort by line.  I'm not sure whether this is optimum
+     behavior (see comment at struct linetable in symtab.h).  */
+  return ln1->line - ln2->line;
+}
+
+static int
+compare_blocks (const void *ln1p, const void *ln2p)
+{
+  struct block **b1 = (struct block **)ln1p;
+  struct block **b2 = (struct block **)ln2p;
+
+  if (BLOCK_START (*b1) < BLOCK_START (*b2))
+    return -1;
+
+  if (BLOCK_START (*b1) > BLOCK_START (*b2))
+    return 1;
+
+  return 0;
+}
+
+/* Copy pasted from objfiles.c:objfile_relocate() */
+static void
+linux_aware_objfile_relocate (struct objfile *objfile,
+			      CORE_ADDR init_start,
+			      CORE_ADDR init_end,
+			      CORE_ADDR core_start,
+			      CORE_ADDR core_end)
+{
+  int i;
+  struct symtab *s;
+  struct partial_symbol **psym;
+  struct partial_symtab *pst;
+  struct minimal_symbol *msym;
+  struct obj_section *sec;
+  bfd *abfd;
+
+  /* OK, get all the symtabs.  */
+  ALL_OBJFILE_SYMTABS (objfile, s) {
+      struct linetable *l;
+      struct blockvector *bv;
+      int i;
+
+      /* First the line table.  */
+      l = LINETABLE (s);
+      if (l) {
+	  for (i = 0; i < l->nitems; ++i)
+	      if (init_start <= l->item[i].pc
+		  && init_end > l->item[i].pc)
+		  l->item[i].pc = ~(CORE_ADDR)0;
+
+	  qsort (l->item,
+		 l->nitems,
+		 sizeof (struct linetable_entry), compare_line_numbers);
+      }
+
+      /* Don't relocate a shared blockvector more than once.  */
+      if (!s->primary)
+	  continue;
+
+      bv = BLOCKVECTOR (s);
+      for (i = 0; i < BLOCKVECTOR_NBLOCKS (bv); ++i) {
+	  struct block *b;
+	  struct symbol *sym;
+	  struct dict_iterator iter;
+
+	  b = BLOCKVECTOR_BLOCK (bv, i);
+
+	  ALL_BLOCK_SYMBOLS (b, iter, sym) {
+	      fixup_symbol_section (sym, objfile);
+
+	      if (SYMBOL_BFD_SECTION (sym)
+		  && !strncmp (".init.", SYMBOL_BFD_SECTION (sym)->name, 6)
+		  && (SYMBOL_CLASS (sym) == LOC_LABEL
+		      || SYMBOL_CLASS (sym) == LOC_STATIC
+		      || SYMBOL_CLASS (sym) == LOC_INDIRECT)
+		  && SYMBOL_SECTION (sym) >= 0) {
+		  SYMBOL_VALUE_ADDRESS (sym) = ~(CORE_ADDR)0;
+	      }
+	  }
+
+	  if (init_start <= BLOCK_START (b)
+	      && init_end >= BLOCK_END (b)) {
+	      BLOCK_START (b) = ~(CORE_ADDR)0;
+	      BLOCK_END (b) = ~(CORE_ADDR)0;
+	  } else {
+	      if (init_start <= BLOCK_START (b)
+		  && init_end > BLOCK_START (b)) {
+		  BLOCK_START (b) = core_start;
+	      }
+	      if (init_start <= BLOCK_END (b)
+		  && init_end >= BLOCK_END (b)) {
+		  BLOCK_END(b) = core_end;
+	      }
+	  }
+      }
+
+      qsort (bv->block+2,
+	     bv->nblocks-2,
+	     sizeof (struct block *), compare_blocks);
+  }
+
+  /* Now the psymtabs */
+  for (psym = objfile->global_psymbols.list;
+       psym < objfile->global_psymbols.next;
+       psym++) {
+      fixup_psymbol_section (*psym, objfile);
+      if (SYMBOL_BFD_SECTION (*psym)
+	  && !strncmp (".init.", SYMBOL_BFD_SECTION (*psym)->name, 6))
+	  SYMBOL_VALUE_ADDRESS (*psym) = ~(CORE_ADDR)0;
+  }
+  for (psym = objfile->static_psymbols.list;
+       psym < objfile->static_psymbols.next;
+       psym++) {
+      fixup_psymbol_section (*psym, objfile);
+      if (SYMBOL_BFD_SECTION (*psym)
+	  && !strncmp(".init.", SYMBOL_BFD_SECTION (*psym)->name, 6))
+	  SYMBOL_VALUE_ADDRESS (*psym) = ~(CORE_ADDR)0;
+  }
+
+  ALL_OBJFILE_PSYMTABS (objfile, pst) {
+      if (init_start <= pst->textlow
+	  && init_end >= pst->texthigh) {
+	  pst->textlow = ~(CORE_ADDR)0;
+	  pst->texthigh = ~(CORE_ADDR)0;
+      } else {
+	  if (init_start <= pst->textlow
+	      && init_end > pst->textlow) {
+	      pst->textlow = core_start;
+	  }
+	  if (init_start <= pst->texthigh
+	      && init_end >= pst->texthigh) {
+	      pst->texthigh = core_end;
+	  }
+      }
+  }
+
+  /* And finally the minimal symbols. */
+  ALL_OBJFILE_MSYMBOLS (objfile, msym)
+      if (SYMBOL_BFD_SECTION (msym)
+	  && !strncmp (".init.", SYMBOL_BFD_SECTION (msym)->name, 6))
+	  SYMBOL_VALUE_ADDRESS (msym) = ~(CORE_ADDR)0;
+
+  /* Relocating different sections by different amounts may cause the symbols
+     to be out of order.  */
+  msymbols_sort (objfile);
+
+
+  /* As a final point, eradicate the section */
+  abfd = objfile->obfd;
+
+  ALL_OBJFILE_OSECTIONS (objfile, sec) {
+      if (!strncmp (sec->the_bfd_section->name, ".init.", 6)) {
+	  sec->addr = ~(CORE_ADDR)0;
+	  sec->endaddr = ~(CORE_ADDR)0;
+      }
+  }
+
+  /* Relocate breakpoints as necessary, after things are relocated. */
+  resetting_bps_after_init = 1;
+  breakpoint_re_set ();
+  resetting_bps_after_init = 0;
+  seen_module_unload = 1;
+}
+
+/* This comment holds for all the solib code in here: _Things should be
+   simpler_, but some details prevent us from making it simpler. For
+   example, the module init code is called before the module insertion
+   in the global list. Thus we can't just reread the list, we have to
+   explicitely detect the load_modul end, and maintain our own
+   list. Without that, no break in init code... */
+static struct so_list *
+linux_aware_current_sos (void)
+{
+    CORE_ADDR current_pc;
+
+    DEBUG (MODULE, 3, "linux_aware_current_sos => pc=0x%s\n",
+	   paddr (target_has_registers ? read_pc() : 0));
+
+    if (! target_has_registers || !loaded)
+	return NULL;
+
+    current_pc = read_pc ();
+
+    if (!init_module_return_resolved
+	&& shlib_event_init_bp
+	&& current_pc == shlib_event_init_bp->loc->address) {
+	delete_breakpoint (shlib_event_init_bp);
+	thread_awareness_inhibit();
+	shlib_event_init_bp
+	    = create_solib_event_breakpoint (linux_awareness_ops->lo_return_address_at_start_of_function());
+	thread_awareness_exhibit();
+	init_module_return_resolved = 1;
+	return so_list_from_lm_infos ();
+    }
+
+    if (shlib_event_load_bp != NULL
+	&& current_pc == shlib_event_load_bp->loc->address)
+	{
+	    /* We've just loaded a new module to memory. */
+	    CORE_ADDR ptr;
+	    struct breakpoint *bp;
+	    ptr = linux_awareness_ops->lo_third_pointer_arg_value ();
+
+	    DEBUG (MODULE, 3,
+		   "module_finalize module %x\n", (unsigned int)ptr);
+
+	    add_module_from_struct_module (ptr, &lm_infos);
+	    last_loaded = lm_infos->info;
+
+	    /* We just loaded a module. Enable all the breakpoints
+	       that were located in this module and that got disabled
+	       when it was first unloaded. We abuse the dll_pathname
+	       field to remember what module a breakpoint corresponds
+	       to. This gets set in _breakpoint_create_hook(). */
+	    ALL_BREAKPOINTS (bp)
+		if(bp->enable_state == bp_disabled
+		   && bp->loc->address == ~(CORE_ADDR)0
+		   && bp->dll_pathname
+		   && !strcmp(bp->dll_pathname, last_loaded->module_name)) {
+		    bp->enable_state = bp_enabled;
+		}
+
+	    if (lm_infos
+		&& lm_infos->info->this_module == ptr
+		&& lm_infos->info->module_init
+		&& lm_infos->info->init
+		&& !init_module_return_resolved) {
+		shlib_event_init_bp
+		    = create_solib_event_breakpoint (lm_infos->info->init);
+		DEBUG (MODULE, 3, "Created shlib_event_init_bp : %s %i\n",
+		       paddr (lm_infos->info->init),
+		       shlib_event_init_bp->loc->inserted);
+	    }
+
+	    return so_list_from_lm_infos ();
+	}
+
+    if (shlib_event_init_bp
+	&& current_pc == shlib_event_init_bp->loc->address) {
+
+	if (last_loaded != NULL
+	    && last_loaded->mod
+	    && last_loaded->module_init) {
+
+	    /* We previously used the beginning of the lm_info list as
+	       the last loaded modules, but this breaks if the user
+	       does 'info sharedlibrary' while in the init function:
+	       the list gets re-read in a different order. */
+
+	    struct lm_info *info = last_loaded;
+	    struct objfile *objfile;
+	    struct partial_symtab *psymtab;
+	    int i;
+	    objfile = info->mod->objfile;
+
+	    DEBUG (MODULE, 3, "End of init for %s\n", objfile->name);
+	    for (psymtab = objfile->psymtabs;
+		 psymtab != NULL;
+		 psymtab = psymtab->next)
+		{
+		    psymtab_to_symtab (psymtab);
+		}
+
+	    linux_aware_objfile_relocate (info->mod->objfile,
+					  info->module_init,
+					  info->module_init+info->init_size,
+					  info->module_core,
+					  info->module_core+info->core_size);
+	}
+	last_loaded = NULL;
+	return so_list_from_lm_infos ();
+    }
+
+    if (shlib_event_free_bp != NULL
+	&& current_pc == shlib_event_free_bp->loc->address)	    {
+	CORE_ADDR ptr = linux_awareness_ops->lo_first_pointer_arg_value ();
+	remove_module_from_struct_module (ptr);
+	seen_module_unload = 1;
+	return so_list_from_lm_infos ();
+    }
+
+    /* Reread only if the current list is empty. Either, there's no
+       module and it will go fast, or the user just cleaned the list
+       (using for example 'set module-search-path').  */
+    if (lm_infos == NULL) {
+	DEBUG (MODULE, 1, "Reading module list\n");
+	linux_read_module_list ();
+    }
+    return so_list_from_lm_infos ();
+}
+
+static int
+linux_aware_open_symbol_file_object (void *from_ttyp)
+{
+    DEBUG (MODULE, 3, "linux_aware_open_symbol_file_object\n");
+    return 0;
+}
+
+static int
+linux_aware_in_dynsym_resolve_code (CORE_ADDR pc)
+{
+    DEBUG (MODULE, 3, "linux_aware_in_dynsym_resolve_code\n");
+    return 0;
+}
+
+static void
+init_so_ops ()
+{
+    DEBUG (MODULE, 3, "init_so_ops\n");
+    linux_aware_so_ops.relocate_section_addresses = linux_aware_relocate_section_addresses;
+    linux_aware_so_ops.free_so = linux_aware_free_so;
+    linux_aware_so_ops.clear_solib = linux_aware_clear_solib;
+    linux_aware_so_ops.solib_create_inferior_hook = linux_aware_solib_create_inferior_hook;
+    linux_aware_so_ops.special_symbol_handling = linux_aware_special_symbol_handling;
+    linux_aware_so_ops.current_sos = linux_aware_current_sos;
+    linux_aware_so_ops.open_symbol_file_object = linux_aware_open_symbol_file_object;
+    linux_aware_so_ops.in_dynsym_resolve_code = linux_aware_in_dynsym_resolve_code;
+    linux_aware_so_ops.find_and_open_solib = linux_aware_find_and_open_solib;
+}
+
+
+/******************************************************************************/
+/*****************                 THREADS                   ******************/
+/******************************************************************************/
+
+static struct process *
+get_task_info (CORE_ADDR task_struct)
+{
+    struct process *ps = XZALLOC (struct process);
+    struct cleanup *cleaner = make_cleanup (xfree, ps);
+    DEBUG (TASK,3, "get_task_info(%s)\n", paddr (task_struct));
+    ps->mm = read_unsigned_field (task_struct, task_struct, mm);
+    ps->task_struct_address = task_struct;
+    ps->pid = read_unsigned_field (task_struct, task_struct, pid);
+    ps->tgid = read_unsigned_field (task_struct, task_struct, tgid);
+    ps->prio = read_unsigned_field (task_struct, task_struct, prio);
+    ps->comm = xmalloc (F_SIZE (task_struct, comm)+3);
+    read_memory_string (task_struct+F_OFFSET (task_struct, comm), ps->comm,
+			F_SIZE (task_struct, comm));
+
+    if (!ps->mm) {
+	char* comm = xstrdup (ps->comm);
+	snprintf (ps->comm, F_SIZE (task_struct, comm)+3, "[%s]", comm);
+	xfree (comm);
+    }
+
+    discard_cleanups (cleaner);
+    return ps;
+}
+
+static struct process *
+get_current_process ()
+{
+    if (!current_process) {
+	CORE_ADDR task_struct;
+	thread_awareness_inhibit();
+	task_struct = linux_awareness_ops->lo_current_task_struct_address();
+	thread_awareness_exhibit();
+	current_process = get_task_info(task_struct);
+    }
+
+    return current_process;
+}
+
+static struct process *
+get_gdb_process ()
+{
+    struct process *ps = get_current_process ();
+    DEBUG (TASK,3, "get_gdb_process : ps->pid %i, inferior pid : %i\n",
+	   ps->pid, PIDGET (inferior_ptid));
+    if (ps->pid != PIDGET (inferior_ptid)) {
+	struct process *gdb_ps;
+	gdb_ps = thread_list_contains_pid (PIDGET (inferior_ptid));
+	if (gdb_ps) {
+	    ps = gdb_ps;
+	    switch_to_user_process (ps);
+	}
+    }
+
+    return ps;
+}
+
+static void
+thread_list_clear_cache ()
+{
+    struct process *ps;
+
+    while (processes) {
+	ps = processes;
+	processes = ps->next;
+	xfree (ps->comm);
+	xfree (ps);
+    }
+
+    if (current_process != NULL) {
+	xfree (current_process->comm);
+	xfree (current_process);
+	current_process = NULL;
+    }
+
+    thread_list_needs_clearing = 0;
+}
+
+static struct process **
+get_thread_list_helper(CORE_ADDR task_struct, struct process **ps)
+{
+    CORE_ADDR children, child;
+    CORE_ADDR current_struct_task = task_struct;
+
+    DEBUG(TASK, 3, "Get task info for at %s\n", paddr(task_struct));
+    *ps = get_task_info (current_struct_task);
+    ps = & (*ps)->next;
+
+    DEBUG(TASK, 3, "Reading children for task %s\n", paddr(task_struct));
+    children = task_struct +  F_OFFSET (task_struct, children);
+    child = read_unsigned_embedded_field (current_struct_task,
+					  list_head, next,
+					  task_struct, children);
+    while (child != children) {
+	/* The children list_head is chained in the sibling list of the
+	   children.  */
+	current_struct_task = child - F_OFFSET (task_struct, sibling);
+	DEBUG(TASK, 3, "Child att task %s\n", paddr(current_struct_task));
+	ps = get_thread_list_helper(current_struct_task, ps);
+
+	if (linux_awareness_ops->lo_address_needs_translation (current_struct_task))
+	    error("\
+A task struct address can't live in virtual memory. The linux awareness\n\
+layer's view of the kernel is seriously compromised.");
+
+	child = read_unsigned_embedded_field (current_struct_task,
+					      list_head, next,
+					      task_struct, sibling);
+    }
+
+    DEBUG(TASK, 3, "End for task %s\n", paddr(task_struct));
+    return ps;
+}
+
+static struct process *
+get_thread_list ()
+{
+    struct process **ps = &processes;
+    struct debugged_user_process *ups = user_processes;
+    CORE_ADDR current_struct_task = ADDR (init_task);
+
+    if (processes != NULL || !loaded)
+	return processes;
+
+    if (thread_event_do_exit_bp == NULL) {
+	if (HAS_ADDR (do_exit))
+	    thread_event_do_exit_bp = create_thread_event_breakpoint (ADDR (do_exit));
+	else
+	    warning ("'do_exit' wasn't found.");
+    }
+
+    get_thread_list_helper(current_struct_task, ps);
+
+    if (processes && processes->next == NULL) {
+	/* Only one task, the kernel hasn't started. */
+	xfree (processes->comm);
+	xfree (processes);
+	processes = NULL;
+    }
+
+    while (ups) {
+	struct debugged_user_process *cur = ups;
+	ups = ups->next;
+
+	if (! thread_list_contains_pid (cur->pid)) {
+	    DEBUG (USER, 2,
+		   "Deleting information for vanished process with "
+		   "pid %i\n", cur->pid);
+	    delete_user_process (cur->gdb_thread_id);
+	}
+    }
+
+    return processes;
+}
+
+static struct process *
+thread_list_contains_pid (unsigned int pid)
+{
+    struct process *ps = get_current_process ();
+
+    DEBUG (TASK, 3, "thread_list_contains_pid(%i)\n", pid);
+
+    if (pid == ps->pid)
+	return ps;
+
+    ps = get_thread_list ();
+
+    while (ps != NULL) {
+	if (ps->pid == pid)
+	    return ps;
+	ps = ps->next;
+    }
+
+    return NULL;
+}
+
+static int
+linux_aware_thread_alive (ptid_t ptid)
+{
+    if (! thread_awareness_inhibited ())
+	return ptid_equal (ptid, current_ptid)
+	    || thread_list_contains_pid (PIDGET (ptid)) != NULL;
+    else
+	return linux_aware_ops.beneath->to_thread_alive (ptid);
+}
+
+static void linux_aware_find_new_threads (void)
+{
+    if (! thread_awareness_inhibited () && loaded) {
+	struct process *ps = get_thread_list ();
+
+	while (ps != NULL) {
+	    if (!in_thread_list (linux_aware_pid_to_ptid (ps->pid))) {
+		add_thread (linux_aware_pid_to_ptid (ps->pid));
+	    }
+	    ps = ps->next;
+	}
+    } else
+	linux_aware_ops.beneath->to_find_new_threads ();
+
+}
+
+static char *
+linux_aware_pid_to_str (ptid_t ptid)
+{
+    if (! thread_awareness_inhibited ()) {
+	struct process *ps = thread_list_contains_pid (PIDGET (ptid));
+	if (!ps)
+	    return "";
+	return ps->comm;
+    } else
+	return linux_aware_ops.beneath->to_pid_to_str (ptid);
+}
+
+static char *
+linux_aware_extra_thread_info (struct thread_info *thread)
+{
+    if (! thread_awareness_inhibited ()) {
+	static char info[64];
+	struct process *ps = thread_list_contains_pid (PIDGET (thread->ptid));
+
+	if (!ps)
+	    return "";
+
+	snprintf (info, 64, "pid: %i tgid: %i", ps->pid, ps->tgid);
+	return info;
+    } else
+	return linux_aware_ops.beneath->to_extra_thread_info (thread);
+}
+
+static CORE_ADDR
+get_current_task_struct ()
+{
+    CORE_ADDR res;
+
+    if (!thread_awareness_inhibited () && loaded
+	&& !ptid_equal(inferior_ptid, minus_one_ptid)) {
+	struct process *ps = get_gdb_process ();
+	return ps->task_struct_address;
+    }
+
+    thread_awareness_inhibit ();
+    res = linux_awareness_ops->lo_current_task_struct_address ();
+    thread_awareness_exhibit ();
+
+    return res;
+}
+
+static void
+linux_aware_fetch_registers (struct regcache * rc, int regno)
+{
+    DEBUG (TARGET, 3, "fetch_registers %i\n", regno);
+
+    if (!thread_awareness_inhibited () && loaded) {
+	if (! ptid_equal (current_ptid, inferior_ptid)
+	    && thread_list_contains_pid (PIDGET (inferior_ptid))) {
+	    CORE_ADDR task_struct = get_current_task_struct ();
+	    thread_awareness_inhibit ();
+	    if (!linux_awareness_ops->lo_fetch_context_register (regno,
+								 task_struct)) {
+		thread_awareness_exhibit ();
+		error ("Could not fetch task register.");
+	    }
+	    thread_awareness_exhibit ();
+	    return;
+	}
+
+	/* This will switch to the right process when we switch back
+	   to the currently running task. */
+	switch_to_user_process (get_gdb_process ());
+    }
+
+    if (linux_aware_ops.beneath == NULL
+	|| linux_aware_ops.beneath->to_fetch_registers == NULL)
+	error ("No registers.");
+
+    linux_aware_ops.beneath->to_fetch_registers (rc, regno);
+}
+
+static void
+linux_aware_store_registers (struct regcache *rc, int regno)
+{
+    DEBUG (TARGET, 3,"store_registers %i\n", regno);
+
+    if (!thread_awareness_inhibited () && loaded) {
+	if (! ptid_equal (current_ptid, inferior_ptid)
+	    && thread_list_contains_pid (PIDGET (inferior_ptid))) {
+	    CORE_ADDR task_struct = get_current_task_struct ();
+	    thread_awareness_inhibit ();
+	    if (!linux_awareness_ops->lo_store_context_register (regno,
+								 task_struct)) {
+		thread_awareness_exhibit ();
+		error("Could not fetch task register.");
+	    }
+	    thread_awareness_exhibit ();
+	    return;
+	}
+    }
+
+    linux_aware_ops.beneath->to_store_registers (rc, regno);
+}
+
+static void
+normal_stop_callback (struct bpstats *bs)
+{
+    saved_singlestep_dest = 0;
+    singlestep_dest = ~(CORE_ADDR)0;
+    waiting_on_bp = 0;
+    force_hw_singlestep = 0;
+    normal_stop_pc = read_pc ();
+    normal_stop_sp = get_frame_sp ( get_current_frame() );
+
+    if (loaded) {
+	normal_stop_preempt_count = read_signed_field(linux_awareness_ops->lo_current_thread_info_address(),
+						      thread_info, preempt_count);
+    }
+
+    if (step_bp) {
+	delete_breakpoint(step_bp);
+	step_bp = NULL;
+    }
+
+    if (thread_event_do_exit_bp != NULL || thread_event_low_mem_bp != NULL) {
+	int has_bp = 0;
+	struct breakpoint *bp;
+
+	ALL_BREAKPOINTS (bp) {
+	    if (bp->loc->address
+		&& linux_awareness_ops->lo_is_user_address (bp->loc->address)) {
+		has_bp = 1;
+		break;
+	    }
+	}
+
+	if (!has_bp) {
+	    if (processes == NULL && thread_event_do_exit_bp != NULL) {
+		delete_breakpoint(thread_event_do_exit_bp);
+		thread_event_do_exit_bp = NULL;
+	    }
+	    if (thread_event_low_mem_bp != NULL) {
+		delete_breakpoint(thread_event_low_mem_bp);
+		thread_event_low_mem_bp = NULL;
+	    }
+	    has_userspace_breakpoint = 0;
+	}
+    }
+}
+
+static ptid_t
+linux_aware_wait (ptid_t ptid, struct target_waitstatus *status)
+{
+    CORE_ADDR singlestep_dest = singlestep_dest;
+    static int stopped_at_wrong_preempt_count = 0;
+    ptid_t res = linux_aware_pid_to_ptid (0);
+
+    if (!loaded || thread_awareness_inhibited ()) {
+	res = linux_aware_ops.beneath->to_wait (ptid, status);
+	running = 0;
+
+	if (linux_awareness_ops->lo_post_exec_stop)
+	    linux_awareness_ops->lo_post_exec_stop ();
+
+	return res;
+    }
+
+    thread_awareness_inhibit ();
+    DEBUG (TARGET, 2,"linux_aware_wait \n");
+    res = linux_aware_ops.beneath->to_wait (ptid, status);
+    running = 0;
+
+    if (linux_awareness_ops->lo_post_exec_stop)
+	linux_awareness_ops->lo_post_exec_stop ();
+
+    if (loaded) {
+	CORE_ADDR pc = read_pc ();
+	CORE_ADDR task_struct = linux_awareness_ops->lo_current_task_struct_address ();
+ 	unsigned int pid = read_unsigned_field (task_struct, task_struct, pid);
+	ptid_t ptid = linux_aware_pid_to_ptid (pid);
+	int new_last_pid = -1;
+
+	if (HAS_ADDR(init_pid_ns)) {
+	    /* Since STLinux 2.3 (2.6.23) */
+	    new_last_pid = read_signed_field(ADDR(init_pid_ns),
+					     pid_namespace, last_pid);
+	} else if (HAS_ADDR(last_pid)) {
+	    /* STLinux 2.0 and 2.2 (2.6.{11,17}) */
+	    new_last_pid = read_memory_integer(ADDR(last_pid), 4);
+	}
+
+	if (new_last_pid != last_pid) {
+	    last_pid = new_last_pid;
+	    thread_list_clear_cache();
+	}
+
+	DEBUG (TASK, 3,"linux_aware_wait : getting current process\n");
+	if ((shlib_event_load_bp && pc == shlib_event_load_bp->loc->address)
+	    || (shlib_event_init_bp && pc == shlib_event_init_bp->loc->address)
+	    || (shlib_event_free_bp && pc == shlib_event_free_bp->loc->address)
+	    || (thread_event_do_exit_bp && pc == thread_event_do_exit_bp->loc->address)
+	    || (thread_event_low_mem_bp && pc == thread_event_low_mem_bp->loc->address)
+	    || (thread_event_do_exec_bp && pc == thread_event_do_exec_bp->loc->address)) {
+	    switch_to_user_process (NULL);
+	    stick_to_kernelspace = 1;
+	}
+
+	DEBUG (TASK, 3,"linux_aware_wait : pid => %i\n", pid);
+	current_ptid = res = ptid;
+	DEBUG (TASK, 3,"linux_aware_wait : ptid => %i\n", PIDGET (res));
+
+	if (!in_thread_list (res)) {
+	    add_thread (res);
+	}
+
+	if (!current_user_process
+	    || current_user_process->pid != pid) {
+	    switch_to_user_process (get_current_process ());
+	}
+
+	if (!current_user_process
+	    && linux_awareness_ops->lo_is_user_address (pc)) {
+	    ptid_t saved_ptid = inferior_ptid;
+	    inferior_ptid = current_ptid;
+	    linux_read_process_symbols ();
+	    inferior_ptid = saved_ptid;
+	}
+
+	if (thread_event_do_exit_bp != NULL
+	    && pc == ADDR (do_exit)) {
+	    int thread_id = pid_to_thread_id (current_ptid);
+	    DEBUG (USER, 2, "Process has ended (pid %i)\n",
+		   PIDGET (current_ptid));
+	    delete_user_process (thread_id);
+	    thread_list_needs_clearing = 1;
+	} else if (thread_event_low_mem_bp != NULL
+		   && pc == thread_event_low_mem_bp->loc->address) {
+	    disable_userspace_breakpoints();
+	} else if (thread_event_do_exec_bp != NULL
+		   && pc == thread_event_do_exec_bp->loc->address) {
+	    thread_event_do_exec_return_bp
+		= create_thread_event_breakpoint(linux_awareness_ops->lo_return_address_at_start_of_function());
+	} else if (thread_event_do_exec_return_bp != NULL
+		   && pc == thread_event_do_exec_return_bp->loc->address) {
+	    if (thread_event_do_exec_bp != NULL) {
+		delete_breakpoint(thread_event_do_exec_bp);
+		thread_event_do_exec_bp = NULL;
+	    }
+	    check_exec_actions();
+	}
+
+	if (/* stoped after step_bp */
+	    (saved_singlestep_dest
+	     && ptid_equal(current_ptid, saved_singlestep_ptid))
+	    ||
+	    /* stopped after nice singlstep */
+	    (singlestep_dest != ~(CORE_ADDR)0
+	     && ptid_equal(current_ptid, singlestep_ptid))) {
+	    CORE_ADDR sp = get_frame_sp( get_current_frame() );
+
+	    if (normal_stop_sp == sp)
+		normal_stop_preempt_count = read_signed_field(linux_awareness_ops->lo_current_thread_info_address(),
+							      thread_info, preempt_count);
+	    else if (read_signed_field(linux_awareness_ops->lo_current_thread_info_address(),
+				       thread_info, preempt_count) == normal_stop_preempt_count)
+		normal_stop_sp = sp;
+	    else {
+		warning("\
+The code you were stepping has been preempted and the preemting task\n\
+or interrupt has executed this exact same code. You should be able to\n\
+find the frame you were stepping in the backtrace and to break there there.");
+#if 0
+		/* This will not match an existing ptid, but at the
+		   same time won't generate a new thread event. */
+		res = minus_one_ptid;
+		stopped_at_wrong_preempt_count = 1;
+#endif
+	    }
+	} else if (stopped_at_wrong_preempt_count) {
+#if 0
+	    /* stopped_at_wrong_preempt_count will force a hardware
+	       singlestep, so the condition that the flag is set is
+	       sufficient.  */
+	    stopped_at_wrong_preempt_count = 0;
+	    res = minus_one_ptid;
+#endif
+	    ;
+	}
+
+	if (saved_singlestep_dest) {
+	    /* If we come here, we must have set a step_resume_bp
+	       (otherwise saved_singlestep_dest would be zero).  */
+	    if (ptid_equal(res, saved_singlestep_ptid)) {
+		if (saved_singlestep_dest + 4 == pc) {
+		    /* Wait, we were singlestepping a thread and we
+		       don't arrive on the right instruction ?!
+		       Bullshit.  */
+		    warning("PC fixup after step_bp! %s != %s",
+			    paddr (saved_singlestep_dest), paddr (pc));
+		    write_pc(saved_singlestep_dest);
+		    pc = saved_singlestep_dest;
+		}
+
+		/* Good thread, good PC. The singlestep is finally
+		   over !  */
+		saved_singlestep_dest = 0;
+		if (step_bp) {
+		    delete_breakpoint(step_bp);
+		    step_bp = NULL;
+		}
+	    }
+	} else if (singlestep_dest != ~(CORE_ADDR)0) {
+	    if (singlestep_dest + 4 == pc
+		&& !breakpoint_here_p(pc)) {
+		warning("PC fixup after singlstep %s != %s",
+			paddr (singlestep_dest), paddr (pc));
+		write_pc(singlestep_dest);
+		pc = singlestep_dest;
+	    }
+
+	    if (!ptid_equal(res, singlestep_ptid)) {
+		/* We singlestepped into the wrong wrong thread.  */
+		DEBUG (TARGET, 2, "Ooops, wrong thread !\n");
+		saved_singlestep_ptid = singlestep_ptid;
+		saved_singlestep_dest = singlestep_dest;
+		if (pc == singlestep_dest)
+		    force_hw_singlestep = 1;
+	    }
+	}
+
+	if (waiting_on_bp && step_bp) {
+	    delete_breakpoint(step_bp);
+	    step_bp = NULL;
+	}
+    }
+
+    singlestep_dest = ~(CORE_ADDR)0;
+    thread_awareness_exhibit ();
+
+    DEBUG (TARGET, 2,"linux_aware_waited : %i %i pc : %s pid: %i\n",
+	   status->kind, status->value.sig, paddr (read_pc_pid (res)), PIDGET(res));
+
+    return res;
+}
+
+static void
+try_to_step_on_unmapped_page (CORE_ADDR dest)
+{
+    CORE_ADDR faulty_addr = linux_awareness_ops->lo_translate_memory_watch_address (dest, get_current_task_struct ());
+    struct monitored_page *res = find_monitored_page (faulty_addr);
+    struct symtab_and_line sal;
+    struct breakpoint *bp;
+
+    if (res == NULL) {
+	int i, other_type_used, target_resources_ok;
+	i = hw_watchpoint_used_count (bp_hardware_watchpoint, &other_type_used);
+	target_resources_ok =
+	    TARGET_CAN_USE_HARDWARE_WATCHPOINT (bp_hardware_watchpoint, i + 1,
+						other_type_used);
+	if (target_resources_ok <= 0)
+	    error ("\
+You're about to step on an unmapped page. To this pupose, the debugger needs\n\
+a hardware watcpoint, but none are left. If you really want to step you must\n\
+disable one of the used HW watchpoints.");
+    }
+
+    /* From here, it shouldn;t fail */
+    init_sal (&sal);		/* initialize to zeroes */
+
+    sal.pc = dest;
+    sal.section = find_pc_overlay (sal.pc);
+
+    bp = set_raw_breakpoint (sal, bp_breakpoint);
+    set_breakpoint_count (breakpoint_count+1);
+    bp->number = breakpoint_count;
+    bp->disposition = disp_del;
+    bp->enable_state = bp_disabled;
+
+    if (res == NULL)
+	res = create_monitored_page (faulty_addr, bp);
+    else
+	add_bpt_to_monitored_page (res, bp);
+}
+
+static void
+linux_aware_context_hook(int id)
+{
+    if (waiting_on_bp) {
+	inferior_ptid = current_ptid;
+
+	/* We can do context_switch in the middle of a step, and GDB isn't
+	   prepared for that.  The information it might leave lying around
+	   will cause problems on later runs.  */
+	if (saved_singlestep_dest) {
+	    CORE_ADDR prev_pc, step_range_start, step_range_end;
+	    int trap_expected, handling_longjmp, another_trap;
+	    int stepping_through_solib_after_catch, current_line;
+	    struct breakpoint *step_resume_breakpoint;
+	    struct frame_id step_frame_id;
+	    bpstat stepping_through_solib_catchpoints;
+	    struct symtab *current_symtab;
+	    load_infrun_state (saved_singlestep_ptid, &prev_pc,
+			       &trap_expected, &step_resume_breakpoint,
+			       &step_range_start, &step_range_end,
+			       &step_frame_id, &handling_longjmp,
+			       &another_trap, &stepping_through_solib_after_catch,
+			       &stepping_through_solib_catchpoints,
+			       &current_line, &current_symtab);
+
+	    step_range_start = step_range_end = 0;
+	    another_trap = trap_expected = 0;
+
+	    save_infrun_state (saved_singlestep_ptid, prev_pc,
+			       trap_expected, step_resume_breakpoint,
+			       step_range_start, step_range_end,
+			       &step_frame_id, handling_longjmp,
+			       another_trap,stepping_through_solib_after_catch,
+			       stepping_through_solib_catchpoints,
+			       current_line, current_symtab);
+	}
+	saved_singlestep_dest = 0;
+    }
+
+    if (deprecated_context_chain)
+	deprecated_context_chain(id);
+}
+
+static int
+bpstat_should_stop(bpstat bs)
+{
+    while (bs) {
+	if (bs->stop) {
+	    return 1;
+	}
+	bs = bs->next;
+    }
+
+    return 0;
+}
+
+static int
+linux_aware_software_single_step (struct frame_info *frame)
+{
+    /* Be sure that an interpreter_exec didn't remove that hook. */
+    CORE_ADDR pc = get_frame_pc (frame);
+    deprecated_context_hook = linux_aware_context_hook;
+
+    singlestep_ptid = inferior_ptid;
+
+    if (saved_singlestep_dest
+	&& ptid_equal(singlestep_ptid, saved_singlestep_ptid)) {
+	DEBUG (TARGET, 2, "Singlestepping to: %s (retry)\n",
+	       paddr (singlestep_dest));
+	singlestep_dest = saved_singlestep_dest;
+	/* This should be reset if we fail the next step.  */
+	saved_singlestep_dest = 0;
+	force_hw_singlestep = 0;
+    } else {
+	/* Analyse the present instruction environment and insert
+	   breakpoints.  */
+	singlestep_dest = linux_awareness_ops->lo_single_step_destination (pc);
+	DEBUG (TARGET, 2, "Singlestepping to: %s\n", paddr (singlestep_dest));
+    }
+
+    /* This is ugly, but it's the only way we can correctly handle
+       single-stepping from a breakpoint */
+    if (breakpoint_here_p (pc)) {
+	/* First check for obvious conditions where we know that
+	   we'll launch execution again.  */
+	if (pc == normal_stop_pc
+	    || (shlib_event_load_bp && pc == shlib_event_load_bp->loc->address)
+	    || (shlib_event_init_bp && pc == shlib_event_init_bp->loc->address)
+	    || (shlib_event_free_bp && pc == shlib_event_free_bp->loc->address)
+	    || (thread_event_do_exit_bp && pc == thread_event_do_exit_bp->loc->address)
+	    || (thread_event_low_mem_bp && pc == thread_event_low_mem_bp->loc->address)
+	    || (thread_event_do_exec_bp && pc == thread_event_do_exec_bp->loc->address)
+	    || (thread_event_do_exec_return_bp && pc == thread_event_do_exec_return_bp->loc->address)
+	    || !breakpoint_thread_match(pc, current_ptid)) {
+	    force_hw_singlestep = 1;
+	} else {
+	    /* Handle break conditions... We can't wait on a
+	       breakpoint if its condition is false, It would
+	       cause infrun to go in a infinite loop. */
+	    if (stop_bpstat) {
+		waiting_on_bp = bpstat_should_stop(stop_bpstat);
+	    } else {
+		bpstat bps;
+		bps = bpstat_stop_status(pc, current_ptid);
+		waiting_on_bp = bpstat_should_stop(bps);
+		bpstat_clear(&bps);
+	    }
+
+	    if (!waiting_on_bp)
+		force_hw_singlestep = 1;
+	}
+    }
+
+    if (breakpoint_here_p (singlestep_dest)
+	|| (force_hw_singlestep && !waiting_on_bp))
+      singlestep_dest = ~(CORE_ADDR)0;
+    else {
+	CORE_ADDR translated_dest = singlestep_dest;
+	if (! translate_memory_address_safe (&translated_dest, 1)) {
+	    singlestep_dest = ~(CORE_ADDR)0;
+	    /* This call can error() */
+	    try_to_step_on_unmapped_page (translated_dest);
+	    warning ("\
+You are stepping to a page that isn't currently mapped to memory. The\n\
+debugger will stop the execution after the page has been loaded and stop\n\
+before its first instruction is executed.");
+	}
+    }
+
+    insert_single_step_breakpoint (singlestep_dest);
+
+    /* Insert breakpoints. This needs thread awareness because of
+       userspace debug. No need for breakpoints if we use an HW
+       step.  */
+    if (!force_hw_singlestep)
+	insert_breakpoints ();
+
+    return 1;
+}
+
+static char *
+read_dentry (CORE_ADDR dentry)
+{
+    CORE_ADDR parent, name;
+    char *res, *tmp;
+    unsigned int len;
+
+    parent = read_pointer_field (dentry, dentry, d_parent);
+
+    if (parent == dentry) {
+	res =  xmalloc (1);
+	res[0] = '\0';
+	return res;
+    }
+
+    len = read_unsigned_embedded_field (dentry, qstr, len, dentry, d_name);
+    tmp = read_dentry (parent);
+    res = xmalloc (strlen (tmp) + 1 /* slash */ + len + 1 /* '\0' */);
+    sprintf (res, "%s/", tmp);
+    name = read_pointer_embedded_field (dentry, qstr, name, dentry, d_name);
+    read_memory_string (name, res + strlen (tmp) + 1, len + 1);
+    xfree (tmp);
+    return res;
+}
+
+static void
+pmap_command (char *args, int from_tty)
+{
+    CORE_ADDR task = get_current_task_struct ();
+    CORE_ADDR mm = read_pointer_field (task, task_struct, mm);
+    CORE_ADDR mmap;
+    unsigned int size, total = 0, writable = 0, shared = 0;
+
+    if (!mm) {
+	printf_filtered ("\tKernel thread\n");
+	return;
+    }
+
+    printf_filtered ("Start         Size Perm Mapping\n");
+
+    mmap = read_pointer_field (mm, mm_struct, mmap);
+    while (mmap) {
+	CORE_ADDR file;
+
+#define VM_READ		0x00000001	/* currently active flags */
+#define VM_WRITE	0x00000002
+#define VM_EXEC		0x00000004
+#define VM_SHARED	0x00000008
+
+#define VM_MAYREAD	0x00000010	/* limits for mprotect() etc */
+#define VM_MAYWRITE	0x00000020
+#define VM_MAYEXEC	0x00000040
+#define VM_MAYSHARE	0x00000080
+
+#define VM_GROWSDOWN	0x00000100	/* general info on the segment */
+#define VM_GROWSUP	0x00000200
+
+	unsigned int flags;
+	CORE_ADDR start, end;
+
+	flags = read_unsigned_field (mmap, vm_area_struct, vm_flags);
+	start = read_pointer_field (mmap, vm_area_struct, vm_start);
+	end = read_pointer_field (mmap, vm_area_struct, vm_end);
+	file = read_pointer_field (mmap, vm_area_struct, vm_file);
+
+	size = (end-start)>>10;
+	total += size;
+	printf_filtered ("%s % 8dK %c%c%c%c ",
+			 paddr (start),
+			 size,
+			 flags & VM_READ ? 'r' : '-',
+			 flags & VM_WRITE ? 'w' : '-',
+			 flags & VM_EXEC ? 'x' : '-',
+			 flags & VM_MAYSHARE ? 's' : 'p');
+
+	if (flags & VM_WRITE)
+	    writable += size;
+
+	if (flags & VM_MAYSHARE)
+	    shared += size;
+
+	if (file) {
+	    CORE_ADDR dentry;
+	    char *filename;
+
+	    if (detected_version >= V2_6_23)
+		dentry = read_pointer_embedded_field (file, path, dentry,
+						      file, f_path);
+	    else
+		dentry = read_pointer_field (file, file, f_dentry);
+	    filename = read_dentry (dentry);
+	    printf_filtered ("%s\n", filename);
+	    xfree (filename);
+	} else if (flags & (VM_GROWSDOWN|VM_GROWSUP)) {
+	    printf_filtered ("[ stack ]\n");
+	} else {
+	    printf_filtered ("[ anon ]\n");
+	}
+
+	mmap = read_pointer_field (mmap, vm_area_struct, vm_next);
+    }
+
+#undef VM_READ
+#undef VM_WRITE
+#undef VM_EXEC
+#undef VM_SHARED
+
+#undef VM_MAYREAD
+#undef VM_MAYWRITE
+#undef VM_MAYEXEC
+#undef VM_MAYSHARE
+
+#undef VM_GROWSDOWN
+#undef VM_GROWSUP
+
+    printf_filtered ("mapped: %uK\twriteable/private: %uK\tshared: %uK\n",
+		     total, writable, shared);
+}
+
+static void
+print_proc_env (CORE_ADDR mm)
+{
+    unsigned long env_start = read_unsigned_field (mm,mm_struct, env_start);
+    unsigned long env_end =  read_unsigned_field (mm, mm_struct, env_end);
+    long len = env_end-env_start;
+    gdb_byte *buf = xmalloc (len+1);
+    int l = 0, i = 0;
+
+    read_memory (env_start, buf, len);
+    buf[len]='\0';
+
+    printf_filtered ("------ Environment ------\n");
+
+    while (len > l) {
+	printf_filtered ("environ[%i] = '%s'\n", i++, buf+l);
+	l += strlen ((char *)buf+l) + 1;
+    }
+
+    xfree (buf);
+}
+
+static void
+print_proc_cmdline (CORE_ADDR mm)
+{
+    unsigned long arg_start = read_unsigned_field (mm, mm_struct, arg_start);
+    unsigned long arg_end = read_unsigned_field (mm, mm_struct, arg_end);
+    unsigned long len = arg_end-arg_start;
+    gdb_byte *buf = xmalloc (len+1);
+    int l = 0, i = 0;
+
+    read_memory (arg_start, buf, len);
+    buf[len]='\0';
+
+    printf_filtered ("------ Command line ------\n");
+
+    while (len > l) {
+	printf_filtered ("argv[%i] = '%s'\n", i++, buf+l);
+	l += strlen ((char *)buf+l) + 1;
+    }
+    xfree (buf);
+}
+
+static char *
+get_proc_exe (CORE_ADDR mm)
+{
+#define VM_EXECUTABLE    0x00001000
+    CORE_ADDR mmap = read_pointer_field (mm, mm_struct, mmap);
+    CORE_ADDR file;
+    unsigned int flags;
+
+    while (mmap) {
+	flags = read_unsigned_field (mmap, vm_area_struct, vm_flags);
+	if (flags & VM_EXECUTABLE) {
+	    file = read_pointer_field (mmap, vm_area_struct, vm_file);
+	    if (file) {
+		if (detected_version >= V2_6_23)
+		    return read_dentry (read_pointer_embedded_field (file,
+								     path, dentry,
+								     file, f_path));
+		else
+		    return read_dentry (read_pointer_field (file,
+							    file, f_dentry));
+	    }
+	    break;
+	}
+	mmap = read_pointer_field (mmap, vm_area_struct, vm_next);
+    }
+
+    return NULL;
+}
+
+static void
+print_proc_exe (CORE_ADDR mm)
+{
+    char *filename = get_proc_exe (mm);
+
+    if (filename != NULL)
+	printf_filtered ("exe: %s\n", filename);
+    else
+	printf_filtered ("exe: Not found\n");
+
+    xfree (filename);
+}
+
+static void
+print_resource (CORE_ADDR resource, int depth, int width)
+{
+    CORE_ADDR next;
+    unsigned long start, end;
+    CORE_ADDR name_addr;
+    char buf[64];
+
+ begin:
+    start = read_unsigned_field (resource, resource, start);
+    end = read_unsigned_field (resource, resource, end);
+    name_addr = read_pointer_field (resource, resource, name);
+
+    if (name_addr) {
+	read_memory_string (name_addr, buf, 64);
+	buf[63] = '\0';
+    }
+
+    printf_filtered ("%*s%0*lx-%0*lx : %s\n",
+		     depth * 2, "",
+		     width, start,
+		     width, end,
+		     name_addr ? buf : "<BAD>");
+
+    next = read_pointer_field (resource, resource, child);
+    if (next)
+	print_resource (next, depth+1, width);
+
+    next = read_pointer_field (resource, resource, sibling);
+    if (next) {
+	resource = next;
+	goto begin;
+    }
+}
+
+static void
+print_resources (CORE_ADDR resource)
+{
+    int depth = 0;
+    int width = read_unsigned_field (resource, resource, end) < 0x10000 ? 4 : 8;
+    CORE_ADDR first = read_pointer_field (resource, resource, child);
+    print_resource (first, 0, width);
+}
+
+static void
+iomem_command (char *args, int from_tty)
+{
+    print_resources (ADDR (iomem_resource));
+}
+
+static void
+ioports_command(char *args, int from_tty)
+{
+    print_resources (ADDR (ioport_resource));
+}
+
+static void
+process_info_command (char *args, int from_tty)
+{
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task = ps->task_struct_address;
+    CORE_ADDR mm = read_pointer_field (task, task_struct, mm);
+
+    if (ps->prio>99) {
+        printf_filtered ("Comm: %s (pid %i, prio %i, nice %i, rtprio --)\n",
+                          ps->comm, ps->pid, 139-(ps->prio), 19-(139-(ps->prio)));
+    } else {
+	printf_filtered ("Comm: %s (pid %i, prio %i, nice --, rtprio %i)\n",
+                          ps->comm, ps->pid, 139-(ps->prio), 99-(ps->prio));
+    }
+
+    if (!mm) {
+	printf_filtered ("\tKernel thread\n");
+	return;
+    }
+
+    print_proc_exe (mm);
+    print_proc_cmdline (mm);
+    print_proc_env (mm);
+}
+
+static char *
+printf_dmesg (char *buf)
+{
+    int len = strlen (buf);
+    char* newline = strchr (buf, '\n');
+    char* full_buf = buf;
+
+    while (newline != NULL) {
+
+	if (newline - full_buf > len - 4) {
+	    *newline = '\0';
+	    printf_filtered ("%s", buf);
+	    *newline = '\n';
+	    return newline;
+	}
+
+	if (newline[1] == '<'
+	    && newline[2] >= '0' && newline[2] <= '7'
+	    && newline[3] == '>') {
+	    newline[1] = '\0';
+	    printf_filtered ("%s", buf);
+	    buf = newline + 4;
+	} else {
+	    *newline = '\0';
+	    printf_filtered ("%s\n", buf);
+	    buf = newline+1;
+	}
+
+	newline = strchr (buf, '\n');
+    }
+
+    printf_filtered ("%s", buf);
+    return "";
+}
+
+static void
+dmesg_command (char *args, int from_tty)
+{
+    unsigned int log_len = read_memory_unsigned_integer (ADDR (log_buf_len),
+							 TYPE_LENGTH(builtin_type_int));
+    CORE_ADDR buf_end = ADDR (__log_buf) + log_len;
+    unsigned long log_end = read_memory_unsigned_integer (ADDR (log_end),
+							  TYPE_LENGTH(builtin_type_unsigned_long)) & (log_len - 1);
+    CORE_ADDR log_start = log_end > log_len ?
+	((log_end) & (log_len - 1)) + ADDR (__log_buf)
+	: ADDR (__log_buf);
+    CORE_ADDR buf_start = log_start;
+    int last_ended_with_newline = 0;
+    char *buf = alloca (log_chunk_size+1);
+    char *buf2 = alloca (log_chunk_size*2);
+    char *tmp;
+
+    buf[log_chunk_size] = '\0';
+    buf2[0] = '\n'; buf2[1] = '\0';
+
+    do {
+	if (buf_start + log_chunk_size >= buf_end) {
+	    read_memory (buf_start, (gdb_byte *)buf, buf_end - buf_start);
+	    buf[buf_end - buf_start] = '\0'; /* end the string */
+	    buf_start = ADDR (__log_buf);
+	} else if (buf_start < log_start
+		   && buf_start + log_chunk_size >= log_start) {
+	    read_memory (buf_start, (gdb_byte *)buf, log_start-buf_start);
+	    buf[log_start-buf_start] = '\0'; /* end the string */
+	    buf[log_chunk_size-1] = '\0'; /* stop the loop */
+	} else {
+	    read_memory (buf_start, (gdb_byte *)buf, log_chunk_size);
+	    buf_start += log_chunk_size;
+	}
+
+	QUIT;
+	tmp = printf_dmesg (strcat (buf2, buf));
+	strcpy (buf2, tmp);
+    } while (buf[log_chunk_size-1] != '\0');
+
+    printf_filtered ("\n");
+}
+
+static void
+vm_translate_command (char *args, int from_tty)
+{
+    CORE_ADDR addr = parse_and_eval_address(args);
+    CORE_ADDR phys = addr;
+
+    if (translate_memory_address_safe (&phys, 0))
+	printf_filtered ("\
+Virtual address %s translates to physical address %s in the current context.\n",
+			 hex_string (addr), hex_string (phys));
+}
+
+#define SEQ_MULTIPLIER 32768
+
+#define	SHM_DEST	01000	/* segment will be destroyed on last detach */
+#define SHM_LOCKED      02000   /* segment will not be swapped */
+
+static void
+print_shm_struct (CORE_ADDR shm)
+{
+    unsigned int segsz, nattch, mode;
+
+    nattch = read_unsigned_field (shm, shmid_kernel, shm_nattch);
+    segsz = read_unsigned_field (shm, shmid_kernel, shm_segsz);
+    mode = read_unsigned_field (shm, kern_ipc_perm, mode);
+
+    printf_filtered ("%-10i %-10i %s %s", segsz, nattch,
+		     mode & SHM_DEST ? "dest" : "",
+		     mode & SHM_LOCKED ? "locked" : "");
+}
+
+static void
+print_sem_array_struct (CORE_ADDR sem_array)
+{
+    unsigned int nsems;
+    nsems = read_unsigned_field (sem_array, sem_array, sem_nsems);
+    printf_filtered ("%-10i", nsems);
+}
+
+static void
+print_msg_struct (CORE_ADDR msg)
+{
+    unsigned int bytes, num;
+    bytes = read_unsigned_field (msg, msg_queue, q_cbytes);
+    num = read_unsigned_field (msg, msg_queue, q_qnum);
+
+    printf_filtered ("%-10i %-10i", bytes, num);
+}
+
+static void
+print_ipc_ids_struct (CORE_ADDR ids,
+		      void (*specialized_printer)(CORE_ADDR))
+{
+    int in_use = read_signed_field (ids, ipc_ids, in_use);
+    CORE_ADDR entries, entry;
+    unsigned int i, size, id, seq;
+    gdb_byte *buf;
+
+    if (!in_use) {
+	printf_filtered ("None\n");
+	return;
+    }
+
+    entries = read_pointer_field (ids, ipc_ids, entries);
+    size = read_unsigned_field (entries, ipc_id_ary, size);
+
+    buf = xmalloc (F_SIZE (ipc_id_ary, size) + TYPE_LENGTH(builtin_type_void_data_ptr)*size);
+    read_memory (entries, buf, F_SIZE (ipc_id_ary, size) + TYPE_LENGTH(builtin_type_void_data_ptr)*size);
+
+    for (i = 0; i < size; ++i) {
+	entry = extract_typed_address (buf+F_OFFSET (ipc_id_ary, p)+TYPE_LENGTH(builtin_type_void_data_ptr)*i,
+				       builtin_type_void_data_ptr);
+	if (!entry) continue;
+
+	seq = read_unsigned_field (entry, kern_ipc_perm, seq);
+	id = SEQ_MULTIPLIER*seq + i;
+
+	printf_filtered ("0x%08llx %-10i %-10i %-10o ",
+			 (unsigned long long)read_unsigned_field (entry,
+								  kern_ipc_perm,
+								  key),
+			 id,
+			 (int)read_unsigned_field (entry, kern_ipc_perm, uid),
+			 (int)(0777 & read_unsigned_field (entry,
+							   kern_ipc_perm, mode))
+			 );
+	if (specialized_printer)
+	    specialized_printer (entry);
+
+	printf_filtered ("\n");
+    }
+
+    xfree (buf);
+}
+
+static void
+ipcs_command (char *args, int from_tty)
+{
+    CORE_ADDR shm_addr, sem_addr, msg_addr;
+
+    if (detected_version < V2_6_23) {
+	shm_addr = ADDR (shm_ids);
+	sem_addr = ADDR (sem_ids);
+	msg_addr = ADDR (msg_ids);
+    } else {
+	CORE_ADDR addr = get_current_task_struct ();
+	addr = read_pointer_field (addr, task_struct, nsproxy);
+	addr = read_pointer_field (addr, nsproxy, ipc_ns);
+	addr += F_OFFSET(ipc_namespace, ids);
+	sem_addr = read_memory_typed_address(addr, builtin_type_void_data_ptr);
+	addr += TYPE_LENGTH(builtin_type_void_data_ptr);
+	msg_addr = read_memory_typed_address(addr, builtin_type_void_data_ptr);
+	addr += TYPE_LENGTH(builtin_type_void_data_ptr);
+	shm_addr = read_memory_typed_address(addr, builtin_type_void_data_ptr);
+    }
+
+    printf_filtered ("------ Shared Memory Segments ------\n");
+    printf ("%-10s %-10s %-10s %-10s %-10s %-10s %-10s\n",
+	    "key","shmid","owner","perms", "bytes", "nattch", "status");
+    print_ipc_ids_struct (shm_addr, print_shm_struct);
+
+    printf_filtered ("\n------ Semaphore Arrays ------\n");
+    printf ("%-10s %-10s %-10s %-10s %-10s\n",
+	    "key","semid","owner","perms",
+	    "nsems");
+    print_ipc_ids_struct (sem_addr, print_sem_array_struct);
+
+    printf_filtered ("\n------ Message Queues ------\n");
+    printf ("%-10s %-10s %-10s %-10s %-10s %-10s\n",
+	    "key","msgid","owner","perms", "used-bytes", "messages");
+    print_ipc_ids_struct (msg_addr, print_msg_struct);
+}
+
+static char*
+get_banner_from_file ()
+{
+    static char banner[256];
+    int i = 0;
+    CORE_ADDR banner_addr = ADDR (linux_banner);
+    asection* data = bfd_get_section_by_name (exec_bfd, ".rodata");
+
+    /* It seems that on STLinux ARM, the banner gets stored in .text,
+       and there's no .rodata. */
+    if (data == NULL)
+	data = bfd_get_section_by_name (exec_bfd, ".text");
+
+    if (data == NULL)
+	return NULL;
+
+    if (banner_addr < bfd_get_section_vma (exec_bfd, data)
+	|| banner_addr >= bfd_get_section_vma (exec_bfd,data)+bfd_get_section_size(data))
+	return NULL;
+
+    bfd_seek (exec_bfd, data->filepos + banner_addr - bfd_get_section_vma (exec_bfd, data), SEEK_SET);
+
+    while (i<256) {
+	bfd_bread (banner + i, 1, exec_bfd);
+	if (banner[i++] == '\0')
+	    break;
+    }
+
+    return banner;
+}
+
+static char*
+get_banner ()
+{
+    if (loaded) {
+	static char banner[256];
+
+	read_memory_string (ADDR (linux_banner), banner, 256);
+	banner[255] = '\0';
+
+	return banner;
+    }
+
+    return get_banner_from_file ();
+}
+
+static unsigned long
+get_buffered_ram (unsigned long *buffered_pages, unsigned long *swapcache_pages)
+{
+    int address_space__nrpages_size = 0;
+    int address_space__nrpages_offset = 0;
+    struct type *type;
+    struct symbol *sym;
+    char *error_msg = NULL;
+    int i;
+    CORE_ADDR all_bdevs = 0;
+    CORE_ADDR next;
+
+    if (! HAS_ADDR (all_bdevs)) {
+	error_msg = "Can't find the all_bdevs variable";
+	goto error;
+    }
+    all_bdevs = ADDR (all_bdevs);
+
+    error_msg = "Can't find the struct address_space definition";
+
+    /* GCC generates the description of ``struct address_space'' only
+       in function scopes, which means it won't be put in GDB's global
+       struct type list. We have to get it's description by some other
+       way. */
+    if (!HAS_FIELD(inode, i_mapping))
+	goto error;
+
+    sym = FIELD_INFO (inode, i_mapping).type;
+    type = SYMBOL_TYPE (sym);
+
+    /* Type is struct inode.  */
+    CHECK_TYPEDEF (type);
+
+    for (i=0; i<TYPE_NFIELDS (type); ++i)
+	if (! strcmp (FIELD_NAME (TYPE_FIELDS (type)[i]), "i_mapping"))
+	    break;
+
+    if (i >= TYPE_NFIELDS (type))
+	goto error;
+
+    type = FIELD_TYPE (TYPE_FIELDS (type)[i]);
+    CHECK_TYPEDEF (type);
+
+    /* Type should be ptr to struct address_space.  */
+    if (TYPE_CODE (type) != TYPE_CODE_PTR)
+	goto error;
+
+    type = TYPE_TARGET_TYPE (type);
+    CHECK_TYPEDEF (type);
+
+    /* Type should be struct address_space.  */
+    if (TYPE_CODE (type) != TYPE_CODE_STRUCT)
+	goto error;
+
+    for (i=0; i<TYPE_NFIELDS (type); ++i)
+	if (! strcmp (FIELD_NAME(TYPE_FIELDS (type)[i]), "nrpages"))
+	    break;
+
+    if (i >= TYPE_NFIELDS (type))
+	goto error;
+
+    address_space__nrpages_offset = FIELD_BITPOS (TYPE_FIELDS (type)[i])/TARGET_CHAR_BIT;
+    address_space__nrpages_size = TYPE_LENGTH (check_typedef (TYPE_FIELDS (type)[i].type));
+
+    for (next = read_pointer_field (all_bdevs, list_head, next);
+	 next != all_bdevs;
+	 next = read_pointer_field (next, list_head, next)) {
+	CORE_ADDR bdev = next - F_OFFSET (block_device, bd_list);
+	CORE_ADDR inode = read_pointer_field (bdev, block_device, bd_inode);
+	CORE_ADDR mapping = read_pointer_field (inode, inode, i_mapping);
+	*buffered_pages += read_memory_unsigned_integer (mapping + address_space__nrpages_offset,
+							 address_space__nrpages_size);
+    }
+
+    if (HAS_ADDR (swapper_space)) {
+	*swapcache_pages = read_memory_unsigned_integer (ADDR (swapper_space) + address_space__nrpages_offset,
+							 address_space__nrpages_size);
+    }
+
+    return 1;
+ error:
+    warning ("%s. Buffers numbers won't be accurate.", error_msg);
+    return 0;
+}
+
+static void
+get_swap (unsigned long *totalswap, unsigned long *freeswap)
+{
+    unsigned int i;
+    unsigned long nr_swap_pages = 0;
+    unsigned long total_swap_pages = 0;
+    unsigned long nr_swapfiles = 0;
+    unsigned long nr_to_be_unused = 0;
+    unsigned long swap_info_size = 0;
+    struct symbol *sym;
+    CORE_ADDR swap_info;
+
+    enum {
+	SWP_USED	= (1 << 0),	/* is slot in swap_info[] used? */
+	SWP_WRITEOK	= (1 << 1),	/* ok to write to this swap?	*/
+	SWP_ACTIVE	= (SWP_USED | SWP_WRITEOK),
+    };
+
+    if (!HAS_ADDR (nr_swap_pages)
+	|| !HAS_ADDR (totalswap_pages)
+	|| !HAS_ADDR (nr_swapfiles)
+	|| !HAS_ADDR (swap_info))
+	return;
+
+    nr_swap_pages = read_memory_unsigned_integer (ADDR (nr_swap_pages),
+						  TYPE_LENGTH (builtin_type_unsigned_long));
+    total_swap_pages = read_memory_unsigned_integer (ADDR (totalswap_pages),
+						     TYPE_LENGTH (builtin_type_long));
+    nr_swapfiles = read_memory_unsigned_integer (ADDR (nr_swapfiles),
+						 TYPE_LENGTH (builtin_type_unsigned_int));
+    swap_info = ADDR (swap_info);
+
+    if (!HAS_FIELD(swap_info_struct, flags))
+	return;
+
+    sym = FIELD_INFO (swap_info_struct, flags).type;
+    swap_info_size = TYPE_LENGTH (SYMBOL_TYPE (sym));
+
+    for (i = 0; i < nr_swapfiles; i++) {
+	unsigned long flags = read_unsigned_field (swap_info + i*swap_info_size,
+						   swap_info_struct, flags);
+	if (!(flags & SWP_USED) ||
+	    (flags & SWP_WRITEOK))
+	    continue;
+	nr_to_be_unused += read_unsigned_field (swap_info + i*swap_info_size,
+						swap_info_struct, inuse_pages);
+    }
+
+    *freeswap = nr_swap_pages + nr_to_be_unused;
+    *totalswap = total_swap_pages + nr_to_be_unused;
+}
+
+#define K(x) (unsigned long)((x) << (linux_awareness_ops->page_shift - 10))
+
+
+
+static void
+proc_meminfo_command (char *args, int from_tty)
+{
+
+    unsigned long totalram = 0;
+    unsigned long totalhigh = 0;
+    unsigned long free_pages = 0;
+    unsigned long active_pages = 0;
+    unsigned long inactive_pages = 0;
+    unsigned long free_highpages = 0;
+    unsigned long buffered_pages = 0;
+    unsigned long swapcache_pages = 0;
+    unsigned long pagecache_pages = 0;
+    unsigned long totalswap_pages = 0;
+    unsigned long freeswap_pages = 0;
+    unsigned long dirty_pages = 0;
+    unsigned long mapped_pages = 0;
+    unsigned long writeback_pages = 0;
+    unsigned long slab_pages = 0;
+    unsigned long pagetable_pages = 0;
+    unsigned long vm_committed_space = 0;
+    unsigned long sysctl_overcommit_ratio = 0;
+    unsigned long nr_huge_pages = 0;
+    unsigned long committed = 0;
+    unsigned long allowed = 0;
+    unsigned long vmalloc = 0;
+    CORE_ADDR vmlist = 0;
+    unsigned int struct_zone_size;
+    CORE_ADDR pgdat;
+    CORE_ADDR page_states = 0;
+    unsigned int max_nr_zones = 3;
+    unsigned int zone_highmem = 2;
+
+    if (HAS_ADDR (per_cpu__page_states)) {
+	page_states = ADDR (per_cpu__page_states);
+	dirty_pages = read_unsigned_field (page_states, page_state, nr_dirty);
+	mapped_pages = read_unsigned_field (page_states, page_state, nr_mapped);
+	writeback_pages = read_unsigned_field (page_states,
+					       page_state, nr_writeback);
+	slab_pages = read_unsigned_field (page_states, page_state, nr_slab);
+	pagetable_pages = read_unsigned_field (page_states,
+					       page_state, nr_page_table_pages);
+    } else if (HAS_ADDR (vm_stat)) {
+	enum zone_stat_item {
+	    NR_FREE_PAGES,
+	    NR_INACTIVE,
+	    NR_ACTIVE,
+	    NR_ANON_PAGES,  /* Mapped anonymous pages */
+	    NR_FILE_MAPPED, /* pagecache pages mapped into pagetables.
+			       only modified from process context */
+	    NR_FILE_PAGES,
+	    NR_FILE_DIRTY,
+	    NR_WRITEBACK,
+	    NR_SLAB_RECLAIMABLE,
+	    NR_SLAB_UNRECLAIMABLE,
+	    NR_PAGETABLE,           /* used for pagetables */
+	    NR_UNSTABLE_NFS,        /* NFS unstable pages */
+	    NR_BOUNCE,
+	    NR_VMSCAN_WRITE
+	};
+
+	unsigned int size = TYPE_LENGTH (builtin_type_unsigned_long);
+	dirty_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						   + size*NR_FILE_DIRTY,
+						   size);
+	mapped_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						    + size*NR_FILE_MAPPED,
+						    size);
+	writeback_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						       + size*NR_WRITEBACK,
+						       size);
+	slab_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						  + size*NR_SLAB_RECLAIMABLE,
+						  size)
+	    + read_memory_unsigned_integer(ADDR(vm_stat)
+					   + size*NR_SLAB_UNRECLAIMABLE,
+					   size);
+	pagetable_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						       + size*NR_PAGETABLE,
+						       size);
+	pagecache_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						       + size*NR_FILE_PAGES,
+						       size);
+	active_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						    + size*NR_ACTIVE,
+						    size);
+	inactive_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						      + size*NR_INACTIVE,
+						      size);
+	free_pages = read_memory_unsigned_integer(ADDR(vm_stat)
+						  + size*NR_FREE_PAGES,
+						  size);
+    } else {
+	warning("\
+Can't find the per_cpu__page_states  variable. Numbers won't be accurate.");
+    }
+
+    if (HAS_ADDR (totalram_pages))
+	totalram = read_memory_unsigned_integer (ADDR (totalram_pages),
+						 TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	warning("\
+Can't find the totalram_pages variable. Total memory won't be accurate.");
+
+    if (HAS_ADDR (totalhigh_pages))
+	totalhigh = read_memory_unsigned_integer(ADDR (totalhigh_pages),
+						 TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	/* When compiled without HIGHMEM, totalhigh_pages is a
+	   #define to 0 */
+	totalhigh = 0;
+
+    if (HAS_ADDR (nr_pagecache))
+	pagecache_pages = read_memory_unsigned_integer(ADDR (nr_pagecache),
+						       TYPE_LENGTH(builtin_type_unsigned_long));
+    else if (!HAS_ADDR(vm_stat))
+	warning("\
+Can't find the nr_pagecache variable. Caches memory won't be accurate.");
+
+    if (HAS_ADDR (vm_committed_space))
+	vm_committed_space = read_memory_unsigned_integer(ADDR (vm_committed_space),
+							  TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	warning("\
+Can't find the vm_commited_space variable. Commited memory won't be accurate.");
+
+    if (HAS_ADDR (sysctl_overcommit_ratio))
+	sysctl_overcommit_ratio = read_memory_unsigned_integer(ADDR (sysctl_overcommit_ratio),
+							       TYPE_LENGTH(builtin_type_int));
+    else
+	warning("\
+Can't find the sysctl_overcommit_ratio variable. Commited memory won't be accurate.");
+
+    if (HAS_ADDR (vmlist))
+	vmlist = ADDR (vmlist);
+    else
+	warning("\
+Can't find the vmlist variable. Vmalloced memory won't be accurate.");
+
+    if (HAS_ADDR (nr_huge_pages))
+	nr_huge_pages = read_memory_unsigned_integer(ADDR (nr_huge_pages),
+						     TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	/* Might not be compiled in. */;
+
+    if (!HAS_ADDR(vm_stat)) {
+
+	if (HAS_ADDR (pgdat_list))
+	    /* Used for STLinux 2.0 (2.6.11) kernels */
+	    pgdat = read_memory_typed_address (ADDR (pgdat_list),
+					       builtin_type_void_data_ptr);
+	else {
+	    /* Used for STLinux 2.2 (2.6.17) kernels */
+	    pgdat = ADDR (contig_page_data);
+	    max_nr_zones = 4;
+	    zone_highmem = 3;
+	}
+
+	struct_zone_size = F_SIZE (pglist_data, node_zones) / max_nr_zones;
+
+	while (pgdat) {
+	    CORE_ADDR zone = pgdat+F_OFFSET (pglist_data, node_zones);
+	    unsigned long i, free;
+
+	    for (i = 0; i < max_nr_zones; ++i, zone += struct_zone_size) {
+		active_pages += read_unsigned_field (zone, zone, nr_active);
+		inactive_pages += read_unsigned_field (zone, zone, nr_inactive);
+		free = read_unsigned_field (zone, zone, free_pages);
+		free_pages += free;
+		if (i == zone_highmem) free_highpages += free;
+	    }
+
+	    if (! HAS_FIELD (pglist_data, pgdat_next))
+		/* It's not a list in linux 2.6.17 */
+		break;
+	    pgdat = read_pointer_field (pgdat, pglist_data, pgdat_next);
+	}
+    }
+
+    get_buffered_ram (&buffered_pages, &swapcache_pages);
+    get_swap (&totalswap_pages, &freeswap_pages);
+
+    committed = vm_committed_space;
+    allowed = totalram * sysctl_overcommit_ratio / 100 + totalswap_pages;
+
+    for (vmlist = read_memory_typed_address (vmlist,
+					     builtin_type_void_data_ptr);
+	 vmlist != 0;
+	 vmlist = read_pointer_field (vmlist, vm_struct, next)) {
+	vmalloc += read_unsigned_field (vmlist, vm_struct, size);
+    }
+
+    printf_filtered ("MemTotal:     %8lu kB\n"
+		     "MemFree:      %8lu kB\n"
+		     "Buffers:      %8lu kB\n"
+		     "Cached:       %8lu kB\n"
+		     "SwapCached:   %8lu kB\n"
+		     "Active:       %8lu kB\n"
+		     "Inactive:     %8lu kB\n"
+		     "HighTotal:    %8lu kB\n"
+		     "HighFree:     %8lu kB\n"
+		     "LowTotal:     %8lu kB\n"
+		     "LowFree:      %8lu kB\n"
+		     "SwapTotal:    %8lu kB\n"
+		     "SwapFree:     %8lu kB\n"
+		     "Dirty:        %8lu kB\n"
+		     "Writeback:    %8lu kB\n"
+		     "Mapped:       %8lu kB\n"
+		     "Slab:         %8lu kB\n"
+		     "CommitLimit:  %8lu kB (minus %lu huge pages)\n"
+		     "Committed_AS: %8lu kB\n"
+		     "PageTables:   %8lu kB\n"
+		     "VmallocUsed:  %8lu kB\n",
+		     K (totalram),
+		     K (free_pages),
+		     K (buffered_pages),
+		     K (pagecache_pages-swapcache_pages-buffered_pages),
+		     K (swapcache_pages),
+		     K (active_pages),
+		     K (inactive_pages),
+		     K (totalhigh),
+		     K (free_highpages),
+		     K (totalram-totalhigh),
+		     K (free_pages-free_highpages),
+		     K (totalswap_pages),
+		     K (freeswap_pages),
+		     K (dirty_pages),
+		     K (writeback_pages),
+		     K (mapped_pages),
+		     K (slab_pages),
+		     K (allowed),
+		     K (nr_huge_pages * sysctl_overcommit_ratio / 100),
+		     K (committed),
+		     K (pagetable_pages),
+		     vmalloc >> 10
+		     );
+
+}
+
+#undef K
+#undef MAX_NR_ZONES
+#undef ZONE_HIGHMEM
+
+static void
+proc_version_command (char *args, int from_tty)
+{
+    printf_filtered ("%s", get_banner());
+}
+
+static void
+proc_cmdline_command (char *args, int from_tty)
+{
+    static char cmdline[1024];
+    CORE_ADDR cmd_addr;
+
+    if (detected_version >= V2_6_23)
+	cmd_addr = read_memory_typed_address(ADDR (saved_command_line),
+					     builtin_type_void_data_ptr);
+    else
+	cmd_addr = ADDR (saved_command_line);
+
+    read_memory_string (cmd_addr, cmdline, 1024);
+    cmdline[1023] = '\0';
+
+    printf_filtered ("%s\n", cmdline);
+}
+
+static void
+proc_mounts_command (char *args, int from_tty)
+{
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task = ps->task_struct_address;
+    CORE_ADDR namespace;
+    CORE_ADDR list_head = 0, next_vfs, vfs, tmp, tmp2, sb;
+    static char buf[256];
+    char *str;
+    unsigned int flags, len;
+
+#define MS_RDONLY	 1	/* Mount read-only */
+#define MS_SYNCHRONOUS	16	/* Writes are synced at once */
+#define MS_MANDLOCK	64	/* Allow mandatory locks on an FS */
+#define MS_DIRSYNC	128	/* Directory modifications are synchronous */
+#define MS_NOATIME	1024	/* Do not update access times. */
+#define MS_NODIRATIME	2048	/* Do not update directory access times */
+
+#define MNT_NOSUID	0x01
+#define MNT_NODEV	0x02
+#define MNT_NOEXEC	0x04
+#define MNT_NOATIME     0x08
+#define MNT_NODIRATIME  0x10
+#define MNT_RELATIME    0x20
+
+
+    static struct proc_fs_info {
+	int flag;
+	char *str;
+    } fs_info[] = {
+	{ MS_SYNCHRONOUS, ",sync" },
+	{ MS_DIRSYNC, ",dirsync" },
+	{ MS_MANDLOCK, ",mand" },
+	{ MS_NOATIME, ",noatime" },
+	{ MS_NODIRATIME, ",nodiratime" },
+	{ 0, NULL }
+    };
+    static struct proc_fs_info mnt_info[] = {
+	{ MNT_NOSUID, ",nosuid" },
+	{ MNT_NODEV, ",nodev" },
+	{ MNT_NOEXEC, ",noexec" },
+	{ MNT_NOATIME, ",noatime" },
+	{ MNT_NODIRATIME, ",nodiratime" },
+	{ MNT_RELATIME, ",relatime" },
+	{ 0, NULL }
+    };
+    struct proc_fs_info *fs_infop;
+
+    buf[255] = '\0';
+
+    if (detected_version >= V2_6_23) {
+	namespace = read_pointer_field (task, task_struct, nsproxy);
+	namespace = read_pointer_field (namespace, nsproxy, mnt_ns);
+	if (!namespace) {
+	    printf_filtered ("\
+\tNo namespace for current process. Kernel thread?\n");
+	    return;
+	}
+
+	list_head = namespace + F_OFFSET (mnt_namespace, list);
+    } else {
+	namespace = read_pointer_field (task, task_struct, namespace);
+	if (!namespace) {
+	    printf_filtered ("\
+\tNo namespace for current process. Kernel thread?\n");
+	    return;
+	}
+
+	list_head = namespace + F_OFFSET (namespace, list);
+    }
+
+    next_vfs = read_pointer_field (list_head, list_head, next);
+
+    while (next_vfs != list_head) {
+	vfs = next_vfs - F_OFFSET (vfsmount, mnt_list);
+
+	tmp = read_pointer_field (vfs, vfsmount, mnt_devname);
+	if (tmp)
+	    read_memory_string (tmp, buf, 255);
+	else
+	    strcpy(buf, "none");
+	printf_filtered ("%s ", buf);
+
+	tmp2 = vfs;
+	len = 0;
+	do {
+	    tmp = read_pointer_field (tmp2, vfsmount, mnt_mountpoint);
+	    str = read_dentry (tmp);
+	    memmove (buf + strlen (str), buf, len);
+	    len += strlen (str);
+
+	    strcpy (buf, str);
+	    buf[strlen (str)] = '/';
+	    xfree (str);
+
+	    tmp = tmp2;
+	    tmp2 = read_pointer_field (tmp2, vfsmount, mnt_parent);
+	} while (tmp != tmp2);
+
+	buf[len ? len : 1] = '\0';
+	printf_filtered ("%s ", buf);
+
+	sb = read_pointer_field (vfs, vfsmount, mnt_sb);
+	tmp = read_pointer_field (sb, super_block, s_type);
+	tmp = read_pointer_field (tmp, file_system_type, name);
+	read_memory_string (tmp, buf, 255);
+	printf_filtered ("%s ", buf);
+
+	flags = read_unsigned_field (sb, super_block, s_flags);
+	if (flags & MS_RDONLY)
+	    printf_filtered ("ro");
+	else
+	    printf_filtered ("rw");
+
+	for (fs_infop = fs_info; fs_infop->flag; fs_infop++) {
+	    if (flags & fs_infop->flag)
+		printf_filtered ("%s", fs_infop->str);
+	}
+
+	flags = read_unsigned_field (vfs, vfsmount, mnt_flags);
+
+	for (fs_infop = mnt_info; fs_infop->flag; fs_infop++) {
+	    if (flags & fs_infop->flag)
+		printf_filtered ("%s", fs_infop->str);
+	}
+
+	printf_filtered ("\n");
+
+	next_vfs = read_pointer_field (next_vfs, list_head, next);
+    }
+
+}
+
+
+static void
+restore_caution (void *saved_caution)
+{
+    extern int caution;
+    caution = (long)saved_caution;
+}
+
+static void
+restore_inferior_ptid (void *saved_ptid)
+{
+    inferior_ptid = *(ptid_t*)saved_ptid;
+}
+
+static void
+check_exec_actions()
+{
+    char *execed;
+    struct process *ps;
+    struct waited_exe *exe = waited_exes, *prev = NULL;
+    struct command_line *cmd;
+    extern int caution;
+
+    ps = get_current_process();
+    if (ps->mm == 0)
+	return;
+
+    execed = get_proc_exe(ps->mm);
+    if (execed == NULL)
+	return;
+
+    DEBUG(USER, 2, "%s: The executable is : %s\n", __FUNCTION__, execed);
+
+    while (exe) {
+	struct cleanup *cleanup;
+	ptid_t saved_ptid = inferior_ptid;
+
+	DEBUG(USER, 3, "\tComparing to '%s'\n",exe->name);
+	if (strstr(execed, exe->name) != (execed + strlen(execed) - strlen(exe->name))) {
+	    prev = exe;
+	    exe = exe->next;
+	    continue;
+	}
+
+	cleanup = make_cleanup(restore_caution, (void*)(long)caution);
+	make_cleanup(restore_inferior_ptid, &saved_ptid);
+	caution = 0;
+	inferior_ptid = current_ptid;
+
+	debug_process_command(NULL, 0);
+	cmd = exe->cmds;
+	while (cmd != NULL) {
+	    execute_control_command(cmd);
+	    cmd = cmd->next;
+	}
+	do_cleanups(cleanup);
+
+	if (prev != NULL)
+	    prev->next = exe->next;
+	else
+	    waited_exes = exe->next;
+
+	xfree(exe->name);
+	free_command_lines(&exe->cmds);
+	xfree(exe);
+	return;
+    }
+}
+
+static void
+delete_user_process (int thread_id)
+{
+    struct debugged_user_process *ups = user_processes;
+    struct debugged_user_process **prev;
+    struct objfile *objf, *next_objf;
+    struct breakpoint *bp, *tmp;
+    int first = 1;
+    long refs;
+
+    prev = &user_processes;
+
+    while (ups) {
+	if (ups->gdb_thread_id != thread_id) {
+	    prev = &ups->next;
+	    ups = ups->next;
+	    continue;
+	}
+
+	objf = object_files;
+	object_files = ups->objfiles;
+	forget_cached_source_info ();
+	object_files = objf;
+
+	*prev = ups->next;
+
+	ALL_OBJFILES (objf)
+	    if (objf->next == ups->objfiles) {
+		objf->next = NULL;
+		break;
+	    }
+
+	objf = ups->objfiles;
+
+	refs = (long)objfile_data (objf, linux_user_process_objfile_data_key);
+
+	if (refs == 1) {
+	    DEBUG(USER, 2, "Really freeing objfiles for pid %i\n", ups->pid);
+	    while (objf) {
+		next_objf = objf->next;
+		objf->next = object_files;
+		object_files = objf;
+		free_objfile (objf);
+		objf = next_objf;
+	    }
+	} else {
+	    DEBUG(USER, 2,
+		  "Decrementing refcount of objfiles for pid %i => %ld\n",
+		  ups->pid, refs - 1);
+	    set_objfile_data (objf, linux_user_process_objfile_data_key,
+			      (void*)--refs);
+	}
+
+	ALL_BREAKPOINTS_SAFE (bp, tmp) {
+	    if (bp->thread == ups->gdb_thread_id) {
+		if (first)
+		    warning ("\
+Debugged user process (pid: %i) has finished. Removing breakpoints.", ups->pid);
+		first = 0;
+		delete_breakpoint (bp);
+	    }
+	}
+
+	if (current_user_process == ups)
+	    current_user_process = NULL;
+	xfree (ups);
+	break;
+    }
+}
+
+static void
+running_task_command (char *args, int from_tty)
+{
+    ptid_t ptid = linux_aware_pid_to_ptid (get_current_process ()->pid);
+    char *thread_id = xstrprintf ("%d", pid_to_thread_id (ptid));
+    gdb_thread_select (uiout, thread_id, NULL);
+    xfree (thread_id);
+}
+
+static void
+switch_to_user_process (struct process *ps)
+{
+    struct objfile *objf = NULL;
+    struct debugged_user_process *ups = user_processes;
+
+    if (stick_to_kernelspace)
+	return;
+
+    if (ps) {
+	DEBUG (USER, 4, "Asking to switch to %s %i\n", ps->comm, ps->pid);
+    } else {
+	DEBUG (USER, 4, "Switching to kernel\n");
+    }
+
+    if (current_user_process == NULL && ps != NULL && ps->mm == 0)
+	return;
+
+    last_warned = (CORE_ADDR)-1;
+
+    if (ps != NULL
+	&& current_user_process
+	&& current_user_process->pid == ps->pid
+	&& current_user_process->task_struct_address == ps->task_struct_address) {
+	ups = current_user_process;
+	symfile_objfile = ups->main_objfile;
+	set_main_name (NULL);
+    } else if (ps != NULL)
+	while (ups) {
+	    if (ups->pid == ps->pid
+		&& ups->task_struct_address == ps->task_struct_address) {
+		DEBUG (USER, 2, "Switching to user process %s\n", ps->comm);
+		symfile_objfile = ups->main_objfile;
+		set_main_name (NULL);
+		break;
+	    }
+	    ups = ups->next;
+	}
+    else
+	ups = NULL;
+
+    if (current_user_process != NULL) {
+	ALL_OBJFILES (objf)
+	    if (objf->next == current_user_process->objfiles) {
+		if (ups)
+		    objf->next = ups->objfiles;
+		else
+		    objf->next = NULL;
+		break;
+	    } else if (objf->next == NULL && ups) {
+		objf->next = ups->objfiles;
+		break;
+	    }
+    } else if (ups) {
+	ALL_OBJFILES (objf)
+	    if (objf->next == NULL)
+		break;
+	objf->next = ups->objfiles;
+    }
+
+    if (!ups) {
+	symfile_objfile = object_files;
+	set_main_name ("start_kernel");
+    }
+
+    current_user_process = ups;
+}
+
+struct bp_list {
+    struct bp_list *next;
+    struct breakpoint *b;
+};
+
+struct monitored_page {
+    struct monitored_page *next;
+    CORE_ADDR              addr;
+    CORE_ADDR              virt_addr;
+    int                    stop;
+    struct breakpoint     *watchpoint;
+    struct bp_list        *bps;
+};
+
+static struct monitored_page *monitored_pages;
+
+static void
+create_watchpoint_commands (struct monitored_page *page)
+{
+    struct command_line **cmds;
+    struct bp_list *bps = page->bps;
+
+    free_command_lines (&page->watchpoint->commands);
+
+    cmds = & page->watchpoint->commands;
+    *cmds = xmalloc (sizeof (struct command_line));
+    (*cmds)->line = xstrdup ("silent");
+    (*cmds)->control_type = simple_control;
+    (*cmds)->body_count = 0;
+    (*cmds)->next = NULL;
+
+    if (page->stop) {
+	cmds = &(*cmds)->next;
+	*cmds = xmalloc (sizeof (struct command_line));
+	(*cmds)->line = xstrprintf ("printf \"The page at address 0x%s has just been mapped to memory.\n\"",
+				    paddr (page->virt_addr));
+	(*cmds)->control_type = simple_control;
+	(*cmds)->body_count = 0;
+    }
+
+    if (bps != NULL)
+	do {
+	    cmds = &(*cmds)->next;
+	    *cmds = xmalloc (sizeof (struct command_line));
+	    (*cmds)->line = xstrprintf ("enable %i", bps->b->number);
+	    (*cmds)->control_type = simple_control;
+	    (*cmds)->body_count = 0;
+	    bps = bps->next;
+	} while (bps);
+
+    cmds = &(*cmds)->next;
+    *cmds = xmalloc (sizeof (struct command_line));
+    (*cmds)->line = xstrprintf ("delete %i", page->watchpoint->number);
+    (*cmds)->control_type = simple_control;
+    (*cmds)->body_count = 0;
+
+    if (! page->stop) {
+	cmds = &(*cmds)->next;
+	*cmds = xmalloc (sizeof (struct command_line));
+	(*cmds)->line = xstrdup ("continue");
+	(*cmds)->control_type = simple_control;
+	(*cmds)->body_count = 0;
+    }
+
+    (*cmds)->next = NULL;
+}
+
+static struct monitored_page *
+create_monitored_page (CORE_ADDR addr, struct breakpoint *bp)
+{
+    struct monitored_page *res = xmalloc (sizeof (struct monitored_page));
+    int bpnum, i, other_type_used, target_resources_ok;
+    struct symtab_and_line sal;
+    char *text, *exp_text;
+    struct expression *exp;
+    struct value *val, *mark;
+    struct breakpoint *b;
+
+    res->next = monitored_pages;
+    monitored_pages = res;
+
+    res->addr = addr;
+    if (bp != NULL) {
+	res->bps = xmalloc (sizeof (struct bp_list));
+	res->bps->next = NULL;
+	res->bps->b = bp;
+    } else
+	res->bps = NULL;
+
+    res->stop = 0;
+
+    init_sal (&sal);		/* initialize to zeroes */
+    text = xstrprintf ("*0x%s", paddr (addr));
+    exp_text = text;
+    exp = parse_exp_1 (&exp_text, 0, 0);
+    mark = value_mark ();
+    val = evaluate_expression (exp);
+    release_value (val);
+    if (value_lazy (val))
+	value_fetch_lazy (val);
+
+    i = hw_watchpoint_used_count (bp_hardware_watchpoint, &other_type_used);
+    target_resources_ok =
+	TARGET_CAN_USE_HARDWARE_WATCHPOINT (bp_hardware_watchpoint, i + 1,
+					    other_type_used);
+
+    if (target_resources_ok <= 0) {
+	/* FIXME : leaks */
+	warning ("\
+The hardware watchpoints are exhausted. The debugger can't monitor this\n\
+page's load.");
+	return NULL;
+    }
+
+    b = set_raw_breakpoint (sal, bp_hardware_watchpoint);
+    set_breakpoint_count (breakpoint_count + 1);
+    b->number = breakpoint_count;
+    b->disposition = disp_donttouch;
+    b->exp = exp;
+    b->exp_valid_block = NULL;
+    b->exp_string = savestring (text, exp_text - text);
+    xfree (text);
+    b->val = val;
+    b->loc->cond = NULL;
+    if (bp != NULL)
+	b->thread = bp->thread;
+    else
+	b->thread = pid_to_thread_id (inferior_ptid);
+    b->commands = NULL;
+
+    res->watchpoint = b;
+
+    create_watchpoint_commands (res);
+    return res;
+}
+
+static void
+add_bpt_to_monitored_page (struct monitored_page *page, struct breakpoint *bpt)
+{
+    struct bp_list *list = xmalloc (sizeof (struct bp_list));
+    list->next = page->bps;
+    list->b = bpt;
+    page->bps = list;
+
+    create_watchpoint_commands (page);
+}
+
+static struct monitored_page *
+find_monitored_page (CORE_ADDR addr)
+{
+    struct monitored_page *page = monitored_pages;
+
+    while (page != NULL) {
+	if (page->addr == addr)
+	    break;
+	page = page->next;
+    }
+
+    return page;
+}
+
+static struct monitored_page *
+add_monitored_page (struct breakpoint *bpt, CORE_ADDR addr)
+{
+    CORE_ADDR faulty_addr;
+    struct monitored_page *res;
+    CORE_ADDR task = get_current_task_struct ();
+    faulty_addr = linux_awareness_ops->lo_translate_memory_watch_address (addr,
+									  task);
+    if (!faulty_addr) {
+	error ("Could not find a place to put the page watchpoint.");
+    }
+
+    res = find_monitored_page (faulty_addr);
+
+    if (res == NULL) {
+	if (yquery ("\
+The page where you tried to set a breakpoint isn't currently mapped to\n\
+memory. The debugger can monitor the page load and set the breakpoint when it\n\
+gets loaded. This will use a hardware watchpoint. Do you want the debugger to\n\
+monitor the page load? ")) {
+	    res = create_monitored_page (faulty_addr, bpt);
+	}
+	if (res == NULL)
+	    warning ("Your breakpoint has been disabled.");
+    } else {
+	add_bpt_to_monitored_page (res, bpt);
+    }
+    return res;
+}
+
+static void
+set_nopage_watchpoint (struct breakpoint *bpt, CORE_ADDR addr)
+{
+    add_monitored_page (bpt, addr);
+}
+
+static void
+wait_page_command(char *args, int from_tty)
+{
+    enum page_status stat;
+    CORE_ADDR addr = parse_and_eval_address(args);
+    CORE_ADDR orig_addr = addr;
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task_struct = ps->task_struct_address;
+    CORE_ADDR faulty_addr;
+    struct monitored_page *res;
+
+    stat = linux_awareness_ops->lo_translate_memory_address (&addr, task_struct);
+
+    if (stat == PAGE_PRESENT) {
+	printf_filtered("The page is already in memory!\n");
+	return;
+    }
+
+    faulty_addr = linux_awareness_ops->lo_translate_memory_watch_address (orig_addr,
+									  task_struct);
+
+    res = find_monitored_page (faulty_addr);
+
+    if (res == NULL) {
+	res = create_monitored_page (faulty_addr, NULL);
+    }
+
+    /* create_monitored_page will have emited a warning if needed.  */
+    if (res != NULL) {
+	res->stop = 1;
+	res->virt_addr = orig_addr;
+	create_watchpoint_commands(res);
+    }
+
+}
+
+static void
+wait_exe_command(char *args, int from_tty)
+{
+    struct command_line *cmds;
+    struct waited_exe   *res;
+    if (args == NULL) {
+	printf_filtered("You must supply an executable name.\n");
+	return;
+    }
+
+    res = xmalloc(sizeof(struct waited_exe));
+    res->next = waited_exes;
+    waited_exes = res;
+    res->name = xstrdup(args);
+
+    cmds = read_command_lines("\
+Type commands that will be executed the next time the binary is exec'd:", from_tty);
+
+    res->cmds = cmds;
+
+    if (thread_event_do_exec_return_bp == NULL)
+	thread_event_do_exec_bp = create_thread_event_breakpoint(ADDR(search_binary_handler));
+}
+
+static void
+new_debugged_user_process (struct process *ps,
+			   struct objfile *objfiles,
+			   struct objfile *main_objfile)
+{
+    struct debugged_user_process *user_process;
+    ptid_t ptid = linux_aware_pid_to_ptid (ps->pid);
+
+    user_process = xmalloc (sizeof (struct debugged_user_process));
+    user_process->next = user_processes;
+    user_process->pid = ps->pid;
+    user_process->tgid = ps->tgid;
+    user_process->gdb_thread_id = pid_to_thread_id (ptid);
+    user_process->task_struct_address = ps->task_struct_address;
+    user_process->objfiles = objfiles;
+    user_process->main_objfile = main_objfile;
+
+    user_processes = user_process;
+
+    /* It's important to set current_user_process, otherwise the
+       objfile list won't be cleaned in switch_to_user_process and
+       we'll get duplicate entries.*/
+    current_user_process = user_process;
+    switch_to_user_process (ps);
+
+    if (ps->tgid != ps->pid) {
+	/* This is a thread. The backtrace should stop at 'clone'.
+	   We can't use set_main_name, because this name will only be
+	   looked up in the main binary and 'clone' is in the
+	   libc. Instead, we put clone's address in the entry point
+	   field of the binary which serves as another backtracing
+	   stop mechanism. Yeah, quite hackish, but this works :-) */
+	struct minimal_symbol *sym = lookup_minimal_symbol_text ("clone", NULL);
+	if (sym != NULL)
+	    objfiles->ei.entry_point = SYMBOL_VALUE_ADDRESS (sym);
+    }
+}
+
+static void restore_breakpoints (void *bps)
+{
+    breakpoint_chain = bps;
+}
+
+static void (*dwarf2_psymtab_to_symtab) (struct partial_symtab *pst);
+
+static void
+linux_aware_read_symtab(struct partial_symtab *pst)
+{
+    struct stat stat_struct;
+
+    if (! dwarf2_psymtab_to_symtab)
+	return;
+
+    dwarf2_psymtab_to_symtab (pst);
+
+    if (! pst->symtab)
+	return;
+
+    if (pst->symtab->dirname
+	&& stat (pst->symtab->dirname, &stat_struct) == -1) {
+	char *host_dir = xstrprintf ("%s/%s",
+				     *target_root_prefix,
+				     pst->symtab->dirname);
+
+	if (stat (host_dir, &stat_struct) == 0) {
+	    pst->symtab->dirname = (char *)
+		obstack_alloc (&pst->objfile->objfile_obstack,
+			       strlen (host_dir) + 1);
+	    strcpy (pst->symtab->dirname, host_dir);
+	}
+
+	xfree (host_dir);
+    }
+}
+
+static void
+debug_process_command (char *args, int from_tty)
+{
+    struct stat stat_struct;
+    struct partial_symtab *psymtab;
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task = ps->task_struct_address;
+    CORE_ADDR mm = read_unsigned_field(task, task_struct, mm);
+    CORE_ADDR mmap, dentry;
+    char *filename;
+    bfd *abfd;
+    asection *sect;
+    struct objfile* objfiles = NULL, *objfile;
+    struct objfile* main_objfile = NULL;
+    struct section_addr_info addrs = { 1, {{0, ".text", 0}}};
+    struct cleanup *cleanup;
+    struct debugged_user_process *ups = user_processes;
+
+    if (current_user_process != NULL) {
+	/* Process already debugged.  */
+	if (! from_tty)
+	    return;
+
+	/* Update the process information.  */
+	delete_user_process(current_user_process->gdb_thread_id);
+    }
+
+    cleanup = make_cleanup (restore_breakpoints, breakpoint_chain);
+    /* We don't won't bps to get reevaluated by the symbol_file_add().
+       It causes errors. because symbols aren't visible from one user
+       processto another. */
+    breakpoint_chain = NULL;
+
+    if (from_tty)
+	printf_filtered ("Comm: %s (pid %i)\n", ps->comm, ps->pid);
+
+    if (! mm) {
+	if (from_tty)
+	    printf_filtered ("This is a kernel thread.\n");
+	do_cleanups (cleanup);
+	return;
+    }
+
+    while (ups) {
+	if (ups->tgid == ps->tgid) {
+	    long refs;
+	    objfiles = ups->objfiles;
+	    main_objfile = ups->main_objfile;
+	    refs = (long)objfile_data (objfiles,
+				      linux_user_process_objfile_data_key);
+	    DEBUG (USER, 2,
+		   "Found thread sibling symbol information (pid %i) %ld refs\n",
+		   ups->pid, refs);
+	    set_objfile_data (objfiles, linux_user_process_objfile_data_key,
+			      (void*)++refs);
+	    goto done;
+	}
+	ups = ups->next;
+    }
+
+    /* Remove trailing whitespaces.  */
+    sanitize_target_root_prefix();
+
+    if (**target_root_prefix == '\0')
+	error ("\
+You haven't set the prefix where to look for target binaries.\n\
+Use 'set target-root-prefix'.");
+
+    filename = get_proc_exe (mm);
+    if (filename == NULL) {
+	error ("Couldn't find the process executable path.");
+    }
+
+    filename = xrealloc (filename,
+			 strlen (filename) + strlen (*target_root_prefix) + 1);
+    memmove (filename + strlen (*target_root_prefix),
+	     filename,
+	     strlen (filename)+1);
+    memcpy (filename, *target_root_prefix, strlen(*target_root_prefix));
+    if (from_tty)
+	printf_filtered ("Target exe: %s\n", filename);
+
+    abfd = bfd_openr (filename, gnutarget);
+    if (!abfd) {
+	warning ("Could not open `%s' as an executable file: %s",
+		 filename, bfd_errmsg (bfd_get_error ()));
+	xfree (filename);
+	do_cleanups (cleanup);
+	return;
+    }
+    /* FIXME : use make_cleanup */
+    if (!bfd_check_format (abfd, bfd_object)) {
+	bfd_close (abfd);
+	if (from_tty)
+	    printf_filtered ("\"%s\": not in executable format: %s.",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	xfree (filename);
+	do_cleanups (cleanup);
+	return;
+    }
+
+    if (strcmp (bfd_get_target (abfd), bfd_get_target (exec_bfd))) {
+	bfd_close (abfd);
+	if (from_tty)
+	    printf_filtered ("\"%s\": wrong architecture (%s should be %s).",
+			     filename, bfd_get_target (abfd),
+			     bfd_get_target (exec_bfd));
+	xfree (filename);
+	do_cleanups (cleanup);
+	return;
+    }
+    bfd_close (abfd);
+    xfree (filename);
+    mmap = read_pointer_field (mm, mm_struct, mmap);
+
+    while (mmap) {
+	CORE_ADDR file;
+#define VM_EXEC		0x00000004
+
+	unsigned int flags;
+	CORE_ADDR start;
+
+	flags = read_unsigned_field (mmap, vm_area_struct, vm_flags);
+	start = read_pointer_field (mmap, vm_area_struct, vm_start);
+	file = read_pointer_field (mmap, vm_area_struct, vm_file);
+
+	if (! (flags & VM_EXEC))
+	    goto next;
+
+	file = read_pointer_field (mmap, vm_area_struct, vm_file);
+	if (! file)
+	    goto next;
+
+	if (detected_version >= V2_6_23)
+	    dentry = read_pointer_embedded_field (file,
+						  path, dentry,
+						  file, f_path);
+	else
+	    dentry = read_pointer_field (file, file, f_dentry);
+	filename = read_dentry (dentry);
+	if (filename == NULL)
+	    goto next;
+
+	/* FIXME copied from above */
+	filename = xrealloc (filename,
+			     strlen (filename)
+			     + strlen (*target_root_prefix) + 1);
+	memmove (filename + strlen(*target_root_prefix),
+		 filename,
+		 strlen (filename)+1);
+	memcpy (filename, *target_root_prefix, strlen (*target_root_prefix));
+
+	abfd = bfd_openr (filename, gnutarget);
+	if (!abfd) {
+	    printf_filtered ("Could not open `%s' as an executable file: %s",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	    do_cleanups (cleanup);
+	    return;
+	}
+
+	if (!bfd_check_format (abfd, bfd_object)) {
+	    printf_filtered ("\"%s\": not in executable format: %s.",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	    do_cleanups (cleanup);
+	    return;
+	}
+
+	if (strcmp(bfd_get_target(abfd), bfd_get_target(exec_bfd))) {
+	    printf_filtered ("\"%s\": wrong architecture (%s should be %s).",
+			     filename, bfd_get_target(abfd),
+			     bfd_get_target(exec_bfd));
+	    do_cleanups (cleanup);
+	    return;
+	}
+
+	sect = bfd_get_section_by_name (abfd, ".text");
+
+	if (sect == NULL)
+	    goto next;
+
+	if (flags & VM_EXECUTABLE)
+	    start = 0;
+
+	addrs.other[0].addr = bfd_get_section_vma (abfd, sect) + start;
+	addrs.other[0].sectindex = sect->index;
+
+	DEBUG (USER, 2, "Addresses vma %s start %s  sum %s\n",
+	       paddr (bfd_get_section_vma (abfd, sect)),
+	       paddr (start),
+	       paddr (addrs.other[0].addr));
+
+	objfile = symbol_file_add (filename, from_tty,
+				   &addrs, 0, OBJF_USERLOADED);
+	if (objfiles == NULL)
+	    objfiles = objfile;
+
+	if (flags & VM_EXECUTABLE)
+	    main_objfile = objfile;
+
+	ALL_OBJFILE_PSYMTABS (objfile, psymtab) {
+	    if (!dwarf2_psymtab_to_symtab)
+		dwarf2_psymtab_to_symtab = psymtab->read_symtab;
+
+	    if (dwarf2_psymtab_to_symtab != psymtab->read_symtab)
+		warning ("Your kernel doesn't use Dwarf2 debug info ?!");
+	    else
+		psymtab->read_symtab = linux_aware_read_symtab;
+
+	    if (psymtab->dirname
+		&& stat(psymtab->dirname, &stat_struct) == -1) {
+		char *host_dir = xstrprintf ("%s/%s",
+					     *target_root_prefix,
+					     psymtab->dirname);
+
+		if (stat (host_dir, &stat_struct) == 0) {
+		    psymtab->dirname = (char *)
+			obstack_alloc (&objfile->objfile_obstack,
+				       strlen (host_dir) + 1);
+		    strcpy (psymtab->dirname, host_dir);
+		}
+
+		xfree (host_dir);
+	    }
+	}
+
+	bfd_close (abfd);
+	xfree (filename);
+
+    next:
+	mmap = read_pointer_field (mmap, vm_area_struct, vm_next);
+    }
+
+    /* We must restore the breakpoint_chain before adding the new
+       debugged_user_process, because that might add a breakpoint to
+       the chain. */
+    do_cleanups (cleanup);
+
+    set_objfile_data (objfiles, linux_user_process_objfile_data_key, (void*)1);
+
+ done:
+    new_debugged_user_process (ps, objfiles, main_objfile);
+
+    if (from_tty) {
+	reinit_frame_cache ();
+	print_stack_frame (get_current_frame (), 1, SRC_AND_LOC);
+    }
+}
+
+void
+linux_read_process_symbols ()
+{
+    if (auto_debug_process)
+	debug_process_command (NULL, 0);
+}
+
+static void
+set_loaded (char *arg, int from_tty,
+	    struct cmd_list_element *c)
+{
+    static int currently_loaded = 0;
+
+    if (use_linux_awareness) {
+	if (loaded && loaded != currently_loaded) {
+	    char* banner1 = get_banner ();
+	    char* banner2 = get_banner_from_file ();
+	    struct process *ps;
+
+	    if (banner1 == NULL
+		|| banner2 == NULL
+		|| strcmp (banner1, banner2)) {
+		if (! nquery("\
+The debugger can't find the linux version string stored in your binary image\n\
+in the the current kernel's memory. The file claims to be: \n%s\n\
+The loaded image claims to be: \n%s\n\
+Do you still want to continue (if the kernels don't match, it might crash the\n\
+debugger)? ", banner2, banner1)) {
+		    loaded = 0;
+		    error ("Aborted.");
+		}
+	    }
+
+	    /* Set current ptids. */
+	    ps = get_current_process ();
+	    current_ptid = linux_aware_pid_to_ptid (ps->pid);
+	    inferior_ptid = current_ptid;
+	    DEBUG (TASK, 2, "current_ptid: %i inferior_ptid: %i\n",
+		   PIDGET (current_ptid), PIDGET (inferior_ptid));
+
+	    if (!in_thread_list (current_ptid)) {
+		add_thread (current_ptid);
+	    }
+
+	    ps = get_thread_list();
+
+	    /* Read module list. */
+	    linux_read_module_list();
+	    solib_add (NULL, from_tty, (struct target_ops *) 0, 1);
+
+	    if (ps != NULL && ps->next != NULL) {
+		/* Let the linux-awareness target part believe that we've run. */
+		thread_awareness_inhibit ();
+		linux_awareness_ops->lo_clear_cache ();
+		thread_awareness_exhibit ();
+	    }
+	}
+        currently_loaded = loaded;
+    }
+}
+
+static void
+init_bp_mention(struct breakpoint *bpt)
+{
+    bpt->ops = NULL;
+    printf_filtered (_("Breakpoint %d (%s) pending."),
+		     bpt->number, bpt->addr_string);
+}
+
+static struct breakpoint_ops init_breakpoints_ops = {
+    .print_mention = init_bp_mention
+};
+
+static void
+linux_aware_create_breakpoint_hook (struct breakpoint *bpt)
+{
+    struct lm_info *info;
+
+    /* When this hook is called from breakpoint_re_set_one, the
+       enable_state will be reset by the aforementioned
+       function. There's no point in chnaging it. */
+
+    if (bpt->loc
+	&& bpt->loc->address == ~(CORE_ADDR)0) {
+	if (! resetting_bps_after_init) {
+	    warning("\
+You've inserted a breakpoint on a location that isn't currently\n\
+mapped to memory (it's flagged as __init code and the initialization\n\
+phase of its module is over). The breakpoint will be re-set if you\n\
+reload that module:");
+	} else if (resetting_bps_after_init == 1) {
+	    warning("\
+Disabling breakpoints that are in .init section (they will be re-set if\n\
+you reload that module):");
+	    resetting_bps_after_init = 2;
+	    /* Don't mark the breakpoint as pending here, or it will
+	       get resolved immediately and generate wrong mesages. */
+
+	    /* Store the corresponding module name so that the
+	       breakpoint can get re-enabled at the right time. See
+	       _wait() and make_shlib_bps_pending(). */
+	    if (last_loaded != NULL) {
+		bpt->dll_pathname = xstrdup(last_loaded->module_name);
+	    }
+	}
+	/* Display correct breakpoint info */
+	bpt->ops = &init_breakpoints_ops;
+    } else if (bpt->loc
+	       && bpt->loc->address
+	       && bpt->loc->loc_type == bp_loc_software_breakpoint
+	       && linux_awareness_ops->lo_is_user_address (bpt->loc->address)) {
+	CORE_ADDR addr = bpt->loc->address;
+	bpt->thread = pid_to_thread_id (inferior_ptid);
+	if (! translate_memory_address_safe (&addr, 1)) {
+	    disable_breakpoint (bpt);
+	    set_nopage_watchpoint (bpt, addr);
+	}
+
+	has_userspace_breakpoint = 1;
+
+	if (HAS_ADDR (do_exit)) {
+	    if (thread_event_do_exit_bp == NULL)
+		thread_event_do_exit_bp = create_thread_event_breakpoint (ADDR (do_exit));
+	} else
+	    warning ("'do_exit' wasn't found.");
+
+	if (HAS_ADDR (try_to_unmap)) {
+	    if (thread_event_low_mem_bp == NULL)
+		thread_event_low_mem_bp = create_thread_event_breakpoint (ADDR (try_to_unmap));
+	} else
+	    warning ("'try_to_unmap' wasn't found.");
+    }
+
+    if (deprecated_create_breakpoint_chain)
+	deprecated_create_breakpoint_chain (bpt);
+}
+
+static void
+linux_aware_delete_breakpoint_hook (struct breakpoint *bpt)
+{
+    struct monitored_page **page = &monitored_pages, *p;
+    struct bp_list **bps, *bp;
+
+    while (*page) {
+	if ((*page)->watchpoint == bpt) {
+	    /* FIXME : we leak the bp_list */
+	    p = *page;
+	    *page = (*page)->next;
+	    xfree (p);
+	    break;
+	}
+
+	bps = &(*page)->bps;
+	while (*bps) {
+	    if ((*bps)->b == bpt) {
+		bp = *bps;
+		*bps = (*bps)->next;
+		xfree (bp);
+		create_watchpoint_commands (*page);
+		goto end;
+	    }
+	    bps = &(*bps)->next;
+	}
+
+	page = &(*page)->next;
+    }
+
+end:
+    if (deprecated_delete_breakpoint_chain)
+	deprecated_delete_breakpoint_chain (bpt);
+}
+
+static void
+find_min_load_addr (bfd *abfd, asection *sectp, void *addr)
+{
+    CORE_ADDR *min_addr = addr;
+    CORE_ADDR vma;
+
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_ALLOC))
+	return;
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_HAS_CONTENTS))
+	return;
+
+    vma = bfd_get_section_vma (abfd, sectp);
+    if (vma < *min_addr)
+	*min_addr = vma;
+}
+
+/*
+ * The functionalities that can be built as modules often have a
+ * cleanup routine (marked with module_exit). When the driver is built
+ * into the kernel (ie. not as a module), the cleanup routines aren't
+ * linked in, but their debug information remains... These routines
+ * all have very low addresses (as they haven't been relocated). This
+ * functions try to partially fix the debug info, so that the psymtabs
+ * don't adverise a too wide range of text addresses.
+ */
+static void
+linux_awareness_fix_debug_info ()
+{
+    CORE_ADDR min_load_addr = (CORE_ADDR)-1;
+    struct partial_symtab *pst;
+
+    if (!exec_bfd || !symfile_objfile)
+	return;
+
+    bfd_map_over_sections (exec_bfd, find_min_load_addr, &min_load_addr);
+
+    ALL_OBJFILE_PSYMTABS (symfile_objfile, pst) {
+	if (pst->textlow < min_load_addr)
+	    pst->textlow = min_load_addr;
+    }
+}
+
+static int
+linux_aware_inner_than (CORE_ADDR lhs, CORE_ADDR rhs)
+{
+    if (linux_awareness_ops->lo_is_kernel_address (rhs)
+	&& linux_awareness_ops->lo_is_user_address (lhs))
+	return 0;
+
+    return core_addr_lessthan (lhs, rhs);
+}
+
+static void
+add_module_search_path_command (char *args, int from_tty)
+{
+    mod_path (args, module_search_path);
+}
+
+static void
+linux_awareness_init ()
+{
+    int ret;
+    struct cmd_list_element *c;
+    static char solib_search_path_1[] = "solib-search-path";
+    char *solib_search_path = solib_search_path_1;
+    static char solib_absolute_prefix_1[] = "solib-absolute-prefix";
+    char *solib_absolute_prefix = solib_absolute_prefix_1;
+    static char linux_awareness_postinit_1[] = "linux-awareness-postinit";
+    char *linux_awareness_postinit = linux_awareness_postinit_1;
+
+    /* Make sure KGDB patches don't get in the way. */
+    extern int __attribute__((weak)) debugkernel;
+    if (&debugkernel != NULL)
+	debugkernel = 0;
+
+    ret = push_target (&linux_aware_ops);
+    if (ret) {
+	warning ("The linux-aware stratum target wasn't pushed on the top !\n");
+    }
+
+    DEBUG (INIT, 1,"Initing linux-aware stratum.\n");
+
+    linux_awareness_ops->lo_init ();
+
+    if (target_has_registers) {
+	/* Forced load of the layer */
+	linux_aware_ops.to_has_registers = target_has_registers;
+	linux_aware_ops.to_has_execution = target_has_execution;
+	linux_aware_ops.to_has_stack = target_has_stack;
+	//	loaded = 1; set_loaded (0,0,0);
+    }
+
+    printf_filtered ("Enabling Linux kernel awareness layer [Build %s].\n",
+		     __DATE__);
+
+    linux_awareness_fix_debug_info ();
+
+    set_solib_ops (current_gdbarch, &linux_aware_so_ops);
+    linux_aware_solib_create_inferior_hook ();
+
+    normal_stop_observer = observer_attach_normal_stop (normal_stop_callback);
+
+    set_main_name ("start_kernel");
+
+    free_depmod_cache ();
+    utsname_release = get_utsname_release_from_file ();
+
+    /* Add single-stepping if needed */
+    if (linux_awareness_ops->lo_single_step_destination) {
+	/* This isn't very nice. See gdbarch.h:SOFTWARE_SINGLE_STEP for
+	   some comments which would make that easier/nicer */
+	set_gdbarch_software_single_step (current_gdbarch,
+					  &linux_aware_software_single_step);
+    } else {
+	set_gdbarch_software_single_step (current_gdbarch, NULL);
+    }
+
+
+    set_gdbarch_inner_than (current_gdbarch, linux_aware_inner_than);
+
+    c = lookup_cmd (&solib_search_path, setlist, "", 1, 1);
+    if (c != NULL) {
+	module_search_path = c->var;
+	if (*module_search_path == NULL) {
+	    /* mod_path will choke on it otherwise. */
+	    *module_search_path = xmalloc (1);
+	    **module_search_path = '\0';
+	}
+
+    } else {
+	warning ("Could not find 'set solib-search-path' command");
+    }
+    add_alias_cmd ("module-search-path", "solib-search-path",
+		   no_class, 0, &setlist);
+    add_alias_cmd ("module-search-path", "solib-search-path",
+		   no_class, 0, &showlist);
+
+    c = lookup_cmd (&solib_absolute_prefix, setlist, "", 1, 1);
+    if (c != NULL)
+	target_root_prefix = c->var;
+    else
+	warning ("Could not find 'set solib-absolute-prefix' command");
+
+    add_alias_cmd ("target-root-prefix", "solib-absolute-prefix",
+		   no_class, 0, &setlist);
+    add_alias_cmd ("target-root-prefix", "solib-absolute-prefix",
+		   no_class, 0, &showlist);
+
+    add_alias_cmd ("modules", "sharedlibrary", no_class, 0, &infolist);
+    add_alias_cmd ("tasks", "threads", no_class, 0, &infolist);
+    add_alias_cmd ("task", "thread", no_class, 0, &cmdlist);
+
+    add_com ("running_task", class_obscure, running_task_command,
+	     "Switch to the currently running task.");
+
+    add_com ("dmesg", class_obscure, dmesg_command,
+	     "Print the contents of the linux log buffer.");
+
+    add_com ("process_info", class_obscure, process_info_command,
+	     "Print various info about the current process.");
+
+    add_com ("pmap", class_obscure, pmap_command,
+	     "Print the memory map of the current process.");
+
+    add_com ("vm_translate", class_obscure, vm_translate_command,
+	     "Translate a virtual address to a physical one.");
+
+    add_com ("ipcs", class_obscure, ipcs_command,
+	     "Print various info about the IPC structures.");
+
+    add_com ("proc_ioports", class_obscure, ioports_command,
+	     "Print the I/O ports map.");
+
+    add_com ("proc_iomem", class_obscure, iomem_command,
+	     "Print the I/O mem map.");
+
+    add_com ("proc_version", class_obscure, proc_version_command,
+	     "Print the contents of /proc/version.");
+
+    add_com ("proc_cmdline", class_obscure, proc_cmdline_command,
+	     "Print the contents of /proc/cmdline.");
+
+    add_com ("proc_mounts", class_obscure, proc_mounts_command,
+	     "Print the contents of /proc/mounts.");
+
+    add_com ("proc_meminfo", class_obscure, proc_meminfo_command,
+	     "Print the contents of /proc/meminfo.");
+
+    add_com ("debug_process", class_obscure, debug_process_command,
+	     "Allow to debug the current userspace process. "
+	     "This will load the required symbols.");
+
+    add_com ("wait_exe", class_obscure, wait_exe_command,
+	     "Make the debugger execute a list of commands when a given "
+	     "executable is exec'd");
+
+    add_com ("wait_page", class_obscure, wait_page_command,
+	     "Make the debugger stop when a given page is mapped to memory.");
+
+    add_com ("add-module-search-path", no_class,
+	     add_module_search_path_command,
+	     "Append a module search path to the current one.");
+
+    add_setshow_uinteger_cmd ("log_chunk_size",
+			      class_obscure,
+			      &log_chunk_size,
+			      "Set the size of the chunks used while reading log_buf",
+			     "Show the size of the chunks used while reading log_buf",
+			      NULL, NULL, NULL,
+			      &set_linux_awareness_cmd_list,
+			      &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("loaded",
+			     class_obscure,
+			     &loaded,
+			     "Set the loaded state of the kernel image",
+			     "Show the loaded state of the kernel image",
+			     NULL, &set_loaded, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    deprecated_create_breakpoint_chain = deprecated_create_breakpoint_hook;
+    deprecated_create_breakpoint_hook = linux_aware_create_breakpoint_hook;
+    deprecated_delete_breakpoint_chain = deprecated_delete_breakpoint_hook;
+    deprecated_delete_breakpoint_hook = linux_aware_delete_breakpoint_hook;
+    deprecated_context_chain = deprecated_context_hook;
+    deprecated_context_hook = linux_aware_context_hook;
+
+    /* Disable printing of the [New thread ...] messages. */
+    print_thread_events = 0;
+
+    c = lookup_cmd (&linux_awareness_postinit, cmdlist, "", 1, 1);
+    if (c != NULL && c->class == class_user)
+	execute_user_command (c, 0);
+}
+
+static void
+linux_aware_close (int quitting)
+{
+    struct target_waitstatus dummy;
+    DEBUG (TARGET, 3,"Closing... (quitting = %i)\n", quitting);
+
+    /* We might be called by a signal handler */
+    if (running) {
+	target_stop ();
+	if (linux_aware_ops.beneath != NULL
+	    && linux_aware_ops.beneath->to_wait != NULL)
+	    linux_aware_ops.beneath->to_wait (minus_one_ptid, &dummy);
+    }
+
+    use_linux_awareness = 0;
+    loaded = 0;
+
+    if (normal_stop_observer) {
+	observer_detach_normal_stop (normal_stop_observer);
+	normal_stop_observer = NULL;
+    }
+
+    delete_cmd ("module-search-path", &setlist);
+    delete_cmd ("module-search-path", &showlist);
+    delete_cmd ("target-root-prefix", &setlist);
+    delete_cmd ("target-root-prefix", &showlist);
+    delete_cmd ("modules", &infolist);
+    delete_cmd ("tasks", &infolist);
+    delete_cmd ("task", &cmdlist);
+    delete_cmd ("dmesg", &cmdlist);
+    delete_cmd ("process_info", &cmdlist);
+    delete_cmd ("pmap", &cmdlist);
+    delete_cmd ("vm_translate", &cmdlist);
+    delete_cmd ("ipcs", &cmdlist);
+    delete_cmd ("proc_ioports", &cmdlist);
+    delete_cmd ("proc_iomem", &cmdlist);
+    delete_cmd ("proc_interrupts", &cmdlist);
+    delete_cmd ("proc_mounts", &cmdlist);
+    delete_cmd ("proc_cmdline", &cmdlist);
+    delete_cmd ("proc_version", &cmdlist);
+    delete_cmd ("running_task", &cmdlist);
+
+    delete_cmd ("log_chunk_size", &set_linux_awareness_cmd_list);
+    delete_cmd ("log_chunk_size", &show_linux_awareness_cmd_list);
+    delete_cmd ("loaded", &set_linux_awareness_cmd_list);
+    delete_cmd ("loaded", &show_linux_awareness_cmd_list);
+
+    current_ptid = minus_one_ptid;
+    disable_breakpoint_at_pc = 0;
+    _inhibit_thread_register_awareness = 0;
+
+    init_module_return_resolved = 0;
+
+    if (shlib_event_load_bp) {
+	delete_breakpoint (shlib_event_load_bp);
+	shlib_event_load_bp = NULL;
+    }
+
+    if (shlib_event_init_bp) {
+	delete_breakpoint (shlib_event_init_bp);
+	shlib_event_init_bp = NULL;
+    }
+
+    if (shlib_event_free_bp) {
+	delete_breakpoint (shlib_event_free_bp);
+	shlib_event_free_bp = NULL;
+    }
+
+    if (thread_event_do_exit_bp) {
+	delete_breakpoint (thread_event_do_exit_bp);
+	thread_event_do_exit_bp = NULL;
+    }
+
+    if (thread_event_low_mem_bp) {
+	delete_breakpoint (thread_event_low_mem_bp);
+	thread_event_low_mem_bp = NULL;
+    }
+
+    if (linux_awareness_ops->lo_close)
+	linux_awareness_ops->lo_close ();
+
+    delete_temp_files ();
+
+    thread_list_clear_cache ();
+
+    fields_and_addrs_clear ();
+
+    if (running) {
+	/* If we leave the board run, we'd better remove breakpoints
+	   so that it's functional. */
+	/* FIXME : we should do that before we reset
+	   disable_breakpoint_at_pc */
+	remove_breakpoints ();
+
+	if (linux_aware_ops.beneath != NULL
+	    && linux_aware_ops.beneath->to_resume != NULL)
+	    linux_aware_ops.beneath->to_resume (inferior_ptid, 0, 0);
+    }
+
+    if (quitting) {
+	if (current_target.to_mourn_inferior != noprocess) {
+	    target_mourn_inferior ();
+	    if (linux_aware_ops.beneath != NULL
+		&& linux_aware_ops.beneath->to_close != NULL)
+		linux_aware_ops.beneath->to_close (quitting);
+	}
+    }
+
+    running = 0;
+}
+
+static void
+linux_awareness_set (char *args, int from_tty,
+		     struct cmd_list_element *c)
+{
+    int ret;
+
+    static int active = 0;
+
+    if (use_linux_awareness == active)
+	return;
+
+    active = use_linux_awareness;
+
+    if (use_linux_awareness) {
+	if (symfile_objfile == NULL) {
+	    warning("\
+No symbol file ('help symbol-file'): Not activating linux awareness.\n");
+	    active = use_linux_awareness = 0;
+	    return;
+	}
+	if (exec_bfd == NULL) {
+	    warning("\
+No exec file ('help exec-file'): Not activating linux awareness.\n");
+	    active = use_linux_awareness = 0;
+	    return;
+	}
+
+	/* calls push_target(&linux_aware_ops) after some more init */
+	linux_awareness_init ();
+    } else if (linux_aware_ops.beneath != NULL) {
+	/* The target hasn't been closed yet */
+	DEBUG (INIT, 1,"Unpushing linux-aware stratum.\n");
+	ret = unpush_target (&linux_aware_ops);
+	if (ret != 1) {
+	    warning ("\
+The linux-aware target wasn't unpushed from the target stack !\n");
+	}
+    }
+}
+
+static void
+linux_aware_call_command (struct cmd_list_element *c,
+			  char *arg, int from_tty)
+{
+    static char *quit = "quit";
+    static const struct cmd_list_element *quit_cmd;
+
+    if (quit_cmd == NULL)
+	quit_cmd = lookup_cmd (&quit, cmdlist, "", 1, 1);
+
+    if (from_tty && c != quit_cmd) {
+	if (detected_version == VERSION_UNKNOWN)
+	    warning ("\
+You seem to be trying to debug a Linux Kernel, but your binary but\n\
+your kernel version is not supported. You can try to force the linux\n\
+awareness on by issuing: 'set linux-awareness enabled on'.");
+	else
+	    warning ("\
+You seem to be trying to debug a Linux Kernel, but your binary is\n\
+missing debug information. If you intend to debug this kernel, please\n\
+compile it with debug information.");
+	deprecated_call_command_hook = deprecated_call_command_chain;
+    }
+
+    if (deprecated_call_command_chain)
+	deprecated_call_command_chain (c, arg, from_tty);
+    else
+	cmd_func (c, arg, from_tty);
+}
+
+static int
+linux_awareness_auto_activate_lookup_symbol(const char *name)
+{
+    int found = lookup_minimal_symbol (name, NULL, NULL) != NULL;
+
+    if (!found)
+	DEBUG (INIT, 1, "Symbol '%s' not found\n", name);
+    else
+	DEBUG (INIT, 2, "Symbol '%s' found\n", name);
+
+    return found;
+}
+
+static int
+linux_awareness_auto_activate_lookup_symtab(const char *name)
+{
+    int found = lookup_symtab (name) != NULL;
+
+    if (!found)
+	DEBUG (INIT, 1, "Symtab '%s' not found\n", name);
+    else
+	DEBUG (INIT, 2, "Symtab '%s' found\n", name);
+
+    return found;
+}
+
+static int linux_awareness_check()
+{
+    int res = 0;
+
+    switch (detected_version) {
+    case V2_6_11:
+    case V2_6_17:
+	res =  HAS_FIELD(list_head,         next)
+	    && HAS_FIELD(task_struct,       children)
+	    && HAS_FIELD(task_struct,       sibling)
+	    && HAS_FIELD(task_struct,       pid)
+	    && HAS_FIELD(task_struct,       tgid)
+	    && HAS_FIELD(task_struct,       comm)
+	    && HAS_FIELD(task_struct,       namespace)
+	    && HAS_FIELD(thread_info,       preempt_count);
+	break;
+    case V2_6_23:
+    case V2_6_24:
+	res =  HAS_FIELD(list_head,         next)
+	    && HAS_FIELD(pid_namespace,     last_pid)
+	    && HAS_FIELD(task_struct,       children)
+	    && HAS_FIELD(task_struct,       sibling)
+	    && HAS_FIELD(task_struct,       pid)
+	    && HAS_FIELD(task_struct,       tgid)
+	    && HAS_FIELD(task_struct,       comm)
+	    && HAS_FIELD(task_struct,       nsproxy)
+	    && HAS_FIELD(thread_info,       preempt_count);
+	break;
+    }
+
+    return res;
+}
+
+static void
+linux_awareness_auto_activate (struct objfile *objf)
+{
+    unsigned int i = 0;
+
+    DEBUG (INIT, 2, "linux_awareness_auto_activate(%s)\n", objf ? objf->name : "null");
+
+    if (!linux_awareness_auto_activate_p
+	|| objf == NULL
+	|| objf != symfile_objfile)
+	return;
+
+    autodetection = NOT_LINUX;
+
+    if (! linux_awareness_auto_activate_lookup_symbol ("schedule")
+	|| ! linux_awareness_auto_activate_lookup_symbol ("linux_banner"))
+	return;
+
+    autodetection = LINUX_WITHOUT_DEBUGINFO;
+
+    if (lookup_minimal_symbol("Version_132619", NULL, NULL)) {
+	/* 2.6.11 version */
+	detected_version = V2_6_11;
+    } else if (lookup_minimal_symbol("Version_132625", NULL, NULL)) {
+	/* 2.6.17 version */
+	detected_version = V2_6_17;
+    } else if (lookup_minimal_symbol("Version_132631", NULL, NULL)) {
+	/* 2.6.23 version */
+	detected_version = V2_6_23;
+    } else if (lookup_minimal_symbol("Version_132632", NULL, NULL)) {
+	/* 2.6.24 version - For Nomadik ARM*/
+	detected_version = V2_6_24;
+    } else {
+	detected_version = VERSION_UNKNOWN;
+	if (! deprecated_call_command_chain)
+	    deprecated_call_command_chain = deprecated_call_command_hook;
+	deprecated_call_command_hook = linux_aware_call_command;
+	return;
+    }
+
+    lookup_symtab ("page_io.c");
+    /* load some data that GDB seems to loose otherwise */
+    if (linux_awareness_auto_activate_lookup_symtab ("mmap.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("fork.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("sched.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("block_dev.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("vmalloc.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("page_alloc.c")
+	&& linux_awareness_check()
+	&& linux_awareness_ops->lo_check ())
+	autodetection = LINUX_WITH_DEBUGINFO;
+
+    if (autodetection == LINUX_WITHOUT_DEBUGINFO) {
+	if (! deprecated_call_command_chain)
+	    deprecated_call_command_chain = deprecated_call_command_hook;
+	deprecated_call_command_hook = linux_aware_call_command;
+	return;
+    }
+
+    if (autodetection != LINUX_WITH_DEBUGINFO)
+	return;
+
+    use_linux_awareness = 1;
+    linux_awareness_set (0,0,0);
+}
+
+static void
+set_linux_awareness (char *arg, int from_tty)
+{
+  printf_unfiltered ("\
+'set linux-awareness' must be followed by the name of a print subcommand.\n");
+  help_list (set_linux_awareness_cmd_list,
+	     "set linux-awareness ", -1, gdb_stdout);
+}
+
+static void
+show_linux_awareness (char *args, int from_tty)
+{
+  cmd_show_list (show_linux_awareness_cmd_list, from_tty, "");
+}
+
+static void
+set_global_loglevel (char *arg, int from_tty,
+		     struct cmd_list_element *c)
+{
+    struct debug_domain* domain = linux_aware_debug_domains_info;
+
+    while (domain->name != NULL)
+	domain++->level = global_loglevel;
+}
+
+static void
+init_linux_aware_target ()
+{
+    DEBUG (INIT, 3, "Overloading %s\n", current_target.to_longname);
+
+    linux_aware_ops.to_shortname = "linux-aware";
+    linux_aware_ops.to_longname = "Linux-aware target interface";
+    linux_aware_ops.to_doc = linux_awareness_doc;
+
+    /* Dirty hook to stack above anythin else, event something above
+       the thread stratum (like starm) */
+    linux_aware_ops.to_stratum = thread_stratum + 10;
+    linux_aware_ops.to_load = &linux_aware_load;
+    linux_aware_ops.to_close = &linux_aware_close;
+    linux_aware_ops.to_attach = &linux_aware_attach;
+    linux_aware_ops.to_can_run = &linux_aware_can_run;
+    linux_aware_ops.to_magic = OPS_MAGIC;
+
+    /* Breakpoints */
+    linux_aware_ops.to_insert_breakpoint = &linux_aware_insert_breakpoint;
+    linux_aware_ops.to_remove_breakpoint = &linux_aware_remove_breakpoint;
+    linux_aware_ops.to_insert_hw_breakpoint = &linux_aware_insert_hw_breakpoint;
+    linux_aware_ops.to_remove_hw_breakpoint = &linux_aware_remove_hw_breakpoint;
+
+    /* ?? Watchpoints ?? */
+
+    /* Memory */
+    linux_aware_ops.deprecated_xfer_memory = &linux_aware_deprecated_xfer_memory;
+
+    /* Registers */
+    linux_aware_ops.to_fetch_registers = &linux_aware_fetch_registers;
+    linux_aware_ops.to_store_registers = &linux_aware_store_registers;
+
+    /* Execution */
+    linux_aware_ops.to_resume = &linux_aware_resume;
+    linux_aware_ops.to_wait = &linux_aware_wait;
+
+    /* Threads */
+    linux_aware_ops.to_thread_alive = &linux_aware_thread_alive;
+    linux_aware_ops.to_find_new_threads = &linux_aware_find_new_threads;
+    linux_aware_ops.to_pid_to_str = &linux_aware_pid_to_str;
+    linux_aware_ops.to_extra_thread_info = &linux_aware_extra_thread_info;
+    linux_aware_ops.to_has_thread_control = tc_schedlock;
+}
+
+volatile int stop_loop = 1;
+void
+_initialize_linux_awareness (void)
+{
+    static struct cmd_list_element *c;
+    struct debug_domain *domain;
+    while (!stop_loop);
+    linux_user_process_objfile_data_key = register_objfile_data ();
+
+    tmpdir = getenv("TMPDIR");
+
+    observer_attach_new_objfile(linux_awareness_auto_activate);
+
+    init_linux_aware_target ();
+    add_target (&linux_aware_ops);
+    init_so_ops ();
+
+    add_prefix_cmd ("linux-awareness",
+		    class_obscure,
+		    set_linux_awareness,
+		    "Command for setting linux-awareness variables",
+		    &set_linux_awareness_cmd_list,
+		    "set linux-awareness ",
+		    0, &setlist);
+
+    add_prefix_cmd ("linux-awareness",
+		    class_obscure,
+		    show_linux_awareness,
+		    "Command for showing linux-awareness variables",
+		    &show_linux_awareness_cmd_list,
+		    "show linux-awareness ",
+		    0, &showlist);
+
+    add_setshow_boolean_cmd ("enabled",
+			     class_obscure,
+			     &use_linux_awareness,
+			     "Set the activation state of the the linux awareness layer",
+			     "Show the activation state of the the linux awareness layer",
+			     NULL, &linux_awareness_set, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    domain = linux_aware_debug_domains_info;
+
+    while (domain->name != NULL) {
+	static const char fmt[] = "%s the debug level of the linux awareness layer %s part.";
+	const char *name = domain->name + 6; /* Skip debug- */
+	char *help_set = xstrprintf (fmt, "Set", name);
+	char *help_show = xstrprintf (fmt, "Show", name);
+	add_setshow_zinteger_cmd ((char*)domain->name,
+				  class_obscure,
+				  &(domain->level),
+				  help_set,
+				  help_show,
+				  NULL,
+				  NULL, NULL,
+				  &set_linux_awareness_cmd_list,
+				  &show_linux_awareness_cmd_list);
+	xfree (help_set);
+	xfree (help_show);
+	++domain;
+    }
+
+    add_setshow_zinteger_cmd ("debug-all",
+			      class_obscure,
+			      &global_loglevel,
+			      "Set the debug level of the linux awareness layer",
+			      "Show the debug level of the linux awareness layer",
+			      NULL,
+			      &set_global_loglevel, NULL,
+			      &set_linux_awareness_cmd_list,
+			      &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("enable_vm_translation",
+			     class_obscure,
+			     &enable_vm_translation,
+			     "Set wether we try to translate virtual addresses into physical ones",
+			     "Show wether we try to translate virtual addresses into physical ones",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("enable_task_awareness",
+			     class_obscure,
+			     &enable_task_awareness,
+			     "Set wether we implement task awareness",
+			     "Show wether we implement task awareness",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("auto_activate",
+			     class_obscure,
+			     &linux_awareness_auto_activate_p,
+			     "Set wether we try to autodetect linux kernels.",
+			     "Show wether we try to autodetect linux kernels.",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("auto_debug_process",
+			     class_obscure,
+			     &auto_debug_process,
+			     "Set wether we try to automatically load information for userspace processes.",
+			     "Show wether we try to automatically load information for userspace processes.",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+}
Index: fred/gdb/linux-awareness.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ fred/gdb/linux-awareness.h	2009-02-20 10:16:23.000000000 +0000
@@ -0,0 +1,200 @@
+
+struct type;
+struct cmd_list_element;
+
+extern struct cmd_list_element *set_linux_awareness_cmd_list;
+extern struct cmd_list_element *show_linux_awareness_cmd_list;
+
+struct addr_info {
+    char                  *name;
+    struct minimal_symbol *sym;
+    struct addr_info      *next;
+};
+
+struct field_info {
+    char              *struct_name;
+    char              *field_name;
+    struct symbol     *type;
+    int                offset;
+    int                size;
+    struct field_info *next;
+};
+
+#define FIELD_INFO(s_name, field) _FIELD_##s_name##__##field
+
+#define DECLARE_FIELD(s_name, field) \
+    static struct field_info FIELD_INFO(s_name, field) \
+    = { .struct_name = #s_name, .field_name = #field, 0 }
+
+#define F_OFFSET(struct, field) \
+    linux_get_field_offset (&FIELD_INFO(struct, field))
+#define F_SIZE(struct, field) \
+    linux_get_field_size (&FIELD_INFO(struct, field))
+#define HAS_FIELD(struct, field) \
+    (FIELD_INFO(struct, field).type != NULL \
+     || (linux_init_field(&FIELD_INFO(struct, field), 1), \
+            FIELD_INFO(struct, field).type != NULL))
+
+
+
+#define ADDR_INFO(symb) _ADDR_##symb
+
+#define DECLARE_ADDR(symb) \
+    static struct addr_info ADDR_INFO(symb) = { .name = #symb }
+
+#define HAS_ADDR(symb) \
+    (ADDR_INFO(symb).sym != NULL \
+     || (linux_init_addr(&ADDR_INFO(symb), 1), ADDR_INFO(symb).sym != NULL))
+
+#define ADDR(sym) linux_get_address (&ADDR_INFO(sym))
+
+
+
+
+#define read_unsigned_field(base, struct, field) \
+    read_memory_unsigned_integer (base + F_OFFSET (struct, field), \
+				  F_SIZE (struct, field))
+
+#define read_signed_field(base, struct, field) \
+    read_memory_integer (base + F_OFFSET (struct, field), \
+			 F_SIZE (struct, field))
+
+#define read_pointer_field(base, struct, field) \
+    read_memory_typed_address (base + F_OFFSET (struct, field), \
+			       builtin_type_void_data_ptr)
+
+#define read_unsigned_embedded_field(base, struct, field, emb_str, emb_field) \
+    read_memory_unsigned_integer (base + F_OFFSET (struct, field) \
+				       + F_OFFSET (emb_str, emb_field), \
+				  F_SIZE (struct, field))
+
+#define read_signed_embedded_field(base, struct, field, emb_str, emb_field) \
+    read_memory_integer (base + F_OFFSET (struct, field) \
+			      + F_OFFSET (emb_str, emb_field), \
+			 F_SIZE (struct, field))
+
+#define read_pointer_embedded_field(base, struct, field, emb_str, emb_field) \
+    read_memory_typed_address (base + F_OFFSET (struct, field) \
+	       		            + F_OFFSET (emb_str, emb_field), \
+			       builtin_type_void_data_ptr)
+
+#define extract_unsigned_field(base, struct, field) \
+    extract_unsigned_integer(base + F_OFFSET (struct, field), \
+			     F_SIZE (struct,field))
+
+#define extract_signed_field(base, struct, field) \
+    extract_signed_integer (base + F_OFFSET (struct, field), \
+			    F_SIZE (struct, field))
+
+#define extract_pointer_field(base, struct, field) \
+    extract_typed_address (base + F_OFFSET (struct, field), \
+			   builtin_type_void_data_ptr)
+
+enum page_status {
+    PAGE_PRESENT,
+    PAGE_SWAPPED,
+    PAGE_NOTMAPPED,
+    PAGE_NOPAGE,
+    PAGE_UNKNOWN
+};
+
+extern enum stlinux_version {
+    V2_6_11,
+    V2_6_17,
+    V2_6_23,
+    V2_6_24,
+    VERSION_UNKNOWN
+} detected_version;
+
+struct linux_awareness_ops {
+    const char *name;
+    int (*lo_check)();
+    int (*lo_init)();
+    void (*lo_close)();
+    void (*lo_pre_load)(char *prog, int fromtty);
+    void (*lo_post_load)(char *prog, int fromtty);
+    void (*lo_pre_exec_start)();
+    void (*lo_post_exec_stop)();
+    int (*lo_address_needs_translation)(CORE_ADDR addr);
+    enum page_status (*lo_translate_memory_address)(CORE_ADDR *addr,
+						    CORE_ADDR task_struct);
+    CORE_ADDR (*lo_translate_memory_watch_address)(CORE_ADDR addr,
+						   CORE_ADDR task_struct);
+    int (*lo_can_write)(CORE_ADDR addr, CORE_ADDR task_struct);
+    int (*lo_is_user_address)(CORE_ADDR addr);
+    int (*lo_is_kernel_address)(CORE_ADDR addr);
+    void (*lo_flush_cache)(CORE_ADDR virtaddr, CORE_ADDR physaddr,
+			   int len, int write);
+    CORE_ADDR (*lo_single_step_destination)(CORE_ADDR pc);
+    void (*lo_clear_cache)();
+
+    CORE_ADDR (*lo_first_pointer_arg_value)();
+    CORE_ADDR (*lo_second_pointer_arg_value)();
+    CORE_ADDR (*lo_third_pointer_arg_value)();
+    CORE_ADDR (*lo_return_address_at_start_of_function)();
+    CORE_ADDR (*lo_current_task_struct_address)();
+    CORE_ADDR (*lo_current_thread_info_address)();
+    int (*lo_fetch_context_register)(int regno, CORE_ADDR task_struct);
+    int (*lo_store_context_register)(int regno, CORE_ADDR task_struct);
+
+    int page_shift;
+};
+
+extern struct linux_awareness_ops *linux_awareness_ops;
+
+struct debug_domain {
+    const char *name;
+    int         level;
+};
+
+extern struct debug_domain linux_aware_debug_domains_info[];
+
+enum linux_aware_debug_domain {
+    VM,
+    TASK,
+    MODULE,
+    TARGET,
+    INIT,
+    USER,
+    KEEP_LAST
+};
+
+#define DEBUG(domain, l, ...) \
+    ({if (domain < KEEP_LAST \
+        && linux_aware_debug_domains_info[domain].level >= l) \
+        fprintf_filtered(gdb_stdlog, "[linux] " __VA_ARGS__);})
+
+int linux_init_addr (struct addr_info *field, int check);
+int linux_init_field (struct field_info *field, int check);
+
+static inline CORE_ADDR
+linux_get_address (struct addr_info *addr)
+{
+    if (addr->sym == NULL)
+	linux_init_addr(addr, 0);
+
+    return SYMBOL_VALUE_ADDRESS (addr->sym);
+}
+
+static inline unsigned int
+linux_get_field_offset (struct field_info *field)
+{
+    if (field->type == NULL)
+	linux_init_field(field, 0);
+
+    return field->offset;
+}
+
+static inline unsigned int
+linux_get_field_size (struct field_info *field)
+{
+    if (field->type == NULL)
+	linux_init_field(field, 0);
+
+    return field->size;
+}
+
+
+void linux_read_process_symbols ();
+
+#define KERNEL_VERSION(a,b,c) (((a) << 16) + ((b) << 8) + (c))
Index: fred/gdb/configure.tgt
===================================================================
--- fred.orig/gdb/configure.tgt	2009-02-20 10:15:15.000000000 +0000
+++ fred/gdb/configure.tgt	2009-02-20 10:16:23.000000000 +0000
@@ -551,3 +551,10 @@
 *-*-mingw* | *-*-cygwin*)
 		gdb_osabi=GDB_OSABI_CYGWIN ;;
 esac
+
+# Add linux awareness files
+
+case "${targ}" in
+sh*-*-linux*) gdb_target_obs="$gdb_target_obs linux-awareness.o linux-awareness-sh4.o" ;;
+arm*-linux*) gdb_target_obs="$gdb_target_obs linux-awareness.o linux-awareness-arm.o" ;;
+esac
Index: fred/gdb/Makefile.in
===================================================================
--- fred.orig/gdb/Makefile.in	2009-02-20 10:15:15.000000000 +0000
+++ fred/gdb/Makefile.in	2009-02-20 10:16:23.000000000 +0000
@@ -2355,6 +2355,23 @@
 	$(symfile_h) $(objfiles_h) $(source_h) $(demangle_h) $(value_h) \
 	$(completer_h) $(cp_abi_h) $(parser_defs_h) $(block_h) \
 	$(objc_lang_h) $(linespec_h) $(exceptions_h) $(language_h)
+linux-awareness.o: linux-awareness.c linux-awareness.h $(defs_h) $(ui_out_h) \
+        $(arch_utils_h) $(block_h) $(breakpoint_h) $(cli_decode_h) \
+        $(cli_script_h) $(command_h) $(completer_h) $(dictionary_h) \
+        $(event_loop_h) $(exceptions_h) $(exec_h) $(frame_h) $(gdb_h) \
+        $(gdb_assert_h) $(gdbcmd_h) $(gdbcore_h) $(gdbthread_h) $(gdbtypes_h) \
+        $(inferior_h) $(objfiles_h) $(observer_h) $(regcache_h) $(solib_h) \
+        $(solist_h) $(symtab_h) $(target_h) $(bdf_h) $(libbfd_h) $(elf_bfd_h)
+linux-awareness-arm.o: linux-awareness.c linux-awareness.h $(defs_h) \
+        $(block_h) $(command_h) $(frame_h) $(frame_unwind_h) $(gdb_assert_h) \
+        $(gdb_stdint_h) $(gdbarch_h) $(gdbcmd_h) $(gdbcore_h) $(gdbtypes_h) \
+        $(gdb_obstack_h) $(inferior_h) $(regcache_h) $(user_regs_h) \
+        $(symtab_h) $(target_h) $(top_h) $(value_h) $(arm_tdep_h)
+linux-awareness-sh4.o: linux-awareness.c linux-awareness.h $(defs_h) \
+        $(block_h) $(command_h) $(frame_h) $(frame_unwind_h) $(gdb_assert_h) \
+        $(gdb_stdint_h) $(gdbarch_h) $(gdbcmd_h) $(gdbcore_h) $(gdbtypes_h) \
+        $(gdb_obstack_h) $(inferior_h) $(regcache_h) $(user_regs_h) \
+        $(symtab_h) $(target_h) $(value_h) $(sh_tdep_h)
 linux-fork.o: linux-fork.c $(defs_h) $(inferior_h) $(regcache_h) $(gdbcmd_h) \
 	$(infcall_h) $(gdb_assert_h) $(gdb_string_h) $(linux_fork_h) \
 	$(linux_nat_h) $(gdb_wait_h) $(gdb_dirent_h)
