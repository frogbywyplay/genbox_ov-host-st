This patch fixes several problems with the gcc atomic memory
operations for sh:

 - Renames __sync_compare_and_swap_N to __sync_val_compare_and_swap_N
   to match gcc, and add __sync_bool_compare_and_swap_N.

 - Fixes the __sync_fetch_and_OP_N functions so that they work correctly
   in the case where a roll back occurs (previously they directly modified
   the value register, rather than working on a temporary, so in the case
   of a roll back it could produce the wrong result).

 - Modify all _1 and _2 functions so that they return a zero extended
   result. This is necessary to pass the gcc test suite.

 - Fix __sync_fetch_and_nand_N function so that it performs the not
   on the just *ptr, not the whole expression (to match gcc expectations).

 - Implement the __sync_OP_and_fetch_N functions which were missing.

Signed-off-by: Stuart Menefy <stuart.menefy@st.com>
--- gcc-4.2.1.orig/gcc/config/sh/linux-atomic.asm	2006-03-31 23:31:05.000000000 +0100
+++ gcc-4.2.1/gcc/config/sh/linux-atomic.asm	2008-03-07 16:41:26.267245000 +0000
@@ -55,11 +55,11 @@
 ATOMIC_TEST_AND_SET (2,w)
 ATOMIC_TEST_AND_SET (4,l)
 
-#define ATOMIC_COMPARE_AND_SWAP(N,T) \
-	.global	__sync_compare_and_swap_##N; \
-	HIDDEN_FUNC(__sync_compare_and_swap_##N); \
+#define ATOMIC_COMPARE_AND_SWAP(OP,N,T) \
+	.global	__sync_##OP##_compare_and_swap_##N; \
+	HIDDEN_FUNC(__sync_##OP##_compare_and_swap_##N); \
 	.align	2; \
-__sync_compare_and_swap_##N:; \
+__sync_##OP##_compare_and_swap_##N:; \
 	mova	1f, r0; \
 	nop; \
 	mov	r15, r1; \
@@ -70,33 +70,51 @@
 	mov.##T	r6, @r4; \
 1:	mov	r1, r15; \
 	rts; \
-	 mov	r2, r0; \
-	ENDFUNC(__sync_compare_and_swap_##N)
-
-ATOMIC_COMPARE_AND_SWAP (1,b)
-ATOMIC_COMPARE_AND_SWAP (2,w)
-ATOMIC_COMPARE_AND_SWAP (4,l)
-
+	.ifc OP, bool; \
+	 movt r0; \
+	.else; \
+	 mov r2, r0; \
+	.endif; \
+	ENDFUNC(__sync_##OP##_compare_and_swap_##N)
+
+ATOMIC_COMPARE_AND_SWAP (bool,1,b)
+ATOMIC_COMPARE_AND_SWAP (bool,2,w)
+ATOMIC_COMPARE_AND_SWAP (bool,4,l)
+
+ATOMIC_COMPARE_AND_SWAP (val,1,b)
+ATOMIC_COMPARE_AND_SWAP (val,2,w)
+ATOMIC_COMPARE_AND_SWAP (val,4,l)
+	
 #define ATOMIC_FETCH_AND_OP(OP,N,T) \
 	.global	__sync_fetch_and_##OP##_##N; \
 	HIDDEN_FUNC(__sync_fetch_and_##OP##_##N); \
 	.align	2; \
 __sync_fetch_and_##OP##_##N:; \
 	mova	1f, r0; \
+	nop; \
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
-	OP	r2, r5; \
-	mov.##T	r5, @r4; \
+	mov	r2, r3; \
+	OP	r5, r3; \
+	mov.##T	r3, @r4; \
 1:	mov	r1, r15; \
 	rts; \
+	.if N == 4 ; \
 	 mov	r2, r0; \
+	.else; \
+	 extu.##T r2, r0; \
+	.endif; \
 	ENDFUNC(__sync_fetch_and_##OP##_##N)
 
 ATOMIC_FETCH_AND_OP(add,1,b)
 ATOMIC_FETCH_AND_OP(add,2,w)
 ATOMIC_FETCH_AND_OP(add,4,l)
 
+ATOMIC_FETCH_AND_OP(sub,1,b)
+ATOMIC_FETCH_AND_OP(sub,2,w)
+ATOMIC_FETCH_AND_OP(sub,4,l)
+
 ATOMIC_FETCH_AND_OP(or,1,b)
 ATOMIC_FETCH_AND_OP(or,2,w)
 ATOMIC_FETCH_AND_OP(or,4,l)
@@ -119,20 +137,86 @@
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
-	OP0	r2, r5; \
-	OP1	r5, r5; \
-	mov.##T	r5, @r4; \
+	OP0	r2, r3; \
+	OP1	r5, r3; \
+	mov.##T	r3, @r4; \
 1:	mov	r1, r15; \
 	rts; \
+	.if N == 4 ; \
 	 mov	r2, r0; \
+	.else; \
+	 extu.##T r2, r0; \
+	.endif; \
 	ENDFUNC(__sync_fetch_and_##OP##_##N)
 
-ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,1,b)
-ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,2,w)
-ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,4,l)
-
-ATOMIC_FETCH_AND_COMBOP(nand,and,not,1,b)
-ATOMIC_FETCH_AND_COMBOP(nand,and,not,2,w)
-ATOMIC_FETCH_AND_COMBOP(nand,and,not,4,l)
-
+ATOMIC_FETCH_AND_COMBOP(nand,not,and,1,b)
+ATOMIC_FETCH_AND_COMBOP(nand,not,and,2,w)
+ATOMIC_FETCH_AND_COMBOP(nand,not,and,4,l)
+
+#define ATOMIC_OP_AND_FETCH(OP,N,T) \
+	.global	__sync_##OP##_and_fetch_##N; \
+	HIDDEN_FUNC(__sync_##OP##_and_fetch_##N); \
+	.align	2; \
+__sync_##OP##_and_fetch_##N:; \
+	mova	1f, r0; \
+	mov	r15, r1; \
+	mov	#(0f-1f), r15; \
+0:	mov.##T	@r4, r2; \
+	OP	r5, r2; \
+	mov.##T	r2, @r4; \
+1:	mov	r1, r15; \
+	rts; \
+	.if N == 4 ; \
+	 mov	r2, r0; \
+	.else; \
+	 extu.##T r2, r0; \
+	.endif; \
+	ENDFUNC(__sync_##OP##_and_fetch_##N)
+
+ATOMIC_OP_AND_FETCH(add,1,b)
+ATOMIC_OP_AND_FETCH(add,2,w)
+ATOMIC_OP_AND_FETCH(add,4,l)
+
+ATOMIC_OP_AND_FETCH(sub,1,b)
+ATOMIC_OP_AND_FETCH(sub,2,w)
+ATOMIC_OP_AND_FETCH(sub,4,l)
+
+ATOMIC_OP_AND_FETCH(or,1,b)
+ATOMIC_OP_AND_FETCH(or,2,w)
+ATOMIC_OP_AND_FETCH(or,4,l)
+
+ATOMIC_OP_AND_FETCH(and,1,b)
+ATOMIC_OP_AND_FETCH(and,2,w)
+ATOMIC_OP_AND_FETCH(and,4,l)
+
+ATOMIC_OP_AND_FETCH(xor,1,b)
+ATOMIC_OP_AND_FETCH(xor,2,w)
+ATOMIC_OP_AND_FETCH(xor,4,l)
+
+#define ATOMIC_COMBOP_AND_FETCH(OP,OP0,OP1,N,T) \
+	.global	__sync_##OP##_and_fetch_##N; \
+	HIDDEN_FUNC(__sync_##OP##_and_fetch_##N); \
+	.align	2; \
+__sync_##OP##_and_fetch_##N:; \
+	mova	1f, r0; \
+	nop; \
+	mov	r15, r1; \
+	mov	#(0f-1f), r15; \
+0:	mov.##T	@r4, r2; \
+	OP0	r2, r2; \
+	OP1	r5, r2; \
+	mov.##T	r2, @r4; \
+1:	mov	r1, r15; \
+	rts; \
+	.if N == 4 ; \
+	 mov	r2, r0; \
+	.else; \
+	 extu.##T r2, r0; \
+	.endif; \
+	ENDFUNC(__sync_##OP##_and_fetch_##N)
+
+ATOMIC_COMBOP_AND_FETCH(nand,not,and,1,b)
+ATOMIC_COMBOP_AND_FETCH(nand,not,and,2,w)
+ATOMIC_COMBOP_AND_FETCH(nand,not,and,4,l)
+		
 #endif /* ! __SH5__ */
