Updated GDB linux awareness patch

Index: gdb-6.5/gdb/breakpoint.c
===================================================================
--- gdb-6.5.orig/gdb/breakpoint.c	2007-10-24 16:22:01.000000000 +0100
+++ gdb-6.5/gdb/breakpoint.c	2007-10-24 16:22:45.000000000 +0100
@@ -5374,6 +5374,7 @@
 static int
 do_captured_breakpoint (struct ui_out *uiout, void *data)
 {
+  struct gdb_exception e;
   struct captured_breakpoint_args *args = data;
   struct symtabs_and_lines sals;
   struct expression **cond;
@@ -5383,7 +5384,13 @@
   char **addr_string;
   char **cond_string;
 
+  struct captured_parse_breakpoint_args parse_args;
+  struct symtab_and_line pending_sal;
+  int not_found;
+  int pending = 0;
+  char *err_msg;
   char *address_end;
+  char *copy_arg;
 
   /* Parse the source and lines spec.  Delay check that the expression
      didn't contain trailing garbage until after cleanups are in
@@ -5392,19 +5399,61 @@
   sals.nelts = 0;
   address_end = args->address;
   addr_string = NULL;
-  parse_breakpoint_sals (&address_end, &sals, &addr_string, 0);
 
-  if (!sals.nelts)
-    return GDB_RC_NONE;
+  parse_args.arg_p = &address_end;
+  parse_args.sals_p = &sals;
+  parse_args.addr_string_p = &addr_string;
+  parse_args.not_found_ptr = &not_found;
+
+  e = catch_exception (uiout, do_captured_parse_breakpoint,
+		       &parse_args, RETURN_MASK_ALL);
+
+  /* If caller is interested in rc value from parse, set value.  */
+  switch (e.reason)
+    {
+    case RETURN_QUIT:
+      exception_print (gdb_stderr, e);
+      return e.reason;
+    case RETURN_ERROR:
+      switch (e.error)
+	{
+	case NOT_FOUND_ERROR:
+	  exception_print (gdb_stderr, e);
+
+	  /* If pending breakpoint support is turned off, throw
+	     error.  */
+	  if (pending_break_support != AUTO_BOOLEAN_TRUE)
+	    deprecated_throw_reason (RETURN_ERROR);
+
+          /* Pending breakpoint behaviour is on, so a pending breakpoint is
+             defaulted on behalf of the user.  */
+	  copy_arg = xstrdup (args->address);
+	  addr_string = &copy_arg;
+	  sals.nelts = 1;
+	  sals.sals = &pending_sal;
+	  pending_sal.pc = 0;
+	  pending = 1;
+	  break;
+	default:
+	  exception_print (gdb_stderr, e);
+	  return e.reason;
+	}
+    default:
+      if (!sals.nelts)
+	return GDB_RC_FAIL;
+    }
 
   /* Create a chain of things at always need to be cleaned up. */
   old_chain = make_cleanup (null_cleanup, 0);
 
-  /* Always have a addr_string array, even if it is empty. */
-  make_cleanup (xfree, addr_string);
+  if (!pending)
+    {
+      /* Always have a addr_string array, even if it is empty. */
+      make_cleanup (xfree, addr_string);
 
-  /* Make sure that all storage allocated to SALS gets freed.  */
-  make_cleanup (xfree, sals.sals);
+      /* Make sure that all storage allocated to SALS gets freed.  */
+      make_cleanup (xfree, sals.sals);
+    }
 
   /* Allocate space for all the cond expressions. */
   cond = xcalloc (sals.nelts, sizeof (struct expression *));
@@ -5429,35 +5478,63 @@
 	make_cleanup (xfree, addr_string[i]);
     }
 
-  /* Wait until now before checking for garbage at the end of the
-     address. That way cleanups can take care of freeing any
-     memory. */
-  if (*address_end != '\0')
-    error (_("Garbage %s following breakpoint address"), address_end);
-
   /* Resolve all line numbers to PC's.  */
-  breakpoint_sals_to_pc (&sals, args->address);
-
-  /* Verify that conditions can be parsed, before setting any
-     breakpoints.  */
-  for (i = 0; i < sals.nelts; i++)
+  if (!pending)
     {
-      if (args->condition != NULL)
-	{
-	  char *tok = args->condition;
-	  cond[i] = parse_exp_1 (&tok, block_for_pc (sals.sals[i].pc), 0);
-	  if (*tok != '\0')
-	    error (_("Garbage %s follows condition"), tok);
-	  make_cleanup (xfree, cond[i]);
-	  cond_string[i] = xstrdup (args->condition);
-	}
-    }
+      /* Wait until now before checking for garbage at the end of the
+         address. That way cleanups can take care of freeing any
+         memory. */
+      if (*address_end != '\0')
+        error (_("Garbage %s following breakpoint address"), address_end);
+
+      breakpoint_sals_to_pc (&sals, args->address);
+
+      /* Verify that conditions can be parsed, before setting any
+         breakpoints.  */
+      for (i = 0; i < sals.nelts; i++)
+        {
+          if (args->condition != NULL)
+            {
+	      char *tok = args->condition;
+	      cond[i] = parse_exp_1 (&tok, block_for_pc (sals.sals[i].pc), 0);
+	      if (*tok != '\0')
+	        error (_("Garbage %s follows condition"), tok);
+	      make_cleanup (xfree, cond[i]);
+	      cond_string[i] = xstrdup (args->condition);
+	    }
+         }
 
-  create_breakpoints (sals, addr_string, cond, cond_string,
-		      args->hardwareflag ? bp_hardware_breakpoint : bp_breakpoint,
-		      args->tempflag ? disp_del : disp_donttouch,
-		      args->thread, args->ignore_count, 0/*from-tty*/, 
-		      NULL/*pending_bp*/);
+      create_breakpoints (sals, addr_string, cond, cond_string,
+  		          args->hardwareflag ? bp_hardware_breakpoint : bp_breakpoint,
+		          args->tempflag ? disp_del : disp_donttouch,
+		          args->thread, args->ignore_count, 0/*from-tty*/,
+		          NULL/*pending_bp*/);
+     }
+   else
+     {
+       struct symtab_and_line sal;
+       struct breakpoint *b;
+
+       sal.symtab = NULL;
+       sal.pc = 0;
+
+       make_cleanup (xfree, copy_arg);
+
+       b = set_raw_breakpoint (sal, args->hardwareflag ? bp_hardware_breakpoint
+ 		               : bp_breakpoint);
+       set_breakpoint_count (breakpoint_count + 1);
+       b->number = breakpoint_count;
+       b->cond = *cond;
+       b->thread = args->thread;
+       b->addr_string = *addr_string;
+       b->cond_string = *cond_string;
+       b->ignore_count = args->ignore_count;
+       b->pending = 1;
+       b->disposition = args->tempflag ? disp_del : disp_donttouch;
+       b->from_tty = 0;
+       b->flag = 0;
+       mention (b);
+     }
 
   /* That's it. Discard the cleanups for data inserted into the
      breakpoint. */
Index: gdb-6.5/gdb/config/sh/embed.mt
===================================================================
--- gdb-6.5.orig/gdb/config/sh/embed.mt	2007-10-24 16:22:01.000000000 +0100
+++ gdb-6.5/gdb/config/sh/embed.mt	2007-10-24 16:22:45.000000000 +0100
@@ -1,5 +1,5 @@
 # Target: Embedded Renesas Super-H with ICE and simulator
-TDEPFILES= sh-tdep.o sh64-tdep.o monitor.o sh3-rom.o remote-e7000.o ser-e7kpc.o dsrec.o shtdi.o solib.o solib-svr4.o
+TDEPFILES= sh-tdep.o sh64-tdep.o monitor.o sh3-rom.o remote-e7000.o ser-e7kpc.o dsrec.o shtdi.o solib.o solib-svr4.o linux-awareness.o linux-awareness-sh4.o
 DEPRECATED_TM_FILE= tm-sh.h
 
 SIM_OBS = remote-sim.o
Index: gdb-6.5/gdb/linux-awareness.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ gdb-6.5/gdb/linux-awareness.c	2007-10-24 16:50:25.000000000 +0100
@@ -0,0 +1,6211 @@
+
+
+#include "defs.h"
+#include <ctype.h>
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <fcntl.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include "ui-out.h"
+#include "arch-utils.h"
+#include "block.h"
+#include "breakpoint.h"
+#include "cli/cli-decode.h"
+#include "cli/cli-script.h"
+#include "command.h"
+#include "completer.h"
+#include "dictionary.h"
+#include "event-loop.h"
+#include "exceptions.h"
+#include "exec.h"
+#include "frame.h"
+#include "gdb.h"
+#include "gdb_assert.h"
+#include "gdbcmd.h"
+#include "gdbcore.h"
+#include "gdbthread.h"
+#include "gdbtypes.h"
+#include "inferior.h"
+#include "objfiles.h"
+#include "observer.h"
+#include "regcache.h"
+#include "solib.h"
+#include "solist.h"
+#include "symtab.h"
+#include "target.h"
+
+#include "bfd.h"
+#include "libbfd.h"
+#include "elf-bfd.h"
+
+#include "linux-awareness.h"
+
+
+/*************************** Copied from breakpoint.c *************************/
+
+extern struct breakpoint *breakpoint_chain;
+extern int breakpoint_count;
+
+struct breakpoint *set_raw_breakpoint (struct symtab_and_line, enum bptype);
+void set_breakpoint_count (int);
+
+#define ALL_BREAKPOINTS(B)  for (B = breakpoint_chain; B; B = B->next)
+
+#define ALL_BREAKPOINTS_SAFE(B,TMP)	\
+	for (B = breakpoint_chain;	\
+	     B ? (TMP=B->next, 1): 0;	\
+	     B = TMP)
+
+static int
+breakpoint_enabled (struct breakpoint *b)
+{
+  return (b->enable_state == bp_enabled && !b->pending);
+}
+
+static int
+hw_watchpoint_used_count (enum bptype type, int *other_type_used)
+{
+  struct breakpoint *b;
+  int i = 0;
+
+  *other_type_used = 0;
+  ALL_BREAKPOINTS (b)
+  {
+    if (breakpoint_enabled (b))
+      {
+	if (b->type == type)
+	  i++;
+	else if ((b->type == bp_hardware_watchpoint ||
+		  b->type == bp_read_watchpoint ||
+		  b->type == bp_access_watchpoint))
+	  *other_type_used = 1;
+      }
+  }
+  return i;
+}
+
+/******************************************************************************/
+
+enum kernel_autodetection {
+    NOT_LINUX,
+    LINUX_WITHOUT_DEBUGINFO,
+    LINUX_WITH_DEBUGINFO
+};
+
+struct linux_awareness_ops *linux_awareness_ops;
+
+static char **module_search_path;
+static char **target_root_prefix;
+
+static char linux_awareness_doc[] = "";
+
+struct target_ops linux_aware_ops;
+
+struct target_so_ops *old_so_ops;
+struct target_so_ops linux_aware_so_ops;
+
+static int use_linux_awareness;
+int linux_awareness_debug;
+
+static int loaded;
+static int enable_vm_translation = 1;
+static int enable_task_awareness = 1;
+static int linux_awareness_auto_activate_p = 1;
+static int auto_debug_process = 1;
+static unsigned int log_chunk_size = 128;
+static int stick_to_kernelspace;
+
+static struct bp_target_info singlestep_info;
+static ptid_t singlestep_ptid;
+static CORE_ADDR saved_singlestep_dest;
+static ptid_t saved_singlestep_ptid;
+static CORE_ADDR normal_stop_pc;
+static CORE_ADDR normal_stop_sp;
+static int normal_stop_preempt_count;
+
+static int waiting_on_bp;
+static struct breakpoint *step_bp;
+static int force_hw_singlestep;
+
+static ptid_t current_ptid;
+static int    running;
+static int    seen_module_unload;
+
+static CORE_ADDR disable_breakpoint_at_pc;
+
+static int _inhibit_thread_register_awareness;
+
+struct cmd_list_element *set_linux_awareness_cmd_list;
+struct cmd_list_element *show_linux_awareness_cmd_list;
+
+static int global_loglevel;
+struct debug_domain linux_aware_debug_domains_info[] = {
+    { "debug-vm", 0 },
+    { "debug-task", 0 },
+    { "debug-module", 0 },
+    { "debug-target", 0 },
+    { "debug-init", 0 },
+    { "debug-user", 0 },
+    { NULL, 0 }
+};
+
+enum linux_addrs {
+    MODULE_PARAM_SYSFS_SETUP,
+    MODULE_ARCH_CLEANUP,
+    MODULES,
+    INIT_TASK,
+    DO_EXIT,
+    TRY_TO_UNMAP,
+    DO_EXECVE,
+    LOG_END,
+    LOG_BUF_LEN,
+    _LOG_BUF,
+    SHM_IDS,
+    SEM_IDS,
+    MSG_IDS,
+    IOPORT_RESOURCE,
+    IOMEM_RESOURCE,
+    IRQ_DESC,
+    PER_CPU__KSTAT,
+    LINUX_BANNER,
+    SAVED_COMMAND_LINE,
+    TOTALRAM_PAGES,
+    PGDAT_LIST,
+    CONTIG_PAGE_DATA,
+    ALL_BDEVS,
+    SWAPPER_SPACE,
+    NR_SWAP_PAGES,
+    TOTAL_SWAP_PAGES,
+    NR_SWAPFILES,
+    SWAP_INFO,
+    PER_CPU__PAGE_STATES,
+    TOTALHIGH_PAGES,
+    NR_PAGECACHE,
+    VM_COMMITTED_SPACE,
+    SYSCTL_OVERCOMMIT_RATIO,
+    VMLIST,
+    NR_HUGE_PAGES
+};
+
+struct addr_info linux_addrs[] = {
+    [MODULE_PARAM_SYSFS_SETUP] = { "module_param_sysfs_setup" },
+    [MODULE_ARCH_CLEANUP]      = { "module_arch_cleanup" },
+    [MODULES]                  = { "modules" },
+    [INIT_TASK]                = { "init_task" },
+    [DO_EXIT]                  = { "do_exit" },
+    [TRY_TO_UNMAP]             = { "try_to_unmap" },
+    [DO_EXECVE]                = { "search_binary_handler" },
+    [LOG_END]                  = { "log_end" },
+    [LOG_BUF_LEN]              = { "log_buf_len" },
+    [_LOG_BUF]                 = { "__log_buf" },
+    [SHM_IDS]                  = { "shm_ids" },
+    [SEM_IDS]                  = { "sem_ids" },
+    [MSG_IDS]                  = { "msg_ids" },
+    [IOPORT_RESOURCE]          = { "ioport_resource" },
+    [IOMEM_RESOURCE]           = { "iomem_resource" },
+    [IRQ_DESC]                 = { "irq_desc" },
+    [PER_CPU__KSTAT]           = { "per_cpu__kstat" },
+    [LINUX_BANNER]             = { "linux_banner" },
+    [SAVED_COMMAND_LINE]       = { "saved_command_line" },
+    [TOTALRAM_PAGES]           = { "totalram_pages" },
+    [PGDAT_LIST]               = { "pgdat_list" },
+    [CONTIG_PAGE_DATA]         = { "contig_page_data" },
+    [ALL_BDEVS]                = { "all_bdevs" },
+    [SWAPPER_SPACE]            = { "swapper_space" },
+    [NR_SWAP_PAGES]            = { "nr_swap_pages" },
+    [TOTAL_SWAP_PAGES]         = { "totalswap_pages" },
+    [NR_SWAPFILES]             = { "nr_swapfiles" },
+    [SWAP_INFO]                = { "swap_info" },
+    [PER_CPU__PAGE_STATES]     = { "per_cpu__page_states" },
+    [TOTALHIGH_PAGES]          = { "totalhigh_pages" },
+    [NR_PAGECACHE]             = { "nr_pagecache" },
+    [VM_COMMITTED_SPACE]       = { "vm_committed_space" },
+    [SYSCTL_OVERCOMMIT_RATIO]  = { "sysctl_overcommit_ratio" },
+    [VMLIST]                   = { "vmlist" },
+    [NR_HUGE_PAGES]            = { "nr_huge_pages" },
+    {0}
+};
+
+enum linux_fields {
+    LIST_HEAD__NEXT,
+    MODULE__LIST,
+    MODULE__NAME,
+    MODULE__INIT,
+    MODULE__MODULE_INIT,
+    MODULE__MODULE_CORE,
+    MODULE__INIT_SIZE,
+    MODULE__CORE_SIZE,
+    TASK_STRUCT__MM,
+    TASK_STRUCT__CHILDREN,
+    TASK_STRUCT__SIBLING,
+    TASK_STRUCT__PID,
+    TASK_STRUCT__TGID,
+    TASK_STRUCT__COMM,
+    TASK_STRUCT__NAMESPACE,
+    THREAD_INFO__PREEMPT_COUNT,
+    MM_STRUCT__MMAP,
+    MM_STRUCT__ARG_START,
+    MM_STRUCT__ARG_END,
+    MM_STRUCT__ENV_START,
+    MM_STRUCT__ENV_END,
+    VM_AREA_STRUCT__VM_NEXT,
+    VM_AREA_STRUCT__VM_FILE,
+    VM_AREA_STRUCT__VM_FLAGS,
+    VM_AREA_STRUCT__VM_START,
+    VM_AREA_STRUCT__VM_END,
+    VM_AREA_STRUCT__VM_PGOFF,
+    FILE__F_DENTRY,
+    DENTRY__D_PARENT,
+    DENTRY__D_NAME,
+    DENTRY__D_FLAGS,
+    QSTR__LEN,
+    QSTR__NAME,
+    IPC_IDS__IN_USE,
+    IPC_IDS__ENTRIES,
+    IPC_ID_ARY__SIZE,
+    IPC_ID_ARY__P,
+    KERN_IPC_PERM__DELETED,
+    KERN_IPC_PERM__KEY,
+    KERN_IPC_PERM__UID,
+    KERN_IPC_PERM__GID,
+    KERN_IPC_PERM__CUID,
+    KERN_IPC_PERM__CGID,
+    KERN_IPC_PERM__MODE,
+    KERN_IPC_PERM__SEQ,
+    SEM_ARRAY__SEM_NSEMS,
+    SHMID_KERNEL__SNH_NATTCH,
+    SHMID_KERNEL__SNH_SEGSZ,
+    MSG_QUEUE__Q_CBYTES,
+    MSG_QUEUE__Q_QNUM,
+    RESOURCE_NAME,
+    RESOURCE_START,
+    RESOURCE_END,
+    RESOURCE_PARENT,
+    RESOURCE_CHILD,
+    RESOURCE_SIBLING,
+    HW_INTERRUPT_TYPE__TYPENAME,
+    IRQ_DESC__ACTION,
+    IRQ_DESC__HANDLER,
+    IRQ_DESC__IRQ_COUNT,
+    IRQACTION__NAME,
+    IRQACTION__NEXT,
+    KERNEL_STAT__IRQS,
+    SUPER_BLOCK__S_TYPE,
+    SUPER_BLOCK__S_FLAGS,
+    FILE_SYSTEM_TYPE__NAME,
+    VFSMOUNT__MNT_LIST,
+    VFSMOUNT__MNT_PARENT,
+    VFSMOUNT__MNT_DEVNAME,
+    VFSMOUNT__MNT_MOUNTPOINT,
+    VFSMOUNT__MNT_FLAGS,
+    VFSMOUNT__MNT_SB,
+    NAMESPACE__LIST,
+    PGLIST_DATA__NODE_ZONES,
+    PGLIST_DATA__PGDAT_NEXT,
+    ZONE__FREE_PAGES,
+    ZONE__NR_ACTIVE,
+    ZONE__NR_INACTIVE,
+    BLOCK_DEVICE__BD_LIST,
+    BLOCK_DEVICE__BD_INODE,
+    INODE__I_MAPPING,
+    SWAP_INFO_STRUCT__FLAGS,
+    SWAP_INFO_STRUCT__INUSE_PAGES,
+    PAGE_STATE__NR_DIRTY,
+    PAGE_STATE__NR_MAPPED,
+    PAGE_STATE__NR_WRITEBACK,
+    PAGE_STATE__NR_SLAB,
+    PAGE_STATE__NR_PAGE_TABLE_PAGES,
+    VM_STRUCT__NEXT,
+    VM_STRUCT__SIZE
+};
+
+struct field_info linux_fields[] = {
+    /*                                struct_name       field_name   */
+    [LIST_HEAD__NEXT]             = { "list_head",        "next"           },
+    [MODULE__LIST]                = { "module",           "list"           },
+    [MODULE__NAME]                = { "module",           "name"           },
+    [MODULE__INIT]                = { "module",           "init"           },
+    [MODULE__MODULE_INIT]         = { "module",           "module_init"    },
+    [MODULE__MODULE_CORE]         = { "module",           "module_core"    },
+    [MODULE__INIT_SIZE]           = { "module",           "init_size"      },
+    [MODULE__CORE_SIZE]           = { "module",           "core_size"      },
+    [TASK_STRUCT__MM]             = { "task_struct",      "mm"             },
+    [TASK_STRUCT__CHILDREN]       = { "task_struct",      "children"       },
+    [TASK_STRUCT__SIBLING]        = { "task_struct",      "sibling"        },
+    [TASK_STRUCT__PID]            = { "task_struct",      "pid"            },
+    [TASK_STRUCT__TGID]           = { "task_struct",      "tgid"           },
+    [TASK_STRUCT__COMM]           = { "task_struct",      "comm"           },
+    [TASK_STRUCT__NAMESPACE]      = { "task_struct",      "namespace"      },
+    [THREAD_INFO__PREEMPT_COUNT]  = { "thread_info",      "preempt_count"  },
+    [MM_STRUCT__MMAP]             = { "mm_struct",        "mmap"           },
+    [MM_STRUCT__ARG_START]        = { "mm_struct",        "arg_start"      },
+    [MM_STRUCT__ARG_END]          = { "mm_struct",        "arg_end"        },
+    [MM_STRUCT__ENV_START]        = { "mm_struct",        "env_start"      },
+    [MM_STRUCT__ENV_END]          = { "mm_struct",        "env_end"        },
+    [VM_AREA_STRUCT__VM_NEXT]     = { "vm_area_struct",   "vm_next"        },
+    [VM_AREA_STRUCT__VM_FILE]     = { "vm_area_struct",   "vm_file"        },
+    [VM_AREA_STRUCT__VM_FLAGS]    = { "vm_area_struct",   "vm_flags"       },
+    [VM_AREA_STRUCT__VM_START]    = { "vm_area_struct",   "vm_start"       },
+    [VM_AREA_STRUCT__VM_END]      = { "vm_area_struct",   "vm_end"         },
+    [VM_AREA_STRUCT__VM_PGOFF]    = { "vm_area_struct",   "vm_pgoff"       },
+    [FILE__F_DENTRY]              = { "file",             "f_dentry"       },
+    [DENTRY__D_PARENT]            = { "dentry",           "d_parent"       },
+    [DENTRY__D_NAME]              = { "dentry",           "d_name"         },
+    [DENTRY__D_FLAGS]             = { "dentry",           "d_flags"        },
+    [QSTR__LEN]                   = { "qstr",             "len"            },
+    [QSTR__NAME]                  = { "qstr",             "name"           },
+    [IPC_IDS__IN_USE]             = { "ipc_ids",          "in_use"         },
+    [IPC_IDS__ENTRIES]            = { "ipc_ids",          "entries"        },
+    [IPC_ID_ARY__SIZE]            = { "ipc_id_ary",       "size"           },
+    [IPC_ID_ARY__P]               = { "ipc_id_ary",       "p"              },
+    [KERN_IPC_PERM__DELETED]      = { "kern_ipc_perm",    "deleted"        },
+    [KERN_IPC_PERM__KEY]          = { "kern_ipc_perm",    "key"            },
+    [KERN_IPC_PERM__UID]          = { "kern_ipc_perm",    "uid"            },
+    [KERN_IPC_PERM__GID]          = { "kern_ipc_perm",    "gid"            },
+    [KERN_IPC_PERM__CUID]         = { "kern_ipc_perm",    "cuid"           },
+    [KERN_IPC_PERM__CGID]         = { "kern_ipc_perm",    "cgid"           },
+    [KERN_IPC_PERM__MODE]         = { "kern_ipc_perm",    "mode"           },
+    [KERN_IPC_PERM__SEQ]          = { "kern_ipc_perm",    "seq"            },
+    [SEM_ARRAY__SEM_NSEMS]        = { "sem_array",        "sem_nsems"      },
+    [SHMID_KERNEL__SNH_NATTCH]    = { "shmid_kernel",     "shm_nattch"     },
+    [SHMID_KERNEL__SNH_SEGSZ]     = { "shmid_kernel",     "shm_segsz"      },
+    [MSG_QUEUE__Q_CBYTES]         = { "msg_queue",        "q_cbytes"       },
+    [MSG_QUEUE__Q_QNUM]           = { "msg_queue",        "q_qnum"         },
+    [RESOURCE_NAME]               = { "resource",         "name"           },
+    [RESOURCE_START]              = { "resource",         "start"          },
+    [RESOURCE_END]                = { "resource",         "end"            },
+    [RESOURCE_PARENT]             = { "resource",         "parent"         },
+    [RESOURCE_CHILD]              = { "resource",         "child"          },
+    [RESOURCE_SIBLING]            = { "resource",         "sibling"        },
+    [HW_INTERRUPT_TYPE__TYPENAME] = {"hw_interrupt_type", "typename"       },
+    [IRQ_DESC__ACTION]            = { "irq_desc",         "action"         },
+    [IRQ_DESC__HANDLER]           = { "irq_desc",         "handler"        },
+    [IRQ_DESC__IRQ_COUNT]         = { "irq_desc",         "irq_count"      },
+    [IRQACTION__NAME]             = { "irqaction",        "name"           },
+    [IRQACTION__NEXT]             = { "irqaction",        "next"           },
+    [KERNEL_STAT__IRQS]           = { "kernel_stat",      "irqs"           },
+    [SUPER_BLOCK__S_TYPE]         = { "super_block",      "s_type"         },
+    [SUPER_BLOCK__S_FLAGS]        = { "super_block",      "s_flags"        },
+    [FILE_SYSTEM_TYPE__NAME]      = { "file_system_type", "name"           },
+    [VFSMOUNT__MNT_LIST]          = { "vfsmount",         "mnt_list"       },
+    [VFSMOUNT__MNT_PARENT]        = { "vfsmount",         "mnt_parent"     },
+    [VFSMOUNT__MNT_DEVNAME]       = { "vfsmount",         "mnt_devname"    },
+    [VFSMOUNT__MNT_MOUNTPOINT]    = { "vfsmount",         "mnt_mountpoint" },
+    [VFSMOUNT__MNT_FLAGS]         = { "vfsmount",         "mnt_flags"      },
+    [VFSMOUNT__MNT_SB]            = { "vfsmount",         "mnt_sb"         },
+    [NAMESPACE__LIST]             = { "namespace",        "list"           },
+    [PGLIST_DATA__NODE_ZONES]     = { "pglist_data",      "node_zones"     },
+    [PGLIST_DATA__PGDAT_NEXT]     = { "pglist_data",      "pgdat_next"     },
+    [ZONE__FREE_PAGES]            = { "zone",             "free_pages"     },
+    [ZONE__NR_ACTIVE]             = { "zone",             "nr_active"      },
+    [ZONE__NR_INACTIVE]           = { "zone",             "nr_inactive"    },
+    [BLOCK_DEVICE__BD_LIST]       = { "block_device",     "bd_list"        },
+    [BLOCK_DEVICE__BD_INODE]      = { "block_device",     "bd_inode"       },
+    [INODE__I_MAPPING]            = { "inode",            "i_mapping"      },
+    [SWAP_INFO_STRUCT__FLAGS]     = { "swap_info_struct", "flags"          },
+    [SWAP_INFO_STRUCT__INUSE_PAGES] = { "swap_info_struct",  "inuse_pages" },
+    [PAGE_STATE__NR_DIRTY]        = { "page_state",       "nr_dirty"       },
+    [PAGE_STATE__NR_MAPPED]       = { "page_state",       "nr_mapped"      },
+    [PAGE_STATE__NR_WRITEBACK]    = { "page_state",       "nr_writeback"   },
+    [PAGE_STATE__NR_SLAB]         = { "page_state",       "nr_slab"        },
+    [PAGE_STATE__NR_PAGE_TABLE_PAGES] = { "page_state","nr_page_table_pages" },
+    [VM_STRUCT__NEXT]             = { "vm_struct",        "next"           },
+    [VM_STRUCT__SIZE]             = { "vm_struct",        "size"           },
+    {0}
+};
+
+#define HAS_ADDR(symb) (linux_addrs[symb].sym != NULL)
+#define ADDR(sym) linux_get_address (&linux_addrs[sym])
+
+#define FIELD_OFFSET(sym) linux_get_field_offset (&linux_fields[sym])
+#define FIELD_SIZE(sym) linux_get_field_size (&linux_fields[sym])
+#define HAS_FIELD(sym) (linux_fields[sym].type != NULL)
+
+struct address_container {
+    struct address_container *next;
+    const char *name;
+    CORE_ADDR addr;
+} *address_containers;
+
+struct field_container {
+    struct field_container *next;
+    struct symbol *type;
+    const char *struct_name;
+    const char *field_name;
+    int offset;
+    int size;
+    unsigned int user_set_size   : 1;
+    unsigned int user_set_offset : 1;
+    unsigned int warned          : 1;
+} *field_containers;
+
+/* Data which we have to change only when the image changes */
+
+static int init_module_return_resolved;
+
+/* solib emulation data */
+
+static struct breakpoint *shlib_event_load_bp;
+static struct breakpoint *shlib_event_init_bp;
+static struct breakpoint *shlib_event_free_bp;
+static struct breakpoint *thread_event_do_exit_bp;
+static struct breakpoint *thread_event_low_mem_bp;
+static struct breakpoint *thread_event_do_exec_bp;
+static struct breakpoint *thread_event_do_exec_return_bp;
+
+static struct observer *normal_stop_observer;
+
+struct lm_info {
+    char module_name[SO_NAME_MAX_PATH_SIZE];
+    CORE_ADDR this_module;
+    CORE_ADDR init;
+    CORE_ADDR module_init;
+    CORE_ADDR module_core;
+    ULONGEST  init_size;
+    ULONGEST  core_size;
+
+    ULONGEST  computed_init_size;
+    int needs_relocated_file;
+
+    char *real_file;
+    char *relocated_file;
+    unsigned int *section_offsets;
+
+    int so_list_updated;
+    struct so_list *mod;
+};
+
+struct lm_info_list {
+    struct lm_info *info;
+    struct lm_info_list *next;
+};
+
+struct lm_info_list *lm_infos;
+struct lm_info *last_loaded;
+
+struct module_bfd_copy_info {
+    bfd             *old;
+    bfd             *new;
+    struct lm_info  *lm_info;
+    asection       **sec_mapping;
+};
+
+struct translation_info {
+    CORE_ADDR *addr;
+    CORE_ADDR task_struct;
+};
+
+static CORE_ADDR last_warned;
+
+struct process {
+    struct process *next;
+    CORE_ADDR       task_struct_address;
+    unsigned int    pid;
+    unsigned int    tgid;
+    CORE_ADDR       mm;
+    char          *comm;
+} *processes = NULL;
+
+struct debugged_user_process {
+    struct debugged_user_process *next;
+
+    int             pid;
+    int             gdb_thread_id;
+    CORE_ADDR       task_struct_address;
+    struct objfile *objfiles;
+    struct objfile *main_objfile;
+};
+
+struct waited_exe {
+    struct waited_exe   *next;
+    char                *name;
+    struct command_line *cmds;
+};
+
+struct debugged_user_process *user_processes;
+struct debugged_user_process *current_user_process;
+struct process *current_process;
+
+struct waited_exe *waited_exes;
+
+static const char *fallback_tmpdirs[] = { "/tmp", "/var/tmp", "." };
+static const char *tmpdir = NULL;
+
+static unsigned int resetting_bps_after_init;
+static enum kernel_autodetection autodetection = NOT_LINUX;
+
+static void (*deprecated_call_command_chain) (struct cmd_list_element *c,
+					      char *cmd, int from_tty);
+static void (*deprecated_create_breakpoint_chain) (struct breakpoint *bpt);
+static void (*deprecated_delete_breakpoint_chain) (struct breakpoint *bpt);
+static void (*deprecated_context_chain) (int id);
+
+static void thread_list_clear_cache ();
+static CORE_ADDR get_current_task_struct ();
+static void delete_temp_files ();
+static struct process* thread_list_contains_pid (unsigned int pid);
+static void linux_aware_objfile_relocate (struct objfile *objfile,
+					  CORE_ADDR init_start,
+					  CORE_ADDR init_end,
+					  CORE_ADDR core_start,
+					  CORE_ADDR core_end);
+
+static void normal_stop_callback (struct bpstats *bs);
+
+static void linux_aware_software_single_step (enum target_signal sig,
+					      int insert_breakpoints_p);
+static void switch_to_user_process (struct process *ps);
+static void delete_user_process (int thread_id);
+static void debug_process_command (char *args, int from_tty);
+
+static struct process *get_gdb_process ();
+
+struct monitored_page;
+static void add_bpt_to_monitored_page (struct monitored_page *page,
+				       struct breakpoint *bpt);
+static struct monitored_page *find_monitored_page (CORE_ADDR addr);
+static struct monitored_page *create_monitored_page (CORE_ADDR addr,
+						     struct breakpoint *bp);
+static char *read_dentry (CORE_ADDR dentry);
+static void check_exec_actions();
+
+static void
+free_cmd_list (struct cmd_list_element **list, int free_name)
+{
+    struct cmd_list_element *tmp;
+    char *name;
+
+    for ( ; *list ? (tmp = (*list)->next, 1) : 0 ; *list = tmp) {
+	name = (*list)->name;
+	if (strncmp (name, "field_", strlen("field_")))
+	    continue;
+	xfree ((*list)->doc);
+	delete_cmd (name, list);
+	if (free_name) xfree (name);
+    }
+}
+
+static void
+free_field_cmd_list ()
+{
+    free_cmd_list (&set_linux_awareness_cmd_list, 0);
+    free_cmd_list (&show_linux_awareness_cmd_list, 1);
+}
+
+static int
+linux_check_address (struct addr_info* addr)
+{
+    if (addr->sym == NULL) {
+	addr->sym = lookup_minimal_symbol (addr->name, NULL, NULL);
+
+	if (addr->sym)
+	    DEBUG (INIT, 2, "Checking for address of '%s' : OK\n", addr->name);
+	else
+	    DEBUG (INIT, 1, "Checking for address of '%s' : NOT FOUND\n",
+		   addr->name);
+    }
+
+    return addr->sym != NULL;
+}
+
+int
+linux_check_addresses (struct addr_info* addr)
+{
+    while (addr->name)
+	if (!linux_check_address (addr++))
+	    return 0;
+
+    return 1;
+}
+
+static struct address_container *
+find_address_container (const char *name)
+{
+    struct address_container *res = address_containers;
+
+    while (res) {
+	if (! strcmp (res->name, name))
+	    return res;
+	res = res->next;
+    }
+
+    res = xcalloc (1, sizeof (struct address_container));
+    res->next = address_containers;
+    res->name = name;
+    address_containers = res;
+
+    return res;
+}
+
+static int
+linux_init_address (struct addr_info *addr)
+{
+    struct address_container *container;
+
+    container = find_address_container (addr->name);
+    addr->addr = &container->addr;
+
+    if (!linux_check_address (addr)) {
+	warning ("Couldn't find address of symbol '%s'. Some functionality "
+		 "won't be available.", addr->name);
+	return 0;
+    }
+
+    container->addr = SYMBOL_VALUE_ADDRESS (addr->sym);
+    DEBUG (INIT, 2, "%s address is %s\n", container->name,
+	   paddr (container->addr));
+    return 1;
+}
+
+int
+linux_init_addresses (struct addr_info *addr)
+{
+    int all_inited = 1;
+
+    while (addr->name) {
+	if (! (linux_check_address (addr) && linux_init_address (addr)))
+	    all_inited = 0;
+	++addr;
+    }
+
+    return all_inited;
+}
+
+void
+linux_free_addresses (struct addr_info *info)
+{
+    struct address_container *addr = address_containers;
+
+    while (addr) {
+	address_containers = addr->next;
+	xfree (addr);
+	addr = address_containers;
+    }
+
+    while (info->name) {
+	info->sym = NULL;
+	info->addr = NULL;
+	++info;
+    }
+}
+
+CORE_ADDR
+linux_get_address (struct addr_info *addr)
+{
+    if (! addr->sym)
+	error ("No address found for symbol '%s'.", addr->name);
+
+    return *addr->addr;
+}
+
+static int
+linux_check_field (struct field_info *field)
+{
+    if (field->type == NULL) {
+	field->type = lookup_symbol (field->struct_name,
+				     NULL, STRUCT_DOMAIN, 0, NULL);
+	if (field->type)
+	    DEBUG (INIT, 2, "Checking for 'struct %s' : OK\n",
+		   field->struct_name);
+	else
+	    DEBUG (INIT, 1, "Checking for 'struct %s' : NOT FOUND\n",
+		   field->struct_name);
+    }
+
+    return field->type != NULL;
+}
+
+int
+linux_check_fields (struct field_info *field)
+{
+    while (field->struct_name)
+	if (! linux_check_field (field++))
+	    return 0;
+
+    return 1;
+}
+
+static struct field_container *
+search_field_container (const char *struct_name, const char *field_name)
+{
+    struct field_container *res = field_containers;
+
+    while (res) {
+	if (! strcmp (res->struct_name, struct_name)
+	    && ! strcmp (res->field_name, field_name))
+	    return res;
+	res = res->next;
+    }
+
+    return NULL;
+}
+
+static void
+set_field_offset (char *args, int from_tty,
+		  struct cmd_list_element *c)
+{
+    struct field_container *cont;
+
+    cont = (void *) ((char*)c->var - offsetof (struct field_container, offset));
+    cont->user_set_offset = 1;
+}
+
+static void
+set_field_size (char *args, int from_tty,
+		struct cmd_list_element *c)
+{
+    struct field_container *cont;
+
+    cont = (void *) ((char*)c->var - offsetof (struct field_container, size));
+    cont->user_set_size = 1;
+}
+
+void
+linux_certify_field (struct field_info *field)
+{
+    struct field_container *cont;
+
+    cont = (void *) ((char*)field->offset
+		     - offsetof (struct field_container, offset));
+    cont->user_set_offset = 1;
+    cont->user_set_size = 1;
+}
+
+static struct field_container *
+find_field_container (const char *struct_name, const char *field_name)
+{
+    struct field_container *res ;
+    char *cmd_name;
+
+    res = search_field_container (struct_name, field_name);
+
+    if (res != NULL)
+	return res;
+
+    res = xcalloc (1, sizeof(struct field_container));
+    res->next = field_containers;
+    res->struct_name = struct_name;
+    res->field_name = field_name;
+    field_containers = res;
+
+    /* Use zinteger and not uinteger because 0 is treated as unlimited
+       by uinteger ans is replaced by UINT_MAX. As 0 is a correct offset
+       value, we don't want that. */
+    cmd_name = xmalloc (strlen (field_name)+strlen (struct_name)+2+13);
+    sprintf (cmd_name, "field_offset_%s_%s", struct_name, field_name);
+    add_setshow_zinteger_cmd (cmd_name, no_class, &res->offset,
+			      "Set offset of field.",
+			      "Show offset of field.",
+			      NULL, set_field_offset, NULL,
+			      &set_linux_awareness_cmd_list,
+			      &show_linux_awareness_cmd_list);
+    cmd_name = xmalloc (strlen (field_name)+strlen (struct_name)+2+13);
+    sprintf (cmd_name, "field_size_%s_%s", struct_name, field_name);
+    add_setshow_zinteger_cmd (cmd_name, no_class, &res->size,
+			      "Set size of field.",
+			      "Show size of field.",
+			      NULL, set_field_size, NULL,
+			      &set_linux_awareness_cmd_list,
+			      &show_linux_awareness_cmd_list);
+    return res;
+}
+
+static void
+struct_definitions (char *args, int from_tty)
+{
+    struct field_container *cont = field_containers;
+    struct ui_file *out;
+
+    if (!args || *args == '\0')
+	out = gdb_stdout;
+    else
+	out = gdb_fopen (args, "w");
+
+    if (out == NULL)
+	error ("Could not open '%s' for writing\n", args);
+
+    fprintf_filtered (out, "set linux-awareness enabled yes\n");
+    fprintf_filtered (out, "set linux-awareness loaded yes\n");
+
+    while (cont) {
+	fprintf_filtered (out, "set linux-awareness field_offset_%s_%s %i\n",
+			  cont->struct_name, cont->field_name, cont->offset);
+	fprintf_filtered (out, "set linux-awareness field_size_%s_%s %i\n",
+			  cont->struct_name, cont->field_name, cont->size);
+	cont = cont->next;
+    }
+    gdb_flush (out);
+    if (out != gdb_stdout)
+	ui_file_delete (out);
+}
+
+static int
+find_struct_field (struct type *type, char *field, int *offset, int *size)
+{
+    int i;
+
+    for (i=0; i<TYPE_NFIELDS (type); ++i) {
+	if (! strcmp(FIELD_NAME (TYPE_FIELDS (type)[i]), field))
+	    break;
+    }
+
+    if (i >= TYPE_NFIELDS (type))
+	return 0;
+
+    *offset = FIELD_BITPOS (TYPE_FIELDS (type)[i])/TARGET_CHAR_BIT;
+    *size = TYPE_LENGTH (check_typedef (TYPE_FIELDS (type)[i].type));
+    return 1;
+}
+
+static int
+linux_init_field (struct field_info *field)
+{
+    struct field_container *container;
+
+    container = find_field_container (field->struct_name, field->field_name);
+    field->offset = &container->offset;
+    field->size = &container->size;
+
+    if (! linux_check_field (field)) {
+	DEBUG (INIT, 2, "Couldn't init struct %s::%s\n", field->struct_name,
+	       field->field_name);
+	container->offset = field->default_offset;
+	container->size = field->default_size;
+	return 0;
+    }
+
+    if (!find_struct_field (SYMBOL_TYPE (field->type), field->field_name,
+			    &container->offset, &container->size)) {
+	DEBUG (INIT, 2, "No such field %s::%s\n", field->struct_name,
+	       field->field_name);
+	container->offset = field->default_offset;
+	container->size = field->default_size;
+	return 0;
+    }
+
+    container->type = field->type;
+    if (container->offset != field->default_offset)
+	DEBUG (INIT, 1, "%s::%s has mismatching default offset : %i != %i\n",
+	       field->struct_name, field->field_name,
+	       container->offset, field->default_offset);
+
+    if (container->size != field->default_size)
+	DEBUG (INIT, 1, "%s::%s has mismatching default size : %i != %i\n",
+	       field->struct_name, field->field_name,
+	       container->size, field->default_size);
+
+    DEBUG (INIT, 2, "%s::%s => offset %i  size %i\n", field->struct_name,
+	   field->field_name, container->offset, container->size);
+    return 1;
+}
+
+int
+linux_init_fields (struct field_info *field)
+{
+    int all_inited = 1;
+
+    while (field->struct_name)
+	if (! linux_init_field (field++))
+	    all_inited = 0;
+
+    return all_inited;
+}
+
+void
+linux_free_fields(struct field_info *info)
+{
+    struct field_container *field = field_containers;
+
+    while (field) {
+	field_containers = field->next;
+	xfree (field);
+	field = field_containers;
+    }
+
+    free_field_cmd_list ();
+
+    while (info->struct_name) {
+	info->type = NULL;
+	++info;;
+    }
+}
+
+static void
+linux_warn_field (struct field_container *field)
+{
+    if (field->type == NULL
+	&& ! field->warned) {
+	warning ("No debug information found for field '%s' of 'struct %s'. "
+		 "Using default values (offset %i, size %i). See 'set "
+		 "linux-awareness field_offset_%s_%s' and 'set linux-awareness "
+		 "field_size_%s_%s'",
+		 field->field_name, field->struct_name, field->offset,
+		 field->size,
+		 field->struct_name, field->field_name,
+		 field->struct_name, field->field_name);
+	field->warned = 1;
+    }
+}
+
+unsigned int
+linux_get_field_offset (struct field_info *field)
+{
+    struct field_container *cont;
+    cont = (void*)((char*)(field->offset)
+		   - offsetof (struct field_container, offset));
+
+    if (cont->user_set_offset)
+	return cont->offset;
+
+    linux_warn_field (cont);
+    return cont->offset;
+}
+
+unsigned int
+linux_get_field_size (struct field_info *field)
+{
+    struct field_container *cont;
+    cont = (void*)((char*)(field->offset)
+		   - offsetof(struct field_container, offset));
+
+    if (cont->user_set_size)
+	return cont->size;
+
+    linux_warn_field (cont);
+    return cont->size;
+}
+
+ULONGEST
+read_unsigned_field (CORE_ADDR base, int field_id)
+{
+    return read_memory_unsigned_integer (base + FIELD_OFFSET (field_id),
+					 FIELD_SIZE (field_id));
+}
+
+LONGEST
+read_signed_field (CORE_ADDR base, int field_id)
+{
+    return read_memory_integer (base + FIELD_OFFSET (field_id),
+				FIELD_SIZE (field_id));
+}
+
+CORE_ADDR
+read_pointer_field (CORE_ADDR base, int field_id)
+{
+    return read_memory_typed_address (base + FIELD_OFFSET (field_id),
+				      builtin_type_void_data_ptr);
+}
+
+ULONGEST
+read_unsigned_embedded_field (CORE_ADDR base, int field_id, int embedder_id)
+{
+    return read_memory_unsigned_integer (base + FIELD_OFFSET (field_id)
+					 + FIELD_OFFSET (embedder_id),
+					 FIELD_SIZE (field_id));
+}
+
+LONGEST
+read_signed_embedded_field (CORE_ADDR base, int field_id, int embedder_id)
+{
+    return read_memory_integer(base + FIELD_OFFSET (field_id)
+				      + FIELD_OFFSET (embedder_id),
+				      FIELD_SIZE (field_id));
+}
+
+CORE_ADDR
+read_pointer_embedded_field (CORE_ADDR base, int field_id, int embedder_id)
+{
+    return read_memory_typed_address (base + FIELD_OFFSET (field_id)
+				      + FIELD_OFFSET (embedder_id),
+				      builtin_type_void_data_ptr);
+}
+
+ULONGEST
+extract_unsigned_field (gdb_byte *base, int field_id)
+{
+    return extract_unsigned_integer(base + FIELD_OFFSET (field_id),
+				    FIELD_SIZE (field_id));
+}
+
+LONGEST
+extract_signed_field (gdb_byte *base, int field_id)
+{
+    return extract_signed_integer (base + FIELD_OFFSET (field_id),
+				   FIELD_SIZE (field_id));
+}
+
+CORE_ADDR
+extract_pointer_field (gdb_byte *base, int field_id)
+{
+    return extract_typed_address (base + FIELD_OFFSET (field_id),
+				  builtin_type_void_data_ptr);
+}
+
+static void
+init_linux_fields ()
+{
+    struct field_info *info = linux_fields;
+    struct field_container *container;
+
+    while (info->struct_name) {
+	container = search_field_container (info->struct_name,
+					    info->field_name);
+	if (container == NULL)
+	    error ("\
+Your linux-awareness targetting don't provide definitions for the field '%s'\n\
+of the struct %s.", info->field_name, info->struct_name);
+
+	info->type = container->type;
+	info->offset = &container->offset;
+	info->size = &container->size;
+	++info;
+    }
+}
+
+static void
+reinit_linux_fields ()
+{
+    struct field_info *info = linux_fields;
+
+    while (info->struct_name) {
+	info->type = NULL;
+	info->offset = NULL;
+	info->size = NULL;
+	++info;
+    }
+}
+
+static int
+thread_awareness_inhibited ()
+{
+    return !enable_task_awareness || _inhibit_thread_register_awareness;
+}
+
+static void
+thread_awareness_inhibit ()
+{
+    ++_inhibit_thread_register_awareness;
+}
+
+static void
+thread_awareness_exhibit ()
+{
+    --_inhibit_thread_register_awareness;
+}
+
+static ptid_t
+linux_aware_pid_to_ptid (int pid)
+{
+    return ptid_build (pid, 1, 1);
+}
+
+static int
+translate_memory_address_safe (CORE_ADDR *addr, int silent)
+{
+    if (!enable_vm_translation)
+	return 1;
+
+    if (!linux_awareness_ops->lo_address_needs_translation (*addr))
+	return 1;
+
+    {
+	CORE_ADDR saved_addr = *addr;
+	CORE_ADDR task_struct = get_current_task_struct ();
+	CORE_ADDR page = *addr & ~((1<<linux_awareness_ops->page_shift)-1);
+	enum page_status res;
+
+	thread_awareness_inhibit();
+	res = linux_awareness_ops->lo_translate_memory_address (addr,
+								task_struct);
+	thread_awareness_exhibit();
+
+	if (res == PAGE_PRESENT)
+	    return 1;
+
+	if (! silent
+	    && last_warned != page) {
+	    printf_filtered("Error translating memory addresses: ");
+	    switch (res) {
+	    case PAGE_SWAPPED:
+		printf_filtered("page 0x%s is swapped out.\n", paddr (page));
+		break;
+	    case PAGE_NOTMAPPED:
+		printf_filtered("page 0x%s is not mapped to memory.\n",
+				paddr (page));
+		break;
+	    case PAGE_NOPAGE:
+		printf_filtered("page 0x%s is not allocated yet.\n",
+				paddr (page));
+		break;
+	    case PAGE_UNKNOWN:
+		printf_filtered("Error walking page tables for page 0x%s.\n",
+				paddr (page));
+		break;
+	    default:
+		printf_filtered("Unexpected return value for page 0x%s.\n",
+				paddr (page));
+		break;
+	    }
+	    last_warned = page;
+	}
+
+	*addr = saved_addr;
+    }
+
+    return 0;
+}
+
+static int
+page_writable (CORE_ADDR addr)
+{
+    if (!enable_vm_translation)
+	return 1;
+
+    return linux_awareness_ops->lo_can_write (addr, get_current_task_struct ());
+}
+
+/*****************************************************************************/
+/*               Copied and adapted from kernel/module.c                     */
+/*****************************************************************************/
+
+#define ALIGN(x,a) (((x)+(a)-1)&~((a)-1))
+
+/* Update size with this section: return offset. */
+static long
+get_offset (unsigned long *size, Elf_Internal_Shdr *sechdr)
+{
+	long ret;
+
+	ret = ALIGN (*size, sechdr->sh_addralign ?: 1);
+	*size = ret + sechdr->sh_size;
+	return ret;
+}
+
+/* This isn't true for ia64 and alpha. But we don't care... */
+#define ARCH_SHF_SMALL 0
+
+/* Lay out the SHF_ALLOC sections in a way not dissimilar to how ld
+   might -- code, read-only data, read-write data, small data.  Tally
+   sizes, and place the offsets into sh_entsize fields: high bit means it
+   belongs in init. */
+static void
+layout_sections (bfd* file, struct lm_info *lm_info)
+{
+    static unsigned long const masks[][2] = {
+	/* NOTE: all executable code must be the first section
+	 * in this array; otherwise modify the text_size
+	 * finder in the two loops below */
+	{ SHF_EXECINSTR | SHF_ALLOC, ARCH_SHF_SMALL },
+	{ SHF_ALLOC, SHF_WRITE | ARCH_SHF_SMALL },
+	{ SHF_WRITE | SHF_ALLOC, ARCH_SHF_SMALL },
+	{ ARCH_SHF_SMALL | SHF_ALLOC, 0 }
+    };
+    unsigned int m, i;
+
+    unsigned long core_size = 0;
+    unsigned long init_size = 0;
+    unsigned int sec_count = file->section_count;
+    asection *bfd_sec;
+    Elf_Internal_Shdr **sechdrs = elf_elfsections (file);
+    Elf_Internal_Ehdr *hdr = elf_elfheader (file);
+
+    unsigned long *offsets = alloca(hdr->e_shnum * sizeof (unsigned long));
+    memset (offsets, 0xFF, hdr->e_shnum * sizeof (unsigned long));
+
+    lm_info->section_offsets = xmalloc (sizeof (unsigned int)*sec_count);
+    memset (lm_info->section_offsets, 0, sizeof (unsigned int)*sec_count);
+
+    /* Is this kosher ? Maybe we should copy the flags in a local
+       array before we modify these. */
+    for (i = 0; i < hdr->e_shnum; ++i) {
+	Elf_Internal_Shdr *s = sechdrs[i];
+	int ix = elf_elfheader(file)->e_shstrndx;
+	char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+
+	if (! strcmp (name, ".modinfo"))
+	    s->sh_flags &= ~SHF_ALLOC;
+	else if (! strcmp (name, ".symtab"))
+	    s->sh_flags |= SHF_ALLOC;
+	else if (! strcmp (name, ".strtab"))
+	    s->sh_flags |= SHF_ALLOC;
+    }
+
+    DEBUG (MODULE, 4, "Core section allocation order:\n");
+    for (m = 0; m < ARRAY_SIZE (masks); ++m) {
+	for (i = 0; i < hdr->e_shnum; ++i) {
+	    Elf_Internal_Shdr *s = sechdrs[i];
+	    int ix = elf_elfheader(file)->e_shstrndx;
+	    char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+
+	    if ((s->sh_flags & masks[m][0]) != masks[m][0]
+		|| (s->sh_flags & masks[m][1])
+		|| offsets[i] != ~0UL
+		|| strncmp (name, ".init", 5) == 0)
+		continue;
+	    offsets[i] = get_offset (&core_size, s) + lm_info->module_core;
+
+	    DEBUG (MODULE, 4, "\t%s 0x%lx\n", name, offsets[i]);
+	}
+    }
+
+    DEBUG (MODULE, 4, "Init section allocation order:\n");
+    for (m = 0; m < ARRAY_SIZE(masks); ++m) {
+	for (i = 0; i < hdr->e_shnum; ++i) {
+	    Elf_Internal_Shdr *s = sechdrs[i];
+	    int ix = elf_elfheader(file)->e_shstrndx;
+	    char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+	    if ((s->sh_flags & masks[m][0]) != masks[m][0]
+		|| (s->sh_flags & masks[m][1])
+		|| offsets[i] != ~0UL
+		|| strncmp(name, ".init", 5) != 0)
+		continue;
+	    offsets[i] = get_offset(&init_size, s) + lm_info->module_init;
+	    DEBUG (MODULE, 4, "\t%s 0x%lx\n", name, offsets[i]);
+	}
+    }
+
+    lm_info->computed_init_size = init_size;
+
+    DEBUG (MODULE, 4, "Remapping on BFD section:\n");
+    for (i = 0; i < hdr->e_shnum; ++i) {
+	Elf_Internal_Shdr *s = sechdrs[i];
+	int ix = elf_elfheader(file)->e_shstrndx;
+	char *name = bfd_elf_string_from_elf_section (file, ix, s->sh_name);
+	asection* sect = bfd_get_section_by_name (file, name);
+
+	if (sect == NULL || offsets[i] == ~0UL)
+	    continue;
+
+	if (strncmp (sect->name, ".init.", 6) == 0
+	    || strncmp (sect->name, ".exit.", 6) == 0)
+	    lm_info->needs_relocated_file = 1;
+
+	if (strcmp (name, ".gnu.linkonce.this_module") == 0) {
+	    lm_info->section_offsets[sect->index] = lm_info->this_module;
+	} else if (bfd_get_section_flags (file, sect) & SEC_ALLOC) {
+	    lm_info->section_offsets[sect->index] = offsets[i];
+	    DEBUG (MODULE, 4, "\t%s 0x%lx\n", name, offsets[i]);
+	}
+    }
+}
+
+/****************************************************************************/
+
+static struct bp_location *
+bp_location_from_shadow_contents(struct bp_target_info *info)
+{
+    struct bp_location *bp_loc;
+
+    if (info->shadow_contents == singlestep_info.shadow_contents)
+	return NULL;
+
+    bp_loc = (struct bp_location *)((char*)info - offsetof(struct bp_location,
+														target_info));
+    if (bp_loc->address != info->placed_address
+	|| bp_loc->requested_address != info->placed_address) {
+	warning ("Unknown bp location passed to target. 0x%p 0x%p 0x%p", bp_loc->address,
+														bp_loc->requested_address, info->placed_address);
+	return NULL;
+    }
+
+    return bp_loc;
+}
+
+static int
+linux_aware_insert_breakpoint (struct bp_target_info *info)
+{
+    struct bp_location *bp_loc;
+    ptid_t saved_ptid = inferior_ptid;
+    int res;
+    CORE_ADDR addr = info->placed_address;
+    CORE_ADDR singlestep_dest = singlestep_info.placed_address;
+    bp_loc = bp_location_from_shadow_contents (info);
+    DEBUG (TARGET, 2,"inserting bp at 0x%x %s\n",
+	   (unsigned int)addr,
+	   bp_loc == NULL ? "(SS)" : "");
+
+    if (info->placed_address == ~(CORE_ADDR)0)
+	return 0;
+
+    if (disable_breakpoint_at_pc == addr) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    /* Choose the right inferior_ptid so that the address translation
+       works. */
+    if (bp_loc != NULL && bp_loc->owner->thread != -1) {
+	inferior_ptid = thread_id_to_pid(bp_loc->owner->thread);
+    } else if (bp_loc == NULL && info->placed_address == singlestep_dest) {
+	inferior_ptid = singlestep_ptid;
+    }
+
+    if (! translate_memory_address_safe (&addr, 1)) {
+	inferior_ptid = saved_ptid;
+	DEBUG (TARGET, 2,"error inserting bp at 0x%x\n", (unsigned int)addr);
+	return 1;
+    }
+
+    if (info->placed_address != addr) {
+	thread_awareness_inhibit();
+	linux_awareness_ops->lo_flush_cache (info->placed_address, addr, 2, 1);
+	DEBUG (TARGET, 2,"\t real addr 0x%x\n", (unsigned int)addr);
+    }
+
+    /* Pass translated address down, but keep original address in
+       info->placed_address */
+    {
+        CORE_ADDR saved_addr = info->placed_address;
+	info->placed_address = addr;
+        res = linux_aware_ops.beneath->to_insert_breakpoint (info);
+	info->placed_address = saved_addr;
+    }
+
+    if (info->placed_address != addr) {
+	linux_awareness_ops->lo_flush_cache (addr, addr, 2, 1);
+	thread_awareness_exhibit();
+    }
+
+    inferior_ptid = saved_ptid;
+    return res;
+}
+
+static int
+linux_aware_remove_breakpoint(struct bp_target_info *info)
+{
+    struct bp_location *bp_loc;
+    ptid_t saved_ptid = inferior_ptid;
+    int res;
+    CORE_ADDR addr = info->placed_address;
+    CORE_ADDR requested_addr = addr;
+    bp_loc = bp_location_from_shadow_contents (info);
+
+    DEBUG (TARGET, 2,"removing bp at 0x%x %s\n",
+	   (unsigned int)addr,
+	   bp_loc == NULL ? "(SS)" : "");
+
+    if (addr == ~(CORE_ADDR)0)
+	return 0;
+
+    if (disable_breakpoint_at_pc == addr) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    if (bp_loc != NULL && bp_loc->owner->thread != -1)
+	inferior_ptid = thread_id_to_pid (bp_loc->owner->thread);
+    else if (bp_loc == NULL && requested_addr ==
+    									singlestep_info.placed_address)
+	inferior_ptid = singlestep_ptid;
+
+    if (! translate_memory_address_safe (&addr, 1)) {
+	DEBUG (TARGET, 2,"\tError translating address\n");
+	inferior_ptid = saved_ptid;
+
+	if (bp_loc != NULL
+	    && bp_loc->owner->thread != -1
+	    && linux_awareness_ops->lo_is_user_address (bp_loc->address)) {
+	    warning ("\
+The page containing breakpoint %i seems to have been unmapped from memory\n\
+You'll have to reset the breakpoint.", bp_loc->owner->number);
+	    disable_breakpoint (bp_loc->owner);
+	}
+
+	return 1;
+    }
+
+    if (requested_addr != addr) {
+	thread_awareness_inhibit();
+	linux_awareness_ops->lo_flush_cache (requested_addr, addr, 2, 1);
+	DEBUG (TARGET, 2,"\t real addr 0x%x\n", (unsigned int)addr);
+    }
+
+    /* Pass the translated address down, but keep the original value in
+       info->placed_address. */
+    {
+        CORE_ADDR saved_addr = info->placed_address;
+	info->placed_address = addr;
+        res = linux_aware_ops.beneath->to_remove_breakpoint (info);
+	info->placed_address = saved_addr;
+    }
+
+    if (requested_addr != addr) {
+	linux_awareness_ops->lo_flush_cache (addr, addr, 2, 1);
+	thread_awareness_exhibit();
+    }
+
+    inferior_ptid = saved_ptid;
+    return res;
+}
+
+static int
+linux_aware_insert_hw_breakpoint(struct bp_target_info *info)
+{
+    DEBUG (TARGET, 2,"inserting hw bp at 0x%x\n",
+    								(unsigned int)info->placed_address);
+
+    if (disable_breakpoint_at_pc == info->placed_address) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    return linux_aware_ops.beneath->to_insert_hw_breakpoint (info);
+}
+
+static int
+linux_aware_remove_hw_breakpoint(struct bp_target_info *info)
+{
+    DEBUG (TARGET, 2,"removing hw bp at 0x%x\n",
+    								(unsigned int)info->placed_address);
+
+    if (disable_breakpoint_at_pc == info->placed_address) {
+	DEBUG (TARGET, 2,"\tDisabled due to single-stepping\n");
+	return 0;
+    }
+
+    return linux_aware_ops.beneath->to_remove_hw_breakpoint (info);
+}
+
+static void
+sanitize_target_root_prefix ()
+{
+    char *dir = *target_root_prefix + strlen (*target_root_prefix) - 1;
+    while (dir > *target_root_prefix && isspace (*dir)) {
+	*dir-- = '\0';
+    }
+}
+
+static CORE_ADDR cache_task_struct;
+static int cache_pid;
+static CORE_ADDR cache_start;
+static CORE_ADDR cache_end;
+static unsigned int cache_pgoff;
+static FILE *cached_file;
+
+static int
+read_from_file(CORE_ADDR file, CORE_ADDR start, unsigned int pgoffset,
+	       CORE_ADDR addr, int len, gdb_byte *myaddr, FILE *file_desc)
+{
+    char *filename;
+    unsigned int in_page_offset =  addr & ((1<<linux_awareness_ops->page_shift) - 1);
+    unsigned int page_len = (1<<linux_awareness_ops->page_shift) - in_page_offset;
+
+    pgoffset += (addr - start) >> linux_awareness_ops->page_shift;
+
+    if (file_desc == NULL) {
+	CORE_ADDR dentry = read_pointer_field (file, FILE__F_DENTRY);
+	filename = read_dentry (dentry);
+
+	if (filename == NULL)
+	    return -1;
+
+	filename = xrealloc (filename,
+			     strlen (filename) + strlen (*target_root_prefix) + 1);
+	memmove (filename + strlen (*target_root_prefix),
+		 filename,
+		 strlen (filename)+1);
+	memcpy (filename, *target_root_prefix, strlen(*target_root_prefix));
+
+	DEBUG(VM, 2 , "Trying to read %s from %s\n", paddr (addr), filename);
+
+	file_desc = fopen (filename, "r");
+	xfree (filename);
+
+	if (file_desc == NULL)
+	    return -1;
+    }
+
+    /* Never cross a page boundary.  */
+    len = len > page_len ? page_len : len;
+
+    if (fseek(file_desc, in_page_offset + pgoffset*(1<<linux_awareness_ops->page_shift), SEEK_SET)) {
+	fclose(file_desc);
+	return -1;
+    }
+
+    if ((len = fread(myaddr, len, 1, file_desc)) <= 0) {
+	fclose(file_desc);
+	return -1;
+    }
+
+    if (cached_file != NULL
+	&& cached_file != file_desc) {
+	fclose(cached_file);
+    }
+
+    cached_file = file_desc;
+    return len;
+}
+
+static int
+get_file_mapped_data(CORE_ADDR addr, gdb_byte *myaddr, int len)
+{
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task_struct = ps->task_struct_address;
+    enum page_status stat;
+    CORE_ADDR memaddr = addr;
+
+
+    if (cache_task_struct == task_struct
+	&& cache_pid == ps->pid
+	&& cache_start <= addr
+	&& cache_end > addr) {
+	int res;
+	res = read_from_file(0, cache_start, cache_pgoff, addr, len, myaddr, cached_file);
+	if (res < 0) {
+	    cache_task_struct = 0;
+	    cache_pid = 0;
+	    cache_start = 0;
+	    cache_end = 0;
+	    cached_file = NULL; /* fclosed by read_from_file.  */
+	}
+	return res;
+    }
+
+
+    stat = linux_awareness_ops->lo_translate_memory_address (&memaddr, task_struct);
+
+    sanitize_target_root_prefix();
+    if (**target_root_prefix == '\0')
+	return -1;
+
+    DEBUG(VM, 2 , "Looking if we can read %s from a file\n", paddr (addr));
+
+    if (stat != PAGE_NOPAGE && stat != PAGE_NOTMAPPED)
+	return -1;
+
+    CORE_ADDR mm = read_pointer_field (task_struct, TASK_STRUCT__MM);
+    CORE_ADDR mmap;
+
+    if (!mm)
+	/* Kernel thread maps file?!...  */
+	return -1;
+
+    mmap = read_pointer_field (mm, MM_STRUCT__MMAP);
+    while (mmap) {
+	CORE_ADDR file;
+
+#define VM_READ		0x00000001	/* currently active flags */
+#define VM_WRITE	0x00000002
+#define VM_EXEC		0x00000004
+#define VM_SHARED	0x00000008
+
+#define VM_MAYREAD	0x00000010	/* limits for mprotect() etc */
+#define VM_MAYWRITE	0x00000020
+#define VM_MAYEXEC	0x00000040
+#define VM_MAYSHARE	0x00000080
+
+#define VM_GROWSDOWN	0x00000100	/* general info on the segment */
+#define VM_GROWSUP	0x00000200
+
+	CORE_ADDR start, end;
+
+	start = read_pointer_field (mmap, VM_AREA_STRUCT__VM_START);
+	end = read_pointer_field (mmap, VM_AREA_STRUCT__VM_END);
+
+	if (start > addr
+	    || end <= addr) {
+	    mmap = read_pointer_field (mmap, VM_AREA_STRUCT__VM_NEXT);
+	    continue;
+	}
+
+	file = read_pointer_field (mmap, VM_AREA_STRUCT__VM_FILE);
+
+	if (file) {
+	    int res;
+	    unsigned int pgoff = read_unsigned_field(mmap, VM_AREA_STRUCT__VM_PGOFF);
+	    res = read_from_file(file, start, pgoff, addr, len, myaddr, NULL);
+
+	    if (res > 0) {
+		cache_task_struct = task_struct;
+		cache_pid = ps->pid;
+		cache_start = start;
+		cache_end = end;
+		cache_pgoff = pgoff;
+	    }
+
+	    return res;
+	} else {
+	    return -1;
+	}
+#undef VM_READ
+#undef VM_WRITE
+#undef VM_EXEC
+#undef VM_SHARED
+
+#undef VM_MAYREAD
+#undef VM_MAYWRITE
+#undef VM_MAYEXEC
+#undef VM_MAYSHARE
+
+#undef VM_GROWSDOWN
+#undef VM_GROWSUP
+    }
+
+    return -1;
+}
+
+static int
+linux_aware_deprecated_xfer_memory (CORE_ADDR memaddr,
+				    gdb_byte *myaddr,
+				    int len, int write,
+				    struct mem_attrib *attrib,
+				    struct target_ops *target)
+{
+    int res = 0;
+    CORE_ADDR orig_addr = memaddr;
+
+    DEBUG (TARGET, 3,
+	   "linux_aware_deprecated_xfer_memory: %s %i bytes %s 0x%x\n",
+	   (write ? "writing" : "reading"),
+	   len,
+	   (write ? "to" : "from"),
+	   (unsigned int)memaddr);
+
+    if (loaded)
+	if (! translate_memory_address_safe (&memaddr, 1)) {
+
+	    if (!write) {
+		res = get_file_mapped_data(memaddr, myaddr, len);
+
+		if (res >= 0)
+		    return res;
+	    }
+
+	    /* Emit warnings now. This shouldn't be too wasteful if
+	       the target side does right caching.  */
+	    translate_memory_address_safe (&memaddr, 0);
+
+	    /* Don't report an error, but do what GDB would do on
+	       memory access error : read zero and do nothing on
+	       write. The error has been reported to the user. If we
+	       report an error, then the target beneath will be called
+	       and do uselss things. See target.c:target_xfer_memory */
+	    if (!write)
+		memset (myaddr, 0, len);
+
+	    return len;
+	}
+
+    if (orig_addr != memaddr) {
+	CORE_ADDR page_end;
+	int length, tmp_res;
+	int page_incr = 1<<linux_awareness_ops->page_shift;
+
+	/* Read page by page. Pages may not by contiguous in memory,
+	   thus we need a new memory translation at each page limit. */
+	do {
+	    page_end = (orig_addr & ~(CORE_ADDR)(page_incr-1)) + page_incr;
+	    length = min (len,page_end-orig_addr);
+
+	    if (write || page_writable (orig_addr))
+		linux_awareness_ops->lo_flush_cache (orig_addr, memaddr,
+						     length, write);
+	    DEBUG (TARGET, 3,
+		   "linux_aware_deprecated_xfer_memory: "
+		   "really %s %i bytes %s 0x%x\n",
+		   (write ? "writing" : "reading"),
+		   length,
+		   (write ? "to" : "from"),
+		   (unsigned int)memaddr);
+	    tmp_res = linux_aware_ops.beneath->deprecated_xfer_memory (memaddr,
+								       myaddr,
+								       len,
+								       write,
+								       attrib,
+								       target);
+	    linux_awareness_ops->lo_flush_cache (memaddr, memaddr,
+						 length, write);
+	    if (tmp_res <= 0)
+		return res;
+
+	    myaddr += length;
+	    res += tmp_res;
+
+	    len -= length;
+	    if (!len) break;
+
+	    orig_addr = page_end;
+	    memaddr = orig_addr;
+	    if (! translate_memory_address_safe (&memaddr, 1)) {
+		/* This should make the underlying memory access code
+		   call us again beginning at the faulty
+		   address. Thus, we use the silent mode here and the
+		   next call will emit the warning at the first
+		   invocation of address (a few lines above). */
+		return res;
+	    }
+
+	} while (orig_addr + len > page_end);
+
+    } else {
+	DEBUG (TARGET, 3,
+	       "linux_aware_deprecated_xfer_memory: "
+	       "simply %s %i bytes %s 0x%x\n",
+	       (write ? "writing" : "reading"),
+	       len,
+	       (write ? "to" : "from"),
+	       (unsigned int)memaddr);
+
+	res = linux_aware_ops.beneath->deprecated_xfer_memory (memaddr,
+							       myaddr,
+							       len, write,
+							       attrib, target);
+    }
+
+    return res;
+}
+
+static void
+make_shlib_bps_pending ()
+{
+    struct breakpoint *bp;
+
+    ALL_BREAKPOINTS (bp)
+	if (bp->enable_state == bp_shlib_disabled
+	    || bp->loc->address == ~(CORE_ADDR)0) {
+	    bp->enable_state = bp_enabled;
+	    bp->pending = 1;
+	}
+}
+
+static void
+disable_userspace_breakpoints ()
+{
+    struct breakpoint *bp;
+    int disabled = 0;
+
+    ALL_BREAKPOINTS (bp)
+	if (bp->loc
+	    && bp->enable_state == bp_enabled
+	    && bp->loc->loc_type == bp_loc_software_breakpoint
+	    && linux_awareness_ops->lo_is_user_address (bp->loc->address)) {
+	    bp->enable_state = bp_disabled;
+	    ++disabled;
+	}
+
+    if (disabled)
+	warning("\
+Your target system is getting low on memory. Userspace debugging will\n\
+become unreliable due to code memory getting unmapped. All the userspace\n\
+breakpoints have been disabled.");
+}
+
+static void
+linux_aware_resume (ptid_t pid, int step, enum target_signal sig)
+{
+    DEBUG (TARGET, 1,"Resuming %i with sig %i (step %i)\n",
+	   (int)ptid_get_pid(pid), (int)sig, step);
+
+    if (seen_module_unload) {
+	seen_module_unload = 0;
+	make_shlib_bps_pending();
+    }
+
+    if (!step_bp && saved_singlestep_dest
+	&& !force_hw_singlestep && !singlestep_info.placed_address) {
+	ptid_t saved_ptid = inferior_ptid;
+	/* The debugger thinks it just needs to continue, it has
+	   forgotten about the ongoing step.  Force the singlestep bp
+	   insertion.  */
+
+	struct symtab_and_line sr_sal;
+	inferior_ptid = saved_singlestep_ptid;
+	step_bp = create_thread_event_breakpoint(saved_singlestep_dest);
+	step_bp->thread = pid_to_thread_id(saved_singlestep_ptid);
+	if (!step_bp->loc->duplicate) {
+	    target_insert_breakpoint(&step_bp->loc->target_info);
+	    step_bp->loc->inserted = 1;
+	}
+	inferior_ptid = saved_ptid;
+    }
+
+    if (!force_hw_singlestep || waiting_on_bp) {
+	linux_awareness_ops->lo_clear_cache ();
+	thread_list_clear_cache ();
+    }
+
+    stick_to_kernelspace = 0;
+    last_warned = (CORE_ADDR)-1;
+
+    /* Forget about normal_stop_pc, it should just be used for the
+       initial step from a bp.  */
+    normal_stop_pc = 0;
+    running = 1;
+    if (!force_hw_singlestep || waiting_on_bp) {
+	linux_aware_ops.beneath->to_resume (pid_to_ptid (-1), 0, TARGET_SIGNAL_0);
+    } else {
+	DEBUG (TARGET, 1,"Really singlesteping\n");
+	linux_aware_ops.beneath->to_resume (pid_to_ptid (-1), 1, TARGET_SIGNAL_0);
+    }
+    force_hw_singlestep = 0;
+}
+
+static void
+linux_aware_load (char *prog, int fromtty) {
+
+    DEBUG (TARGET, 3,"linux_aware_load %s\n", prog);
+    /* Force the loaded variable to 0 before load, so that the user
+       can't crash the debugger by putting 'set linux-awareness loaded
+       1' in his .shgdbinit file */
+    loaded = 0;
+    linux_aware_ops.beneath->to_load (prog, fromtty);
+    loaded = 1;
+
+    DEBUG (TARGET, 3,"end linux_aware_load %s\n", prog);
+}
+
+static void
+linux_aware_attach (char *prog, int fromtty) {
+
+    DEBUG (TARGET, 3,"linux_aware_attach %s\n", prog);
+
+    if (linux_aware_ops.beneath
+	&& linux_aware_ops.beneath->to_attach != NULL
+	&& linux_aware_ops.beneath->to_attach != find_default_attach)
+	linux_aware_ops.beneath->to_attach (prog, fromtty);
+
+    loaded = 1;
+    DEBUG (TARGET, 3,"end linux_aware_attach %s\n", prog);
+}
+
+static int
+linux_aware_can_run () {
+
+    DEBUG (TARGET, 3,"linux_aware_can_run\n");
+    return (use_linux_awareness && loaded);
+}
+
+static void
+set_section_offsets (bfd *abfd, asection *sectp, void *dummy)
+{
+    struct lm_info *info = (struct lm_info *) dummy;
+
+    if (info->section_offsets[sectp->index] != -1)
+	DEBUG (MODULE, 2, "Setting vma of %s to %x\n",
+	       bfd_get_section_name (abfd, sectp),
+	       info->section_offsets[sectp->index]);
+
+    if (info->section_offsets[sectp->index] != -1)
+	bfd_set_section_vma (abfd, sectp, info->section_offsets[sectp->index]);
+}
+
+static void
+create_sections (bfd *abfd, asection *sectp, void *i)
+{
+    struct module_bfd_copy_info *info = (struct module_bfd_copy_info *)i;
+    asection *sec;
+
+    flagword flags = bfd_get_section_flags (abfd, sectp);
+
+    if (! (flags & (SEC_ALLOC | SEC_DEBUGGING)))
+	return;
+
+    if (strcmp (bfd_get_section_name (abfd, sectp), ".modinfo") == 0)
+	return;
+
+    DEBUG (MODULE, 3, "Adding section %s to new file.\n",
+	   bfd_get_section_name (abfd, sectp));
+    sec = bfd_make_section (info->new, bfd_get_section_name (abfd, sectp));
+    /* Don't put the SEC_LOAD flags, so that the BFD doesn't try to do
+       a segment layout for this section. */
+    bfd_set_section_flags (info->new, sec, flags & ~(SEC_RELOC|SEC_LOAD));
+    bfd_set_section_vma (info->new, sec, 0);
+    bfd_set_section_alignment (info->new, sec,
+			       bfd_get_section_alignment (abfd, sectp));
+    bfd_set_section_size (info->new, sec, bfd_section_size (abfd, sectp));
+
+    info->sec_mapping[sectp->index] = sec;
+
+    if (flags & SEC_ALLOC) {
+	int len = strlen (bfd_get_section_name (abfd, sectp))+7;
+	char* dummy_name = bfd_alloc (info->new, len);
+
+	if (!dummy_name)
+	    error("dummy_name: %s.",
+		  bfd_errmsg (bfd_get_error ()));
+
+
+	sprintf (dummy_name, "%s.dummy", bfd_get_section_name (abfd, sectp));
+
+	DEBUG (MODULE, 3, "Adding section %s to new file.\n",
+	       bfd_get_section_name (abfd, sectp));
+	sec = bfd_make_section (info->new, dummy_name);
+	bfd_set_section_flags (info->new, sec, SEC_ALLOC);
+	bfd_set_section_vma (info->new, sec, bfd_get_section_vma(abfd, sectp));
+	sec->lma = bfd_get_section_vma (abfd, sectp);
+	bfd_set_section_alignment (info->new, sec,
+				   bfd_get_section_alignment (abfd, sectp));
+	bfd_set_section_size (info->new, sec, bfd_section_size (abfd, sectp));
+    }
+}
+
+static void
+create_symbols (struct module_bfd_copy_info *info)
+{
+    long storage_needed;
+    asymbol **symbol_table;
+    asymbol **new_symbol_table, *new_sym;
+    int cur_new_sym = 0;
+    long number_of_symbols;
+    long i;
+
+    storage_needed = bfd_get_symtab_upper_bound (info->old);
+    if (storage_needed < 0)
+	error ("Error reading old symtab.");
+
+    if (storage_needed == 0)
+	return;
+
+    symbol_table = xmalloc (storage_needed);
+    new_symbol_table = xmalloc (storage_needed);
+    memset (new_symbol_table, 0, storage_needed);
+
+    number_of_symbols = bfd_canonicalize_symtab (info->old, symbol_table);
+    if (number_of_symbols < 0)
+	error ("Error reading old symbols.");
+
+    for (i = 0; i < number_of_symbols; i++) {
+	asymbol* sym = symbol_table[i];
+
+	/* The section symbols will get recreated by the BFD. */
+	if (sym->flags & BSF_SECTION_SYM)
+	    continue;
+
+	      /* Skip names that don't exist (shouldn't happen), or names
+	         that are null strings (may happen). */
+	if (sym->name == NULL || *sym->name == '\0')
+	    continue;
+
+	if (sym->section == &bfd_und_section)
+	    continue;
+
+	if (info->sec_mapping[sym->section->index] == 0) {
+	    DEBUG (MODULE, 4,
+		   "Ignoring symbol %s because of missing section.\n",
+		   bfd_asymbol_name (sym));
+	    continue;
+	}
+
+	new_sym = bfd_make_empty_symbol (info->new);
+	new_symbol_table[cur_new_sym] = new_sym;
+	new_sym->name = bfd_asymbol_name (sym);
+	new_sym->section = info->sec_mapping[sym->section->index];
+	new_sym->flags = sym->flags;
+	new_sym->value = bfd_asymbol_value (sym);
+
+	DEBUG (MODULE, 2, "Adding sym %s to new file with value 0x%s\n",
+	       new_symbol_table[cur_new_sym]->name,
+	       paddr (new_symbol_table[cur_new_sym]->value));
+
+	++cur_new_sym;
+    }
+
+    bfd_set_symtab (info->new, new_symbol_table, cur_new_sym);
+    xfree (symbol_table);
+}
+
+static void
+set_section_contents (bfd *abfd, asection *sectp, void *i)
+{
+    bfd_byte *buf;
+    struct cleanup *clean;
+    struct module_bfd_copy_info *info = (struct module_bfd_copy_info *)i;
+
+    if (info->sec_mapping[sectp->index] == 0)
+	return;
+
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_HAS_CONTENTS ))
+	return;
+
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_RELOC )
+	|| ! (bfd_get_section_flags (abfd, sectp) & SEC_DEBUGGING )) {
+
+	/* We certainly don't need the code sections. (Except
+	   for disassembling while not loaded... but this is only used
+	   when the module is loaded in target memory.) */
+#if 1
+	bfd_byte *buf = xmalloc (bfd_get_section_size (sectp));
+	struct cleanup *clean = make_cleanup (xfree, buf);
+	if (! bfd_get_section_contents (abfd, sectp,
+					buf, 0, bfd_get_section_size (sectp)))
+	    error ("Can't read non-relocated section contents.");
+
+	if (! bfd_set_section_contents (info->new,
+					info->sec_mapping[sectp->index],
+					buf,
+					0,
+					bfd_get_section_size (sectp)))
+	    error ("Can't set section contents: %s.",
+		   bfd_errmsg (bfd_get_error ()));
+
+	do_cleanups (clean);
+#endif
+	return;
+    }
+
+    DEBUG (MODULE, 2, "Relocating %s\n", bfd_get_section_name (abfd, sectp));
+
+    buf = xmalloc (bfd_get_section_size (sectp));
+    clean = make_cleanup (xfree, buf);
+
+    if (bfd_simple_get_relocated_section_contents (abfd, sectp,
+						   buf, NULL) == NULL)
+	error ("Can't relocate section contents.");
+
+    if (! bfd_set_section_contents (info->new,
+				    info->sec_mapping[sectp->index],
+				    buf,
+				    0,
+				    bfd_get_section_size (sectp)))
+	error ("Can't relocate section contents.");
+
+    do_cleanups (clean);
+}
+
+static int
+make_temporary_bfd (bfd *abfd, struct lm_info *lm_info, char **temp_pathname)
+{
+    struct module_bfd_copy_info info;
+    bfd *newbfd;
+    char *tmpname;
+    char *filename;
+    int fd = -1, len;
+
+    xasprintf (&tmpname, "gdb-module-%s-XXXXXX", lm_info->module_name);
+    xasprintf (&filename, "%s/%s", tmpdir, tmpname);
+    len = strlen (filename);
+
+    if (len >=  SO_NAME_MAX_PATH_SIZE)
+	warning ("Can't create temporary file in '%s': "
+		 "dirname too long.", tmpdir);
+    else
+	fd = mkstemp (filename);
+
+    if (fd == -1) {
+	int i;
+	for (i = 0; fd == -1 && i < ARRAY_SIZE (fallback_tmpdirs); ++i) {
+	    xfree (filename);
+	    xasprintf (&filename, "%s/%s", fallback_tmpdirs[i], tmpname);
+	    len = strlen (filename);
+	    if (len >=  SO_NAME_MAX_PATH_SIZE)
+		warning ("Can't create temporary file in '%s': "
+			 "dirname too long.", tmpdir);
+	    else
+		fd = mkstemp (filename);
+	}
+	if (fd == -1) {
+	    xfree (tmpname); xfree (filename);
+	    return fd;
+	}
+    }
+
+    close (fd);
+    *temp_pathname = xstrdup (filename);
+    newbfd = bfd_openw (filename, bfd_get_target (abfd));
+
+    if (! newbfd) {
+	error ("Can't open newbfd.");
+    }
+
+    bfd_set_format (newbfd, bfd_object);
+    bfd_set_arch_mach (newbfd, bfd_get_arch (abfd), bfd_get_mach (abfd));
+
+    /* Make the generated file a shred object, so that GDB doesn't try
+       to randomly layout the relocatable sections. */
+    if (!bfd_set_file_flags (newbfd, bfd_get_file_flags (newbfd) | DYNAMIC))
+	warning ("Could not set temporary file flags to DYNAMIC.");
+
+    info.old = abfd;
+    info.new = newbfd;
+    info.lm_info = lm_info;
+    info.sec_mapping = xmalloc (sizeof(asection *)
+				* bfd_count_sections (info.old));
+    memset(info.sec_mapping, 0,
+	   sizeof(asection *) * bfd_count_sections (info.old));
+
+    bfd_map_over_sections (info.old, set_section_offsets, lm_info);
+    bfd_map_over_sections (info.old, create_sections, &info);
+    create_symbols (&info);
+    bfd_map_over_sections (info.old, set_section_contents, &info);
+    bfd_close (info.new);
+
+    fd = open (filename, O_RDONLY);
+
+    xfree (info.sec_mapping);
+    xfree (tmpname);
+    xfree (filename);
+
+    return fd;
+}
+
+static struct lm_info *
+find_lm_info (const char *name)
+{
+    struct lm_info_list *list = lm_infos;
+
+    while (list != NULL) {
+	if (! strcmp (name, list->info->module_name))
+	    break;
+	list = list->next;
+    }
+
+    return list ? list->info : NULL;;
+}
+
+/* This function implements the walking of the decision tree
+   representing all the possible names for the module names FILENAME. */
+static int
+try_to_open_alternate_names (char *filename, char **temp_pathname)
+{
+    int *tree;
+    int nb_chars, allocated_chars;
+    int level = 0;
+
+    void add_char (int pos) {
+
+	if (nb_chars == allocated_chars) {
+	    allocated_chars *= 2;
+	    tree = xrealloc (tree, sizeof (int)*allocated_chars);
+	}
+
+	tree[nb_chars] = pos;
+	filename[pos] = '\0';
+	++nb_chars;
+    }
+
+    void gather_chars () {
+	char *c = filename;
+
+	while (*c) {
+	    if (*c == '_') add_char (c-filename);
+	    ++c;
+	}
+    }
+
+    allocated_chars = 4;
+    tree = xmalloc (sizeof (int)*4);
+    nb_chars = 0;
+
+    gather_chars ();
+
+    if (! nb_chars) {
+	xfree (tree);
+	return openp (*module_search_path, OPF_TRY_CWD_FIRST,
+		      filename, O_RDONLY, 0, temp_pathname);
+    }
+
+    while (level >= 0) {
+	switch (filename[tree[level]]) {
+	case 0: filename[tree[level]] = '_'; ++level; break;
+	case '_': filename[tree[level]] = '-'; ++level; break;
+	case '-': filename[tree[level]] = ','; ++level; break;
+	case ',': filename[tree[level]] = 0; --level; break;
+	}
+
+	if (level == nb_chars) {
+	    int res = openp (*module_search_path, OPF_TRY_CWD_FIRST,
+			     filename, O_RDONLY, 0, temp_pathname);
+	    if (res >= 0) {
+		xfree (tree);
+		return res;
+	    }
+	    --level;
+	}
+    }
+
+    xfree (tree);
+    return -1;
+}
+
+static int
+linux_aware_find_and_open_solib(char *soname,
+				unsigned o_flags,
+				char **temp_pathname)
+{
+    int found_file = -1;
+    char realfile[SO_NAME_MAX_PATH_SIZE];
+    bfd *abfd;
+    struct lm_info *lm_info;
+    char *c;
+
+    snprintf (realfile, SO_NAME_MAX_PATH_SIZE, "%s.ko", soname);
+
+    while ((c = strchr(realfile, ',')))
+	*c = '_';
+
+    while ((c = strchr(realfile, '-')))
+	*c = '_';
+
+    found_file = try_to_open_alternate_names (realfile, temp_pathname);
+
+    if ( found_file < 0 ) {
+	warning("\
+You just loaded the '%s' module.\n\
+The debugger searched for '%s.ko' in module-search-path,\n\
+but didn't find the module file.\n\
+Current module-search-path is:\n%s\n", soname, soname, *module_search_path);
+	return found_file;
+    }
+
+    abfd = bfd_openr (*temp_pathname, gnutarget);
+    if (!abfd) {
+	close (found_file);
+	error ("Could not open `%s' as an executable file: %s",
+	       *temp_pathname, bfd_errmsg (bfd_get_error ()));
+    }
+
+    if (!bfd_check_format (abfd, bfd_object)) {
+	error ("\"%s\": not in executable format: %s.",
+	       *temp_pathname, bfd_errmsg (bfd_get_error ()));
+    }
+
+    lm_info = find_lm_info (soname);
+    layout_sections (abfd, lm_info);
+
+    printf_filtered("[New module '%s' (%s)]\n", soname, *temp_pathname);
+
+    if (! lm_info->needs_relocated_file ) {
+	bfd_close (abfd);
+	return found_file;
+    }
+
+    lm_info->real_file = xmalloc (strlen (*temp_pathname)+1);
+    strcpy (lm_info->real_file, *temp_pathname);
+    found_file = make_temporary_bfd (abfd, lm_info, temp_pathname);
+
+    if (found_file >= 0) {
+	lm_info->relocated_file = xmalloc (strlen (*temp_pathname)+1);
+	strcpy (lm_info->relocated_file, *temp_pathname);
+	xfree (*temp_pathname);
+	*temp_pathname = lm_info->relocated_file;
+    }
+
+    bfd_close (abfd);
+    return found_file;
+}
+
+static void
+linux_aware_relocate_section_addresses (struct so_list *so,
+					struct section_table *sec)
+{
+    unsigned int offset;
+    DEBUG (MODULE, 3,
+	   "linux_aware_relocate_section_addresses (%s:%s) <= %s->%s\n",
+	   so->so_name, sec->the_bfd_section->name,
+	   paddr (sec->addr), paddr (sec->endaddr));
+
+    /* This one is in GDB's list */
+    so->lm_info->mod = so;
+
+    if (so->lm_info->needs_relocated_file)
+	/* No relocation at the section level */
+	return;
+
+    /* Put the symbols from the .modinfo section at the end of the
+       memory so that they don't interfer with real symbols.
+       We can't simply let the offset be 0: the issue is that
+       symfile.c:syms_from_objfile re-initializes the 0 offsets to the
+       lower initialized offset. Thus we get offset(.modinfo) ==
+       offset(.text) and a lot of issues stem from that. */
+    if (!strcmp (".modinfo", sec->the_bfd_section->name))
+	offset = ~0UL - sec->the_bfd_section->size;
+    else
+	offset = so->lm_info->section_offsets[sec->the_bfd_section->index];
+
+    sec->addr += offset;
+    sec->endaddr += offset;
+    DEBUG (MODULE, 4,
+	   "linux_aware_relocate_section_addresses (%s:%s) => %s->%s\n",
+	   so->so_name, sec->the_bfd_section->name,
+	   paddr ( sec->addr), paddr (sec->endaddr));
+}
+
+static void
+linux_aware_free_lm_info (struct lm_info *info)
+{
+    xfree (info->section_offsets);
+    if (info->relocated_file != NULL)
+	unlink (info->relocated_file);
+    xfree (info->relocated_file);
+    xfree (info->real_file);
+
+    if (info->mod)
+	info->mod->lm_info = NULL;
+
+    xfree (info);
+}
+
+static void
+delete_temp_files ()
+{
+    struct lm_info_list *list = lm_infos, *next;
+
+    while (list != NULL) {
+	next = list->next;
+	linux_aware_free_lm_info (list->info);
+	xfree (list);
+	list = next;
+    }
+
+    lm_infos = NULL;
+}
+
+static void
+linux_aware_remove_lm_info_from_list_by_addr (CORE_ADDR this_module, int notif)
+{
+    struct lm_info_list *list = lm_infos, *prev = NULL;
+
+    while (list) {
+	if (list->info->this_module == this_module)
+	    break;
+
+	prev = list;
+	list = list->next;
+    }
+
+    if (list == NULL)
+	return;
+
+    DEBUG (MODULE, 4,
+	   "Really deleting module '%s'.\n", list->info->module_name);
+    if (notif)
+	printf_filtered("[Unloading module '%s']\n", list->info->module_name);
+
+    if (prev != NULL)
+	prev->next = list->next;
+    else
+	lm_infos = list->next;
+
+    if (last_loaded == list->info)
+	last_loaded = NULL;
+
+    linux_aware_free_lm_info (list->info);
+    xfree (list);
+}
+
+
+static int
+linux_aware_lm_info_exists (struct lm_info *info)
+{
+    struct lm_info_list *list = lm_infos;
+
+    while (list) {
+	if (info == list->info)
+	    break;
+
+	list = list->next;
+    }
+
+    return list != NULL;
+}
+
+
+static void
+linux_aware_free_so (struct so_list *so)
+{
+    DEBUG (MODULE, 3, "linux_aware_free_so(%s)\n", so->so_name);
+
+    if (so->lm_info
+	&& linux_aware_lm_info_exists (so->lm_info)
+	&& so->lm_info->mod == so)
+	linux_aware_remove_lm_info_from_list_by_addr (so->lm_info->this_module,
+						      0);
+}
+
+static void
+linux_aware_clear_solib (void)
+{
+    DEBUG (MODULE, 3, "linux_aware_clear_solib\n");
+    delete_temp_files ();
+}
+
+static void
+linux_aware_solib_create_inferior_hook (void)
+{
+    CORE_ADDR addr;
+    DEBUG (MODULE, 3, "linux_aware_solib_create_inferior_hook\n");
+
+    if (HAS_ADDR (MODULE_PARAM_SYSFS_SETUP) && shlib_event_load_bp == NULL) {
+	addr = ADDR (MODULE_PARAM_SYSFS_SETUP);
+	shlib_event_load_bp = create_solib_event_breakpoint (addr);
+    }
+
+    if (HAS_ADDR (MODULE_ARCH_CLEANUP) && shlib_event_free_bp == NULL) {
+	addr = ADDR (MODULE_ARCH_CLEANUP);
+	shlib_event_free_bp = create_solib_event_breakpoint (addr);
+    }
+}
+
+static void
+linux_aware_special_symbol_handling (void)
+{
+    struct lm_info_list *list = lm_infos;
+    struct obj_section *sect;
+    DEBUG (MODULE, 3, "linux_aware_special_symbol_handling\n");
+
+    while (list != NULL) {
+	struct lm_info *info = list->info;
+
+	if (! info->so_list_updated) {
+	    if (info->needs_relocated_file) {
+		strcpy (info->mod->so_name, info->real_file);
+		/* The section following .text should be .text.dummy which
+		   has the good offsets */
+		++info->mod->textsection;
+
+		if (info->computed_init_size
+		    && !info->init_size) {
+		    DEBUG (MODULE, 2, "Relocating symbols for %s\n",
+			   info->module_name);
+		    linux_aware_objfile_relocate (info->mod->objfile,
+						  0,
+						  info->computed_init_size,
+						  info->module_core,
+						  info->module_core
+						  + info->core_size);
+		}
+
+		info->so_list_updated = 1;
+	    }
+	}
+	list = list->next;
+    }
+}
+
+static void
+add_module_from_struct_module (unsigned long addr,
+			       struct lm_info_list **list)
+{
+    char original_name[SO_NAME_MAX_PATH_SIZE];
+    struct lm_info *info;
+    struct lm_info_list *elt;
+
+    read_memory_string (addr+FIELD_OFFSET (MODULE__NAME),
+			original_name,
+			SO_NAME_MAX_PATH_SIZE);
+
+    DEBUG (MODULE, 3, "Adding module '%s' ?\n", original_name);
+
+    info = find_lm_info (original_name);
+
+    if (info == NULL) {
+	DEBUG (MODULE, 3, "Allocation new lm_info for '%s'\n", original_name);
+    	info = XZALLOC (struct lm_info);
+
+	strcpy (info->module_name, original_name);
+	info->this_module = addr;
+	info->init = read_unsigned_field(addr, MODULE__INIT);
+	info->module_init = read_unsigned_field(addr, MODULE__MODULE_INIT);
+	info->module_core = read_unsigned_field(addr, MODULE__MODULE_CORE);
+	info->init_size = read_unsigned_field(addr, MODULE__INIT_SIZE);
+	info->core_size = read_unsigned_field(addr, MODULE__CORE_SIZE);
+    }
+
+    elt = xmalloc (sizeof (struct lm_info_list));
+    elt->info = info;
+    elt->next = *list;
+    *list = elt;
+}
+
+static void
+remove_module_from_struct_module (unsigned long addr)
+{
+    char name[SO_NAME_MAX_PATH_SIZE];
+    DEBUG (MODULE, 3, "Trying to remove module at %lx\n", addr);
+
+    linux_aware_remove_lm_info_from_list_by_addr (addr, 1);
+    DEBUG (MODULE, 3, "Removing done...\n");
+}
+
+static void
+linux_read_module_list ()
+{
+    CORE_ADDR next;
+    struct lm_info_list *new_list = NULL;
+
+    if (! HAS_ADDR (MODULES))
+	return;
+
+    for (next = read_memory_typed_address (ADDR (MODULES),
+					   builtin_type_void_data_ptr);
+	 next != ADDR (MODULES);
+	 next = read_memory_typed_address (next, builtin_type_void_data_ptr)) {
+	CORE_ADDR addr = next;
+	if (!translate_memory_address_safe (&addr, 1))
+	    error ("\
+The debugger can't read the module list. The linux awareness\n\
+layer's view of the kernel is seriously compromised.");
+
+	add_module_from_struct_module (next - FIELD_OFFSET (MODULE__LIST),
+				       &new_list);
+    }
+    /* lm_infos will be discarded anyway. Just free the list
+       containers, and not the lm_infos which have been be reused. */
+    while (lm_infos) {
+	struct lm_info_list *next = lm_infos->next;
+	xfree (lm_infos);
+	lm_infos = next;
+    }
+
+    lm_infos = new_list;
+}
+
+static struct so_list *
+so_list_from_lm_infos ()
+{
+    struct so_list *res = NULL, *cur;
+    struct lm_info_list *list = lm_infos;
+
+    while (list != NULL) {
+	cur = XZALLOC (struct so_list);
+	cur->next = res;
+	res = cur;
+
+	cur->lm_info = list->info;
+	strcpy (cur->so_original_name, list->info->module_name);
+	strcpy (cur->so_name, list->info->module_name);
+
+	list = list->next;
+    }
+
+    return res;
+}
+
+/* Copied from buildsym.c:compare_line_numbers */
+static int
+compare_line_numbers (const void *ln1p, const void *ln2p)
+{
+  struct linetable_entry *ln1 = (struct linetable_entry *) ln1p;
+  struct linetable_entry *ln2 = (struct linetable_entry *) ln2p;
+
+  /* Note: this code does not assume that CORE_ADDRs can fit in ints.
+     Please keep it that way.  */
+  if (ln1->pc < ln2->pc)
+    return -1;
+
+  if (ln1->pc > ln2->pc)
+    return 1;
+
+  /* If pc equal, sort by line.  I'm not sure whether this is optimum
+     behavior (see comment at struct linetable in symtab.h).  */
+  return ln1->line - ln2->line;
+}
+
+static int
+compare_blocks (const void *ln1p, const void *ln2p)
+{
+  struct block **b1 = (struct block **)ln1p;
+  struct block **b2 = (struct block **)ln2p;
+
+  if (BLOCK_START (*b1) < BLOCK_START (*b2))
+    return -1;
+
+  if (BLOCK_START (*b1) > BLOCK_START (*b2))
+    return 1;
+
+  return 0;
+}
+
+/* Copy pasted from objfiles.c:objfile_relocate() */
+static void
+linux_aware_objfile_relocate (struct objfile *objfile,
+			      CORE_ADDR init_start,
+			      CORE_ADDR init_end,
+			      CORE_ADDR core_start,
+			      CORE_ADDR core_end)
+{
+  int i;
+  struct symtab *s;
+  struct partial_symbol **psym;
+  struct partial_symtab *pst;
+  struct minimal_symbol *msym;
+  struct obj_section *sec;
+  bfd *abfd;
+
+  /* OK, get all the symtabs.  */
+  ALL_OBJFILE_SYMTABS (objfile, s) {
+      struct linetable *l;
+      struct blockvector *bv;
+      int i;
+
+      /* First the line table.  */
+      l = LINETABLE (s);
+      if (l) {
+	  for (i = 0; i < l->nitems; ++i)
+	      if (init_start <= l->item[i].pc
+		  && init_end > l->item[i].pc)
+		  l->item[i].pc = ~(CORE_ADDR)0;
+
+	  qsort (l->item,
+		 l->nitems,
+		 sizeof (struct linetable_entry), compare_line_numbers);
+      }
+
+      /* Don't relocate a shared blockvector more than once.  */
+      if (!s->primary)
+	  continue;
+
+      bv = BLOCKVECTOR (s);
+      for (i = 0; i < BLOCKVECTOR_NBLOCKS (bv); ++i) {
+	  struct block *b;
+	  struct symbol *sym;
+	  struct dict_iterator iter;
+
+	  b = BLOCKVECTOR_BLOCK (bv, i);
+
+	  ALL_BLOCK_SYMBOLS (b, iter, sym) {
+	      fixup_symbol_section (sym, objfile);
+
+	      if (SYMBOL_BFD_SECTION (sym)
+		  && !strncmp (".init.", SYMBOL_BFD_SECTION (sym)->name, 6)
+		  && (SYMBOL_CLASS (sym) == LOC_LABEL
+		      || SYMBOL_CLASS (sym) == LOC_STATIC
+		      || SYMBOL_CLASS (sym) == LOC_INDIRECT)
+		  && SYMBOL_SECTION (sym) >= 0) {
+		  SYMBOL_VALUE_ADDRESS (sym) = ~(CORE_ADDR)0;
+	      }
+	  }
+
+	  if (init_start <= BLOCK_START (b)
+	      && init_end >= BLOCK_END (b)) {
+	      BLOCK_START (b) = ~(CORE_ADDR)0;
+	      BLOCK_END (b) = ~(CORE_ADDR)0;
+	  } else {
+	      if (init_start <= BLOCK_START (b)
+		  && init_end > BLOCK_START (b)) {
+		  BLOCK_START (b) = core_start;
+	      }
+	      if (init_start <= BLOCK_END (b)
+		  && init_end >= BLOCK_END (b)) {
+		  BLOCK_END(b) = core_end;
+	      }
+	  }
+      }
+
+      qsort (bv->block+2,
+	     bv->nblocks-2,
+	     sizeof (struct block *), compare_blocks);
+  }
+
+  /* Now the psymtabs */
+  for (psym = objfile->global_psymbols.list;
+       psym < objfile->global_psymbols.next;
+       psym++) {
+      fixup_psymbol_section (*psym, objfile);
+      if (SYMBOL_BFD_SECTION (*psym)
+	  && !strncmp (".init.", SYMBOL_BFD_SECTION (*psym)->name, 6))
+	  SYMBOL_VALUE_ADDRESS (*psym) = ~(CORE_ADDR)0;
+  }
+  for (psym = objfile->static_psymbols.list;
+       psym < objfile->static_psymbols.next;
+       psym++) {
+      fixup_psymbol_section (*psym, objfile);
+      if (SYMBOL_BFD_SECTION (*psym)
+	  && !strncmp(".init.", SYMBOL_BFD_SECTION (*psym)->name, 6))
+	  SYMBOL_VALUE_ADDRESS (*psym) = ~(CORE_ADDR)0;
+  }
+
+  ALL_OBJFILE_PSYMTABS (objfile, pst) {
+      if (init_start <= pst->textlow
+	  && init_end >= pst->texthigh) {
+	  pst->textlow = ~(CORE_ADDR)0;
+	  pst->texthigh = ~(CORE_ADDR)0;
+      } else {
+	  if (init_start <= pst->textlow
+	      && init_end > pst->textlow) {
+	      pst->textlow = core_start;
+	  }
+	  if (init_start <= pst->texthigh
+	      && init_end >= pst->texthigh) {
+	      pst->texthigh = core_end;
+	  }
+      }
+  }
+
+  /* And finally the minimal symbols. */
+  ALL_OBJFILE_MSYMBOLS (objfile, msym)
+      if (SYMBOL_BFD_SECTION (msym)
+	  && !strncmp (".init.", SYMBOL_BFD_SECTION (msym)->name, 6))
+	  SYMBOL_VALUE_ADDRESS (msym) = ~(CORE_ADDR)0;
+
+  /* Relocating different sections by different amounts may cause the symbols
+     to be out of order.  */
+  msymbols_sort (objfile);
+
+
+  /* As a final point, eradicate the section */
+  abfd = objfile->obfd;
+
+  ALL_OBJFILE_OSECTIONS (objfile, sec) {
+      if (!strncmp (sec->the_bfd_section->name, ".init.", 6)) {
+	  sec->addr = ~(CORE_ADDR)0;
+	  sec->endaddr = ~(CORE_ADDR)0;
+      }
+  }
+
+  /* Relocate breakpoints as necessary, after things are relocated. */
+  resetting_bps_after_init = 1;
+  breakpoint_re_set ();
+  resetting_bps_after_init = 0;
+}
+
+/* This comment holds for all the solib code in here: _Things should be
+   simpler_, but some details prevent us from making it simpler. For
+   example, the module init code is called before the module insertion
+   in the global list. Thus we can't just reread the list, we have to
+   explicitely detect the load_modul end, and maintain our own
+   list. Without that, no break in init code... */
+static struct so_list *
+linux_aware_current_sos (void)
+{
+    CORE_ADDR current_pc;
+
+    DEBUG (MODULE, 3, "linux_aware_current_sos => pc=0x%s\n",
+	   paddr (target_has_registers ? read_pc() : 0));
+
+    if (! target_has_registers)
+	return NULL;
+
+    current_pc = read_pc ();
+
+    if (!init_module_return_resolved
+	&& shlib_event_init_bp
+	&& current_pc == shlib_event_init_bp->loc->address) {
+	delete_breakpoint (shlib_event_init_bp);
+	thread_awareness_inhibit();
+	shlib_event_init_bp
+	    = create_solib_event_breakpoint (linux_awareness_ops->lo_return_address_at_start_of_function());
+	thread_awareness_exhibit();
+	init_module_return_resolved = 1;
+	return so_list_from_lm_infos ();
+    }
+
+    if (shlib_event_load_bp != NULL
+	&& current_pc == shlib_event_load_bp->loc->address)
+	{
+	    /* We've just loaded a new module to memory. */
+	    CORE_ADDR ptr = linux_awareness_ops->lo_first_pointer_arg_value ();
+
+	    DEBUG (MODULE, 3,
+		   "Setting up params for module %x\n", (unsigned int)ptr);
+
+	    add_module_from_struct_module (ptr, &lm_infos);
+	    last_loaded = lm_infos->info;
+
+	    if (lm_infos
+		&& lm_infos->info->this_module == ptr
+		&& lm_infos->info->module_init
+		&& lm_infos->info->init
+		&& !init_module_return_resolved) {
+		shlib_event_init_bp
+		    = create_solib_event_breakpoint (lm_infos->info->init);
+		DEBUG (MODULE, 3, "Created shlib_event_init_bp : %s %i\n",
+		       paddr (lm_infos->info->init),
+		       shlib_event_init_bp->loc->inserted);
+	    }
+
+	    return so_list_from_lm_infos ();
+	}
+
+    if (shlib_event_init_bp
+	&& current_pc == shlib_event_init_bp->loc->address) {
+
+	if (last_loaded != NULL
+	    && last_loaded->mod
+	    && last_loaded->module_init) {
+
+	    /* We previously used the beginning of the lm_info list as
+	       the last loaded modules, but this breaks if the user
+	       does 'info sharedlibrary' while in the init function:
+	       the list gets re-read in a different order. */
+
+	    struct lm_info *info = last_loaded;
+	    struct objfile *objfile;
+	    struct partial_symtab *psymtab;
+	    int i;
+	    objfile = info->mod->objfile;
+
+	    DEBUG (MODULE, 3, "End of init for %s\n", objfile->name);
+	    for (psymtab = objfile->psymtabs;
+		 psymtab != NULL;
+		 psymtab = psymtab->next)
+		{
+		    psymtab_to_symtab (psymtab);
+		}
+
+	    linux_aware_objfile_relocate (info->mod->objfile,
+					  info->module_init,
+					  info->module_init+info->init_size,
+					  info->module_core,
+					  info->module_core+info->core_size);
+	}
+	last_loaded = NULL;
+	return so_list_from_lm_infos ();
+    }
+
+    if (shlib_event_free_bp != NULL
+	&& current_pc == shlib_event_free_bp->loc->address)	    {
+	CORE_ADDR ptr = linux_awareness_ops->lo_first_pointer_arg_value ();
+	remove_module_from_struct_module (ptr);
+	seen_module_unload = 1;
+	return so_list_from_lm_infos ();
+    }
+
+    DEBUG (MODULE, 1, "Reading module list\n");
+    linux_read_module_list ();
+    return so_list_from_lm_infos ();
+}
+
+static int
+linux_aware_open_symbol_file_object (void *from_ttyp)
+{
+    DEBUG (MODULE, 3, "linux_aware_open_symbol_file_object\n");
+    return 0;
+}
+
+static int
+linux_aware_in_dynsym_resolve_code (CORE_ADDR pc)
+{
+    DEBUG (MODULE, 3, "linux_aware_in_dynsym_resolve_code\n");
+    return 0;
+}
+
+static void
+init_so_ops ()
+{
+    DEBUG (MODULE, 3, "init_so_ops\n");
+    linux_aware_so_ops.relocate_section_addresses = linux_aware_relocate_section_addresses;
+    linux_aware_so_ops.free_so = linux_aware_free_so;
+    linux_aware_so_ops.clear_solib = linux_aware_clear_solib;
+    linux_aware_so_ops.solib_create_inferior_hook = linux_aware_solib_create_inferior_hook;
+    linux_aware_so_ops.special_symbol_handling = linux_aware_special_symbol_handling;
+    linux_aware_so_ops.current_sos = linux_aware_current_sos;
+    linux_aware_so_ops.open_symbol_file_object = linux_aware_open_symbol_file_object;
+    linux_aware_so_ops.in_dynsym_resolve_code = linux_aware_in_dynsym_resolve_code;
+    linux_aware_so_ops.find_and_open_solib = linux_aware_find_and_open_solib;
+}
+
+
+/******************************************************************************/
+/*****************                 THREADS                   ******************/
+/******************************************************************************/
+
+static struct process *
+get_task_info (CORE_ADDR task_struct)
+{
+    struct process *ps = XZALLOC (struct process);
+    struct cleanup *cleaner = make_cleanup (xfree, ps);
+    DEBUG (TASK,3, "get_task_info(%s)\n", paddr (task_struct));
+    ps->mm = read_unsigned_field (task_struct, TASK_STRUCT__MM);
+    ps->task_struct_address = task_struct;
+    ps->pid = read_unsigned_field (task_struct, TASK_STRUCT__PID);
+    ps->tgid = read_unsigned_field (task_struct, TASK_STRUCT__TGID);
+    ps->comm = xmalloc (FIELD_SIZE (TASK_STRUCT__COMM)+3);
+    read_memory_string (task_struct+FIELD_OFFSET (TASK_STRUCT__COMM), ps->comm,
+			FIELD_SIZE (TASK_STRUCT__COMM));
+
+    if (!ps->mm) {
+	char* comm = xstrdup (ps->comm);
+	snprintf (ps->comm, FIELD_SIZE (TASK_STRUCT__COMM)+3, "[%s]", comm);
+	xfree (comm);
+    }
+
+    discard_cleanups (cleaner);
+    return ps;
+}
+
+static struct process *
+get_current_process ()
+{
+    if (!current_process) {
+	CORE_ADDR task_struct;
+	thread_awareness_inhibit();
+	task_struct = linux_awareness_ops->lo_current_task_struct_address();
+	thread_awareness_exhibit();
+	current_process = get_task_info(task_struct);
+    }
+
+    return current_process;
+}
+
+static struct process *
+get_gdb_process ()
+{
+    struct process *ps = get_current_process ();
+    DEBUG (TASK,3, "get_gdb_process : ps->pid %i, inferior pid : %i\n",
+	   ps->pid, PIDGET (inferior_ptid));
+    if (ps->pid != PIDGET (inferior_ptid)) {
+	struct process *gdb_ps;
+	gdb_ps = thread_list_contains_pid (PIDGET (inferior_ptid));
+	if (gdb_ps) {
+	    ps = gdb_ps;
+	    switch_to_user_process (ps);
+	}
+    }
+
+    return ps;
+}
+
+static void
+thread_list_clear_cache ()
+{
+    struct process *ps;
+
+    while (processes) {
+	ps = processes;
+	processes = ps->next;
+	xfree (ps->comm);
+	xfree (ps);
+    }
+
+    if (current_process != NULL) {
+	xfree (current_process->comm);
+	xfree (current_process);
+	current_process = NULL;
+    }
+}
+
+static struct process **
+get_thread_list_helper(CORE_ADDR task_struct, struct process **ps)
+{
+    CORE_ADDR children, child;
+    CORE_ADDR current_struct_task = task_struct;
+
+    *ps = get_task_info (current_struct_task);
+    ps = & (*ps)->next;
+
+    children = task_struct +  FIELD_OFFSET (TASK_STRUCT__CHILDREN);
+    child = read_unsigned_embedded_field (current_struct_task,
+					  LIST_HEAD__NEXT,
+					  TASK_STRUCT__CHILDREN);
+    while (child != children) {
+	/* The children list_head is chained in the sibling list of the
+	   children.  */
+	current_struct_task = child - FIELD_OFFSET (TASK_STRUCT__SIBLING);
+	ps = get_thread_list_helper(current_struct_task, ps);
+
+	if (linux_awareness_ops->lo_address_needs_translation (current_struct_task))
+	    error("\
+A task struct address can't live in virtual memory. The linux awareness\n\
+layer's view of the kernel is seriously compromised.");
+
+	child = read_unsigned_embedded_field (current_struct_task,
+					      LIST_HEAD__NEXT,
+					      TASK_STRUCT__SIBLING);
+    }
+
+    return ps;
+}
+
+static struct process *
+get_thread_list ()
+{
+    struct process **ps = &processes;
+    struct debugged_user_process *ups = user_processes;
+    CORE_ADDR current_struct_task = ADDR (INIT_TASK);
+
+    if (processes != NULL)
+	return processes;
+
+    get_thread_list_helper(current_struct_task, ps);
+
+    if (processes && processes->next == NULL) {
+	/* Only one task, the kernel hasn't started. */
+	xfree (processes->comm);
+	xfree (processes);
+	processes = NULL;
+    }
+
+    while (ups) {
+	struct debugged_user_process *cur = ups;
+	ups = ups->next;
+
+	if (! thread_list_contains_pid (cur->pid)) {
+	    DEBUG (USER, 2,
+		   "Deleting information for vanished process with "
+		   "pid %i\n", cur->pid);
+	    delete_user_process (cur->gdb_thread_id);
+	}
+    }
+
+    return processes;
+}
+
+static struct process *
+thread_list_contains_pid (unsigned int pid)
+{
+    struct process *ps = get_current_process ();
+
+    DEBUG (TASK, 3, "thread_list_contains_pid(%i)\n", pid);
+
+    if (pid == ps->pid)
+	return ps;
+
+    ps = get_thread_list ();
+
+    while (ps != NULL) {
+	if (ps->pid == pid)
+	    return ps;
+	ps = ps->next;
+    }
+
+    return NULL;
+}
+
+static int
+linux_aware_thread_alive (ptid_t ptid)
+{
+    if (! thread_awareness_inhibited ())
+	return ptid_equal (ptid, current_ptid)
+	    || thread_list_contains_pid (PIDGET (ptid)) != NULL;
+    else
+	return linux_aware_ops.beneath->to_thread_alive (ptid);
+}
+
+static void linux_aware_find_new_threads (void)
+{
+    if (! thread_awareness_inhibited () && loaded) {
+	struct process *ps = get_thread_list ();
+
+	while (ps != NULL) {
+	    if (!in_thread_list (linux_aware_pid_to_ptid (ps->pid))) {
+		add_thread (linux_aware_pid_to_ptid (ps->pid));
+	    }
+	    ps = ps->next;
+	}
+    } else
+	linux_aware_ops.beneath->to_find_new_threads ();
+
+}
+
+static char *
+linux_aware_pid_to_str (ptid_t ptid)
+{
+    if (! thread_awareness_inhibited ()) {
+	struct process *ps = thread_list_contains_pid (PIDGET (ptid));
+	if (!ps)
+	    return "";
+	return ps->comm;
+    } else
+	return linux_aware_ops.beneath->to_pid_to_str (ptid);
+}
+
+static char *
+linux_aware_extra_thread_info (struct thread_info *thread)
+{
+    if (! thread_awareness_inhibited ()) {
+	static char info[64];
+	struct process *ps = thread_list_contains_pid (PIDGET (thread->ptid));
+
+	if (!ps)
+	    return "";
+
+	snprintf (info, 64, "pid: %i tgid: %i", ps->pid, ps->tgid);
+	return info;
+    } else
+	return linux_aware_ops.beneath->to_extra_thread_info (thread);
+}
+
+static CORE_ADDR
+get_current_task_struct ()
+{
+    CORE_ADDR res;
+
+    if (!thread_awareness_inhibited () && loaded) {
+	struct process *ps = get_gdb_process ();
+	return ps->task_struct_address;
+    }
+
+    thread_awareness_inhibit ();
+    res = linux_awareness_ops->lo_current_task_struct_address ();
+    thread_awareness_exhibit ();
+
+    return res;
+}
+
+static void
+linux_aware_fetch_registers (int regno)
+{
+    DEBUG (TARGET, 3, "fetch_registers %i\n", regno);
+
+    if (!thread_awareness_inhibited () && loaded) {
+	if (! ptid_equal (current_ptid, inferior_ptid)
+	    && thread_list_contains_pid (PIDGET (inferior_ptid))) {
+	    CORE_ADDR task_struct = get_current_task_struct ();
+	    thread_awareness_inhibit ();
+	    if (!linux_awareness_ops->lo_fetch_context_register (regno,
+								 task_struct)) {
+		thread_awareness_exhibit ();
+		error ("Could not fetch task register.");
+	    }
+	    thread_awareness_exhibit ();
+	    return;
+	}
+
+	/* This will switch to the right process when we switch back
+	   to the currently running task. */
+	switch_to_user_process (get_gdb_process ());
+    }
+
+    if (linux_aware_ops.beneath == NULL
+	|| linux_aware_ops.beneath->to_fetch_registers == NULL)
+	error ("No registers.");
+    linux_aware_ops.beneath->to_fetch_registers (regno);
+}
+
+static void
+linux_aware_store_registers (int regno)
+{
+    DEBUG (TARGET, 3,"store_registers %i\n", regno);
+
+    if (!thread_awareness_inhibited () && loaded) {
+	if (! ptid_equal (current_ptid, inferior_ptid)
+	    && thread_list_contains_pid (PIDGET (inferior_ptid))) {
+	    CORE_ADDR task_struct = get_current_task_struct ();
+	    thread_awareness_inhibit ();
+	    if (!linux_awareness_ops->lo_store_context_register (regno,
+								 task_struct)) {
+		thread_awareness_exhibit ();
+		error("Could not fetch task register.");
+	    }
+	    thread_awareness_exhibit ();
+	    return;
+	}
+    }
+
+    linux_aware_ops.beneath->to_store_registers (regno);
+}
+
+static void
+normal_stop_callback (struct bpstats *bs)
+{
+    saved_singlestep_dest = 0;
+    singlestep_info.placed_address = 0;
+    waiting_on_bp = 0;
+    force_hw_singlestep = 0;
+    normal_stop_pc = read_pc ();
+    normal_stop_sp = read_sp ();
+
+    if (loaded) {
+	normal_stop_preempt_count = read_signed_field(linux_awareness_ops->lo_current_thread_info_address(),
+						      THREAD_INFO__PREEMPT_COUNT);
+    }
+
+    if (step_bp) {
+	delete_breakpoint(step_bp);
+	step_bp = NULL;
+    }
+
+    if (thread_event_do_exit_bp != NULL || thread_event_low_mem_bp != NULL) {
+	int has_bp = 0;
+	struct breakpoint *bp;
+
+	ALL_BREAKPOINTS (bp) {
+	    if (bp->loc->address
+		&& linux_awareness_ops->lo_is_user_address (bp->loc->address)) {
+		has_bp = 1;
+		break;
+	    }
+	}
+
+	if (!has_bp) {
+	    if (thread_event_do_exit_bp != NULL) {
+		delete_breakpoint(thread_event_do_exit_bp);
+		thread_event_do_exit_bp = NULL;
+	    }
+	    if (thread_event_low_mem_bp != NULL) {
+		delete_breakpoint(thread_event_low_mem_bp);
+		thread_event_low_mem_bp = NULL;
+	    }
+	}
+    }
+}
+
+static ptid_t
+linux_aware_wait (ptid_t ptid, struct target_waitstatus *status)
+{
+	CORE_ADDR singlestep_dest = singlestep_info.placed_address;
+    static int stopped_at_wrong_preempt_count = 0;
+    ptid_t res = linux_aware_pid_to_ptid (0);
+
+    if (!loaded || thread_awareness_inhibited ()) {
+	res = linux_aware_ops.beneath->to_wait (ptid, status);
+	running = 0;
+	return res;
+    }
+
+    thread_awareness_inhibit ();
+    DEBUG (TARGET, 2,"linux_aware_wait \n");
+    res = linux_aware_ops.beneath->to_wait (ptid, status);
+    running = 0;
+
+    if (loaded) {
+	CORE_ADDR pc = read_pc ();
+	CORE_ADDR task_struct = linux_awareness_ops->lo_current_task_struct_address ();
+	unsigned int pid = read_unsigned_field (task_struct, TASK_STRUCT__PID);
+	ptid_t ptid = linux_aware_pid_to_ptid (pid);
+
+	DEBUG (TASK, 3,"linux_aware_wait : getting current process\n");
+	if ((shlib_event_load_bp && pc == shlib_event_load_bp->loc->address)
+	    || (shlib_event_init_bp && pc == shlib_event_init_bp->loc->address)
+	    || (shlib_event_free_bp && pc == shlib_event_free_bp->loc->address)
+	    || (thread_event_do_exit_bp && pc == thread_event_do_exit_bp->loc->address)
+	    || (thread_event_low_mem_bp && pc == thread_event_low_mem_bp->loc->address)
+	    || (thread_event_do_exec_bp && pc == thread_event_do_exec_bp->loc->address)) {
+	    switch_to_user_process (NULL);
+	    stick_to_kernelspace = 1;
+	}
+
+	DEBUG (TASK, 3,"linux_aware_wait : pid => %i\n", pid);
+	current_ptid = res = ptid;
+	DEBUG (TASK, 3,"linux_aware_wait : ptid => %i\n", PIDGET (res));
+
+	if (!in_thread_list (res)) {
+	    add_thread (res);
+	}
+
+	if (!current_user_process
+	    || current_user_process->pid != pid) {
+	    switch_to_user_process (get_current_process ());
+	}
+
+	if (!current_user_process
+	    && linux_awareness_ops->lo_is_user_address (pc)) {
+	    ptid_t saved_ptid = inferior_ptid;
+	    inferior_ptid = current_ptid;
+	    linux_read_process_symbols ();
+	    inferior_ptid = saved_ptid;
+	}
+
+	if (thread_event_do_exit_bp != NULL
+	    && pc == ADDR (DO_EXIT)) {
+	    int thread_id = pid_to_thread_id (current_ptid);
+	    DEBUG (USER, 2, "Process has ended (pid %i)\n",
+		   PIDGET (current_ptid));
+	    delete_user_process (thread_id);
+	} else if (thread_event_low_mem_bp != NULL
+		   && pc == thread_event_low_mem_bp->loc->address) {
+	    disable_userspace_breakpoints();
+	} else if (thread_event_do_exec_bp != NULL
+		   && pc == thread_event_do_exec_bp->loc->address) {
+	    thread_event_do_exec_return_bp
+		= create_thread_event_breakpoint(linux_awareness_ops->lo_return_address_at_start_of_function());
+	} else if (thread_event_do_exec_return_bp != NULL
+		   && pc == thread_event_do_exec_return_bp->loc->address) {
+	    if (thread_event_do_exec_bp != NULL) {
+		delete_breakpoint(thread_event_do_exec_bp);
+		thread_event_do_exec_bp = NULL;
+	    }
+	    check_exec_actions();
+	}
+
+	if (/* stoped after step_bp */
+	    (saved_singlestep_dest
+	     && ptid_equal(current_ptid, saved_singlestep_ptid))
+	    ||
+	    /* stopped after nice singlstep */
+	    (singlestep_info.placed_address
+	     && ptid_equal(current_ptid, singlestep_ptid))) {
+	    CORE_ADDR sp = read_sp ();
+
+	    if (normal_stop_sp == sp)
+		normal_stop_preempt_count = read_signed_field(linux_awareness_ops->lo_current_thread_info_address(),
+							      THREAD_INFO__PREEMPT_COUNT);
+	    else if (read_signed_field(linux_awareness_ops->lo_current_thread_info_address(),
+				       THREAD_INFO__PREEMPT_COUNT) == normal_stop_preempt_count)
+		normal_stop_sp = sp;
+	    else {
+		warning("\
+The code you were stepping has been preempted and the preemting task\n\
+or interrupt has executed this exact same code. You should be able to\n\
+find the frame you were stepping in the backtrace and to break there there.");
+#if 0
+		/* This will not match an existing ptid, but at the
+		   same time won't generate a new thread event. */
+		res = minus_one_ptid;
+		stopped_at_wrong_preempt_count = 1;
+#endif
+	    }
+	} else if (stopped_at_wrong_preempt_count) {
+#if 0
+	    /* stopped_at_wrong_preempt_count will force a hardware
+	       singlestep, so the condition that the flag is set is
+	       sufficient.  */
+	    stopped_at_wrong_preempt_count = 0;
+	    res = minus_one_ptid;
+#endif
+	    ;
+	}
+
+	if (saved_singlestep_dest) {
+	    /* If we come here, we must have set a step_resume_bp
+	       (otherwise saved_singlestep_dest would be zero).  */
+	    if (ptid_equal(res, saved_singlestep_ptid)) {
+		if (saved_singlestep_dest + 4 == pc) {
+		    /* Wait, we were singlestepping a thread and we
+		       don't arrive on the right instruction ?!
+		       Bullshit.  */
+		    warning("PC fixup after step_bp! %s != %s",
+			    paddr (saved_singlestep_dest), paddr (pc));
+		    write_pc(saved_singlestep_dest);
+		    pc = saved_singlestep_dest;
+		}
+
+		/* Good thread, good PC. The singlestep is finally
+		   over !  */
+		saved_singlestep_dest = 0;
+		if (step_bp) {
+		    delete_breakpoint(step_bp);
+		    step_bp = NULL;
+		}
+	    }
+	} else if (singlestep_dest) {
+	    if (singlestep_dest + 4 == pc
+		&& !breakpoint_here_p(pc)) {
+		warning("PC fixup after singlstep %s != %s",
+			paddr (singlestep_dest), paddr (pc));
+		write_pc(singlestep_dest);
+		pc = singlestep_dest;
+	    }
+
+	    if (!ptid_equal(res, singlestep_ptid)) {
+		/* We singlestepped into the wrong wrong thread.  */
+		DEBUG (TARGET, 2, "Ooops, wrong thread !\n");
+		saved_singlestep_ptid = singlestep_ptid;
+		saved_singlestep_dest = singlestep_dest;
+		if (pc == singlestep_dest)
+		    force_hw_singlestep = 1;
+	    }
+	}
+
+	if (waiting_on_bp && step_bp) {
+	    delete_breakpoint(step_bp);
+	    step_bp = NULL;
+	}
+    }
+
+    thread_awareness_exhibit ();
+
+    DEBUG (TARGET, 2,"linux_aware_waited : %i %i pc : %s pid: %i\n",
+	   status->kind, status->value.sig, paddr (read_pc_pid (res)), PIDGET(res));
+
+    return res;
+}
+
+static void
+try_to_step_on_unmapped_page (CORE_ADDR dest)
+{
+    CORE_ADDR faulty_addr = linux_awareness_ops->lo_translate_memory_watch_address (dest, get_current_task_struct ());
+    struct monitored_page *res = find_monitored_page (faulty_addr);
+    struct symtab_and_line sal;
+    struct breakpoint *bp;
+
+    if (res == NULL) {
+	int i, other_type_used, target_resources_ok;
+	i = hw_watchpoint_used_count (bp_hardware_watchpoint, &other_type_used);
+	target_resources_ok =
+	    TARGET_CAN_USE_HARDWARE_WATCHPOINT (bp_hardware_watchpoint, i + 1,
+						other_type_used);
+	if (target_resources_ok <= 0)
+	    error ("\
+You're about to step on an unmapped page. To this pupose, the debugger needs\n\
+a hardware watcpoint, but none are left. If you really want to step you must\n\
+disable one of the used HW watchpoints.");
+    }
+
+    /* From here, it shouldn;t fail */
+    init_sal (&sal);		/* initialize to zeroes */
+
+    sal.pc = dest;
+    sal.section = find_pc_overlay (sal.pc);
+
+    bp = set_raw_breakpoint (sal, bp_breakpoint);
+    set_breakpoint_count (breakpoint_count+1);
+    bp->number = breakpoint_count;
+    bp->disposition = disp_del;
+    bp->enable_state = bp_disabled;
+
+    if (res == NULL)
+	res = create_monitored_page (faulty_addr, bp);
+    else
+	add_bpt_to_monitored_page (res, bp);
+}
+
+static void
+linux_aware_context_hook(int id)
+{
+    if (waiting_on_bp) {
+	inferior_ptid = current_ptid;
+
+	/* We can do context_switch in the middle of a step, and GDB isn't
+	   prepared for that.  The information it might leave lying around
+	   will cause problems on later runs.  */
+	if (saved_singlestep_dest) {
+	    CORE_ADDR prev_pc, step_range_start, step_range_end;
+	    int trap_expected, handling_longjmp, another_trap;
+	    int stepping_through_solib_after_catch, current_line;
+	    struct breakpoint *step_resume_breakpoint;
+	    struct frame_id step_frame_id;
+	    bpstat stepping_through_solib_catchpoints;
+	    struct symtab *current_symtab;
+	    load_infrun_state (saved_singlestep_ptid, &prev_pc,
+			       &trap_expected, &step_resume_breakpoint,
+			       &step_range_start, &step_range_end,
+			       &step_frame_id, &handling_longjmp,
+			       &another_trap, &stepping_through_solib_after_catch,
+			       &stepping_through_solib_catchpoints,
+			       &current_line, &current_symtab);
+
+	    step_range_start = step_range_end = 0;
+	    another_trap = trap_expected = 0;
+
+	    save_infrun_state (saved_singlestep_ptid, prev_pc,
+			       trap_expected, step_resume_breakpoint,
+			       step_range_start, step_range_end,
+			       &step_frame_id, handling_longjmp,
+			       another_trap,stepping_through_solib_after_catch,
+			       stepping_through_solib_catchpoints,
+			       current_line, current_symtab);
+	}
+	saved_singlestep_dest = 0;
+    }
+
+    if (deprecated_context_chain)
+	deprecated_context_chain(id);
+}
+
+static int
+bpstat_should_stop(bpstat bs)
+{
+    while (bs) {
+	if (bs->stop) {
+	    return 1;
+	}
+	bs = bs->next;
+    }
+
+    return 0;
+}
+
+static void
+linux_aware_software_single_step (enum target_signal sig,
+				  int insert_breakpoints_p)
+{
+    /* Be sure that an interpreter_exec didn't remove that hook. */
+    deprecated_context_hook = linux_aware_context_hook;
+
+    if (insert_breakpoints_p) {
+	CORE_ADDR pc = read_pc ();
+	singlestep_ptid = inferior_ptid;
+
+	if (saved_singlestep_dest
+	    && ptid_equal(singlestep_ptid, saved_singlestep_ptid)) {
+	    DEBUG (TARGET, 2, "Singlestepping to: %s (retry)\n",
+		   paddr (singlestep_info.placed_address));
+	    singlestep_info.placed_address = saved_singlestep_dest;
+	    /* This should be reset if we fail the next step.  */
+	    saved_singlestep_dest = 0;
+	    force_hw_singlestep = 0;
+	} else {
+	    /* Analyse the present instruction environment and insert
+	       breakpoints.  */
+	    singlestep_info.placed_address = linux_awareness_ops->lo_single_step_destination (pc);
+	    DEBUG (TARGET, 2, "Singlestepping to: %s\n", paddr (singlestep_info.placed_address));
+	}
+
+	/* This is ugly, but it's the only way we can correctly handle
+	   single-stepping from a breakpoint */
+	if (breakpoint_here_p (pc)) {
+	    /* First check for obvious conditions where we know that
+	       we'll launch execution again.  */
+	    if (pc == normal_stop_pc
+		|| (shlib_event_load_bp && pc == shlib_event_load_bp->loc->address)
+		|| (shlib_event_init_bp && pc == shlib_event_init_bp->loc->address)
+		|| (shlib_event_free_bp && pc == shlib_event_free_bp->loc->address)
+		|| (thread_event_do_exit_bp && pc == thread_event_do_exit_bp->loc->address)
+		|| (thread_event_low_mem_bp && pc == thread_event_low_mem_bp->loc->address)
+		|| (thread_event_do_exec_bp && pc == thread_event_do_exec_bp->loc->address)
+		|| (thread_event_do_exec_return_bp && pc == thread_event_do_exec_return_bp->loc->address)
+		|| !breakpoint_thread_match(pc, current_ptid)) {
+		force_hw_singlestep = 1;
+	    } else {
+		/* Handle break conditions... We can't wait on a
+		   breakpoint if its condition is false, It would
+		   cause infrun to go in a infinite loop. */
+		if (stop_bpstat) {
+		    waiting_on_bp = bpstat_should_stop(stop_bpstat);
+		} else {
+		    bpstat bps;
+		    bps = bpstat_stop_status(pc, current_ptid,
+					     STOPPED_BY_WATCHPOINT(0));
+		    waiting_on_bp = bpstat_should_stop(bps);
+		    bpstat_clear(&bps);
+		}
+
+		if (!waiting_on_bp)
+		    force_hw_singlestep = 1;
+	    }
+	}
+
+	if (breakpoint_here_p (singlestep_info.placed_address)
+	    || (force_hw_singlestep && !waiting_on_bp))
+	    singlestep_info.placed_address = 0;
+	else {
+	    CORE_ADDR translated_dest = singlestep_info.placed_address;
+	    if (! translate_memory_address_safe (&translated_dest, 1)) {
+		singlestep_info.placed_address = 0;
+		/* This call can error() */
+		try_to_step_on_unmapped_page (translated_dest);
+		warning ("\
+You are stepping to a page that isn't currently mapped to memory. The\n\
+debugger will stop the execution after the page has been loaded and stop\n\
+before its first instruction is executed.");
+	    } else
+		target_insert_breakpoint (&singlestep_info);
+	}
+
+	/* Insert breakpoints. This needs thread awareness because of
+	   userspace debug. No need for breakpoints if we use an HW
+	   step.  */
+	if (!force_hw_singlestep)
+	    insert_breakpoints ();
+    } else {
+	/* Remove breakpoints. This needs thread awareness because of
+	   userspace debug. */
+	remove_breakpoints ();
+	disable_breakpoint_at_pc = 0;
+
+	if (singlestep_info.placed_address) {
+	    target_remove_breakpoint (&singlestep_info);
+	}
+	singlestep_info.placed_address = 0;
+    }
+}
+
+static char *
+read_dentry (CORE_ADDR dentry)
+{
+    CORE_ADDR parent, name;
+    char *res, *tmp;
+    unsigned int len;
+
+    parent = read_pointer_field (dentry, DENTRY__D_PARENT);
+
+    if (parent == dentry) {
+	res =  xmalloc (1);
+	res[0] = '\0';
+	return res;
+    }
+
+    len = read_unsigned_embedded_field (dentry, QSTR__LEN, DENTRY__D_NAME);
+    tmp = read_dentry (parent);
+    res = xmalloc (strlen (tmp) + 1 /* slash */ + len + 1 /* '\0' */);
+    sprintf (res, "%s/", tmp);
+    name = read_pointer_embedded_field (dentry, QSTR__NAME, DENTRY__D_NAME);
+    read_memory_string (name, res + strlen (tmp) + 1, len + 1);
+    xfree (tmp);
+    return res;
+}
+
+static void
+pmap_command (char *args, int from_tty)
+{
+    CORE_ADDR task = get_current_task_struct ();
+    CORE_ADDR mm = read_pointer_field (task, TASK_STRUCT__MM);
+    CORE_ADDR mmap;
+    unsigned int size, total = 0, writable = 0, shared = 0;
+
+    if (!mm) {
+	printf_filtered ("\tKernel thread\n");
+	return;
+    }
+
+    printf_filtered ("Start         Size Perm Mapping\n");
+
+    mmap = read_pointer_field (mm, MM_STRUCT__MMAP);
+    while (mmap) {
+	CORE_ADDR file;
+
+#define VM_READ		0x00000001	/* currently active flags */
+#define VM_WRITE	0x00000002
+#define VM_EXEC		0x00000004
+#define VM_SHARED	0x00000008
+
+#define VM_MAYREAD	0x00000010	/* limits for mprotect() etc */
+#define VM_MAYWRITE	0x00000020
+#define VM_MAYEXEC	0x00000040
+#define VM_MAYSHARE	0x00000080
+
+#define VM_GROWSDOWN	0x00000100	/* general info on the segment */
+#define VM_GROWSUP	0x00000200
+
+	unsigned int flags;
+	CORE_ADDR start, end;
+
+	flags = read_unsigned_field (mmap, VM_AREA_STRUCT__VM_FLAGS);
+	start = read_pointer_field (mmap, VM_AREA_STRUCT__VM_START);
+	end = read_pointer_field (mmap, VM_AREA_STRUCT__VM_END);
+	file = read_pointer_field (mmap, VM_AREA_STRUCT__VM_FILE);
+
+	size = (end-start)>>10;
+	total += size;
+	printf_filtered ("%s % 8dK %c%c%c%c ",
+			 paddr (start),
+			 size,
+			 flags & VM_READ ? 'r' : '-',
+			 flags & VM_WRITE ? 'w' : '-',
+			 flags & VM_EXEC ? 'x' : '-',
+			 flags & VM_MAYSHARE ? 's' : 'p');
+
+	if (flags & VM_WRITE)
+	    writable += size;
+
+	if (flags & VM_MAYSHARE)
+	    shared += size;
+
+	if (file) {
+	    CORE_ADDR dentry = read_pointer_field (file, FILE__F_DENTRY);
+	    char *filename = read_dentry (dentry);
+	    printf_filtered ("%s\n", filename);
+	    xfree (filename);
+	} else if (flags & (VM_GROWSDOWN|VM_GROWSUP)) {
+	    printf_filtered ("[ stack ]\n");
+	} else {
+	    printf_filtered ("[ anon ]\n");
+	}
+
+	mmap = read_pointer_field (mmap, VM_AREA_STRUCT__VM_NEXT);
+    }
+
+#undef VM_READ
+#undef VM_WRITE
+#undef VM_EXEC
+#undef VM_SHARED
+
+#undef VM_MAYREAD
+#undef VM_MAYWRITE
+#undef VM_MAYEXEC
+#undef VM_MAYSHARE
+
+#undef VM_GROWSDOWN
+#undef VM_GROWSUP
+
+    printf_filtered ("mapped: %uK\twriteable/private: %uK\tshared: %uK\n",
+		     total, writable, shared);
+}
+
+static void
+print_proc_env (CORE_ADDR mm)
+{
+    unsigned long env_start = read_unsigned_field (mm,MM_STRUCT__ENV_START);
+    unsigned long env_end =  read_unsigned_field (mm, MM_STRUCT__ENV_END);
+    long len = env_end-env_start;
+    gdb_byte *buf = xmalloc (len+1);
+    int l = 0, i = 0;
+
+    read_memory (env_start, buf, len);
+    buf[len]='\0';
+
+    printf_filtered ("------ Environment ------\n");
+
+    while (len > l) {
+	printf_filtered ("environ[%i] = '%s'\n", i++, buf+l);
+	l += strlen ((char *)buf+l) + 1;
+    }
+
+    xfree (buf);
+}
+
+static void
+print_proc_cmdline (CORE_ADDR mm)
+{
+    unsigned long arg_start = read_unsigned_field (mm, MM_STRUCT__ARG_START);
+    unsigned long arg_end = read_unsigned_field (mm, MM_STRUCT__ARG_END);
+    unsigned long len = arg_end-arg_start;
+    gdb_byte *buf = xmalloc (len+1);
+    int l = 0, i = 0;
+
+    read_memory (arg_start, buf, len);
+    buf[len]='\0';
+
+    printf_filtered ("------ Command line ------\n");
+
+    while (len > l) {
+	printf_filtered ("argv[%i] = '%s'\n", i++, buf+l);
+	l += strlen ((char *)buf+l) + 1;
+    }
+    xfree (buf);
+}
+
+static char *
+get_proc_exe (CORE_ADDR mm)
+{
+#define VM_EXECUTABLE    0x00001000
+    CORE_ADDR mmap = read_pointer_field (mm, MM_STRUCT__MMAP);
+    CORE_ADDR file;
+    unsigned int flags;
+
+    while (mmap) {
+	flags = read_unsigned_field (mmap, VM_AREA_STRUCT__VM_FLAGS);
+	if (flags & VM_EXECUTABLE) {
+	    file = read_pointer_field (mmap, VM_AREA_STRUCT__VM_FILE);
+	    if (file)
+		return read_dentry (read_pointer_field (file, FILE__F_DENTRY));
+	    break;
+	}
+	mmap = read_pointer_field (mmap, VM_AREA_STRUCT__VM_NEXT);
+    }
+
+    return NULL;
+}
+
+static void
+print_proc_exe (CORE_ADDR mm)
+{
+    char *filename = get_proc_exe (mm);
+
+    if (filename != NULL)
+	printf_filtered ("exe: %s\n", filename);
+    else
+	printf_filtered ("exe: Not found\n");
+
+    xfree (filename);
+}
+
+static void
+print_resource (CORE_ADDR resource, int depth, int width)
+{
+    CORE_ADDR next;
+    unsigned long start, end;
+    CORE_ADDR name_addr;
+    char buf[64];
+
+ begin:
+    start = read_unsigned_field (resource, RESOURCE_START);
+    end = read_unsigned_field (resource, RESOURCE_END);
+    name_addr = read_pointer_field (resource, RESOURCE_NAME);
+
+    if (name_addr) {
+	read_memory_string (name_addr, buf, 64);
+	buf[63] = '\0';
+    }
+
+    printf_filtered ("%*s%0*lx-%0*lx : %s\n",
+		     depth * 2, "",
+		     width, start,
+		     width, end,
+		     name_addr ? buf : "<BAD>");
+
+    next = read_pointer_field (resource, RESOURCE_CHILD);
+    if (next)
+	print_resource (next, depth+1, width);
+
+    next = read_pointer_field (resource, RESOURCE_SIBLING);
+    if (next) {
+	resource = next;
+	goto begin;
+    }
+}
+
+static void
+print_resources (CORE_ADDR resource)
+{
+    int depth = 0;
+    int width = read_unsigned_field (resource, RESOURCE_END) < 0x10000 ? 4 : 8;
+    CORE_ADDR first = read_pointer_field (resource, RESOURCE_CHILD);
+    print_resource (first, 0, width);
+}
+
+static void
+iomem_command (char *args, int from_tty)
+{
+    print_resources (ADDR (IOMEM_RESOURCE));
+}
+
+static void
+ioports_command(char *args, int from_tty)
+{
+    print_resources (ADDR (IOPORT_RESOURCE));
+}
+
+static void
+process_info_command (char *args, int from_tty)
+{
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task = ps->task_struct_address;
+    CORE_ADDR mm = read_pointer_field (task, TASK_STRUCT__MM);
+
+    printf_filtered ("Comm: %s (pid %i)\n", ps->comm, ps->pid);
+
+    if (!mm) {
+	printf_filtered ("\tKernel thread\n");
+	return;
+    }
+
+    print_proc_exe (mm);
+    print_proc_cmdline (mm);
+    print_proc_env (mm);
+}
+
+static int nr_irqs = 0;
+static int irq_desc_size = 0;
+
+static void
+get_nr_irqs ()
+{
+    struct symbol *sym = lookup_symbol ("irq_desc", NULL,
+					VAR_DOMAIN, NULL, NULL);
+
+    if (!sym
+	|| TYPE_CODE (SYMBOL_TYPE (sym)) != TYPE_CODE_ARRAY)
+	error ("\
+Couldn't find the NR_IRQS kernel setting using the debug info. Use\n\
+'set linux-awareness nr_irqs <n>' and 'set linux-awareness irq_desc_size <n>'\n\
+to workaround.");
+
+    irq_desc_size = TYPE_LENGTH (TYPE_TARGET_TYPE (SYMBOL_TYPE (sym)));
+    nr_irqs = TYPE_LENGTH (SYMBOL_TYPE (sym))/irq_desc_size;
+}
+
+static void
+interrupts_command (char *args, int from_tty)
+{
+    gdb_byte *irq_descs;
+    int i;
+    char buf[65];
+
+    struct name {
+	CORE_ADDR    addr;
+	char         name[65];
+	struct name *next;
+    } *names1 = NULL, *names2 = NULL, *cur;
+
+    struct name *find_name_aux (CORE_ADDR addr, struct name* list) {
+	struct name *n = list;
+
+	while (n) {
+	    if (n->addr == addr)
+		return n;
+	    n = n->next;
+	}
+
+	return NULL;
+    }
+
+    struct name *register_name (CORE_ADDR base, int field) {
+	struct name *name = xmalloc (sizeof (struct name));
+	struct name *n;
+	CORE_ADDR addr = read_pointer_field (base, field);
+	n = find_name_aux (addr, names2);
+	if (n)
+	    return n;
+
+	read_memory_string (addr, buf, 64);
+	strcpy (name->name, buf);
+	name->addr = base;
+	name->next = names1;
+	names1 = name;
+
+	name = xmalloc (sizeof (struct name));
+	strcpy (name->name, buf);
+	name->addr = addr;
+	name->next = names2;
+	names2 = name;
+
+	return name;
+    }
+
+    struct name *find_name (CORE_ADDR addr, int field) {
+	struct name* cur = find_name_aux (addr, names1);
+
+	if (cur)
+	    return cur;
+
+	return register_name (addr, field);
+    }
+
+    void free_names () {
+	while (names1) {
+	    cur = names1->next;
+	    xfree (names1);
+	    names1 = cur;
+	}
+	while (names2) {
+	    cur = names2->next;
+	    xfree (names2);
+	    names2 = cur;
+	}
+    }
+
+    buf[64] = '\0';
+
+    if (!nr_irqs)
+	get_nr_irqs ();
+
+    printf_filtered ("IRQ     Triggered Handler => Action\n");
+    printf_filtered ("-----------------------------------\n");
+
+    irq_descs = xmalloc (nr_irqs*irq_desc_size);
+    read_memory (ADDR (IRQ_DESC), irq_descs, nr_irqs*irq_desc_size);
+
+    for (i = 0; i < nr_irqs; ++i) {
+	CORE_ADDR action = extract_pointer_field (irq_descs + i*irq_desc_size,
+						  IRQ_DESC__ACTION);
+	CORE_ADDR handler, name;
+	int count;
+
+	if (!action)
+	    continue;
+
+	count = read_memory_unsigned_integer (ADDR (PER_CPU__KSTAT) + FIELD_OFFSET (KERNEL_STAT__IRQS) + i*FIELD_SIZE (KERNEL_STAT__IRQS)/nr_irqs,
+					      FIELD_SIZE (KERNEL_STAT__IRQS)/nr_irqs);
+	handler = extract_pointer_field (irq_descs + i*irq_desc_size,
+					 IRQ_DESC__HANDLER);
+
+	cur = find_name (handler, HW_INTERRUPT_TYPE__TYPENAME);
+	printf_filtered ("%3i     %9i %s ", i, count, cur->name);
+
+	cur = find_name (action, IRQACTION__NAME);
+	printf_filtered ("=> %s", cur->name);
+
+	do {
+	    action = read_pointer_field (action,  IRQACTION__NEXT);
+	    if (!action) break;
+	    cur = find_name (action, IRQACTION__NAME);
+	    printf_filtered (", %s", cur->name);
+	} while (1);
+
+	printf_filtered ("\n");
+    }
+
+    xfree (irq_descs);
+    free_names ();
+}
+
+static char *
+printf_dmesg (char *buf)
+{
+    int len = strlen (buf);
+    char* newline = strchr (buf, '\n');
+    char* full_buf = buf;
+
+    while (newline != NULL) {
+
+	if (newline - full_buf > len - 4) {
+	    *newline = '\0';
+	    printf_filtered ("%s", buf);
+	    *newline = '\n';
+	    return newline;
+	}
+
+	if (newline[1] == '<'
+	    && newline[2] >= '0' && newline[2] <= '7'
+	    && newline[3] == '>') {
+	    newline[1] = '\0';
+	    printf_filtered ("%s", buf);
+	    buf = newline + 4;
+	} else {
+	    *newline = '\0';
+	    printf_filtered ("%s\n", buf);
+	    buf = newline+1;
+	}
+
+	newline = strchr (buf, '\n');
+    }
+
+    printf_filtered ("%s", buf);
+    return "";
+}
+
+static void
+dmesg_command (char *args, int from_tty)
+{
+    unsigned int log_len = read_memory_unsigned_integer (ADDR (LOG_BUF_LEN),
+							 TYPE_LENGTH(builtin_type_int));
+    CORE_ADDR buf_end = ADDR (_LOG_BUF) + log_len;
+    unsigned long log_end = read_memory_unsigned_integer (ADDR (LOG_END),
+							  TYPE_LENGTH(builtin_type_unsigned_long));
+    CORE_ADDR log_start = log_end > log_len ?
+	                  ((log_end - 1) & (log_len - 1)) + ADDR (_LOG_BUF)
+                          : ADDR (_LOG_BUF);
+    CORE_ADDR buf_start = log_start;
+    int last_ended_with_newline = 0;
+    char *buf = alloca (log_chunk_size+1);
+    char *buf2 = alloca (log_chunk_size*2);
+    char *tmp;
+
+    buf[log_chunk_size] = '\0';
+    buf2[0] = '\n'; buf2[1] = '\0';
+
+    do {
+	if (buf_start + log_chunk_size >= buf_end) {
+	    read_memory (buf_start, (gdb_byte *)buf, buf_end - buf_start);
+	    buf[buf_end - buf_start] = '\0'; /* end the string */
+	    buf_start = ADDR (_LOG_BUF);
+	} else if (buf_start < log_start
+		   && buf_start + log_chunk_size >= log_start) {
+	    read_memory (buf_start, (gdb_byte *)buf, log_start-buf_start);
+	    buf[log_start-buf_start] = '\0'; /* end the string */
+	    buf[log_chunk_size-1] = '\0'; /* stop the loop */
+	} else {
+	    read_memory (buf_start, (gdb_byte *)buf, log_chunk_size);
+	    buf_start += log_chunk_size;
+	}
+
+	QUIT;
+	tmp = printf_dmesg (strcat (buf2, buf));
+	strcpy (buf2, tmp);
+    } while (buf[log_chunk_size-1] != '\0');
+
+    printf_filtered ("\n");
+}
+
+static void
+vm_translate_command (char *args, int from_tty)
+{
+    CORE_ADDR addr = parse_and_eval_address(args);
+    CORE_ADDR phys = addr;
+
+    if (translate_memory_address_safe (&phys, 0))
+	printf_filtered ("\
+Virtual address %s translates to physical address %s in the current context.\n",
+			 hex_string (addr), hex_string (phys));
+}
+
+#define SEQ_MULTIPLIER 32768
+
+#define	SHM_DEST	01000	/* segment will be destroyed on last detach */
+#define SHM_LOCKED      02000   /* segment will not be swapped */
+
+static void
+print_shm_struct (CORE_ADDR shm)
+{
+    unsigned int segsz, nattch, mode;
+
+    nattch = read_unsigned_field (shm, SHMID_KERNEL__SNH_NATTCH);
+    segsz = read_unsigned_field (shm, SHMID_KERNEL__SNH_SEGSZ);
+    mode = read_unsigned_field (shm, KERN_IPC_PERM__MODE);
+
+    printf_filtered ("%-10i %-10i %s %s", segsz, nattch,
+		     mode & SHM_DEST ? "dest" : "",
+		     mode & SHM_LOCKED ? "locked" : "");
+}
+
+static void
+print_sem_array_struct (CORE_ADDR sem_array)
+{
+    unsigned int nsems;
+    nsems = read_unsigned_field (sem_array, SEM_ARRAY__SEM_NSEMS);
+    printf_filtered ("%-10i", nsems);
+}
+
+static void
+print_msg_struct (CORE_ADDR msg)
+{
+    unsigned int bytes, num;
+    bytes = read_unsigned_field (msg, MSG_QUEUE__Q_CBYTES);
+    num = read_unsigned_field (msg, MSG_QUEUE__Q_QNUM);
+
+    printf_filtered ("%-10i %-10i", bytes, num);
+}
+
+static void
+print_ipc_ids_struct (CORE_ADDR ids,
+		      void (*specialized_printer)(CORE_ADDR))
+{
+    int in_use = read_signed_field (ids, IPC_IDS__IN_USE);
+    CORE_ADDR entries, entry;
+    unsigned int i, size, id, seq;
+    gdb_byte *buf;
+
+    if (!in_use) {
+	printf_filtered ("None\n");
+	return;
+    }
+
+    entries = read_pointer_field (ids, IPC_IDS__ENTRIES);
+    size = read_unsigned_field (entries, IPC_ID_ARY__SIZE);
+
+    buf = xmalloc (FIELD_SIZE (IPC_ID_ARY__SIZE) + TYPE_LENGTH(builtin_type_void_data_ptr)*size);
+    read_memory (entries, buf, FIELD_SIZE (IPC_ID_ARY__SIZE) + TYPE_LENGTH(builtin_type_void_data_ptr)*size);
+
+    for (i = 0; i < size; ++i) {
+	entry = extract_typed_address (buf+FIELD_OFFSET (IPC_ID_ARY__P)+TYPE_LENGTH(builtin_type_void_data_ptr)*i,
+				       builtin_type_void_data_ptr);
+	if (!entry) continue;
+
+	seq = read_unsigned_field (entry, KERN_IPC_PERM__SEQ);
+	id = SEQ_MULTIPLIER*seq + i;
+
+	printf_filtered ("0x%08llx %-10i %-10i %-10o ",
+			 read_unsigned_field (entry, KERN_IPC_PERM__KEY),
+			 id,
+			 (int)read_unsigned_field (entry, KERN_IPC_PERM__UID),
+			 (int)(0777 & read_unsigned_field (entry,
+							   KERN_IPC_PERM__MODE))
+			 );
+	if (specialized_printer)
+	    specialized_printer (entry);
+
+	printf_filtered ("\n");
+    }
+
+    xfree (buf);
+}
+
+static void
+ipcs_command (char *args, int from_tty)
+{
+    printf_filtered ("------ Shared Memory Segments ------\n");
+    printf ("%-10s %-10s %-10s %-10s %-10s %-10s %-10s\n",
+	    "key","shmid","owner","perms", "bytes", "nattch", "status");
+    print_ipc_ids_struct (ADDR (SHM_IDS), print_shm_struct);
+
+    printf_filtered ("\n------ Semaphore Arrays ------\n");
+    printf ("%-10s %-10s %-10s %-10s %-10s\n",
+	    "key","semid","owner","perms",
+	    "nsems");
+    print_ipc_ids_struct (ADDR (SEM_IDS), print_sem_array_struct);
+
+    printf_filtered ("\n------ Message Queues ------\n");
+    printf ("%-10s %-10s %-10s %-10s %-10s %-10s\n",
+	    "key","msgid","owner","perms", "used-bytes", "messages");
+    print_ipc_ids_struct (ADDR (MSG_IDS), print_msg_struct);
+}
+
+static char*
+get_banner_from_file ()
+{
+    static char banner[256];
+    int i = 0;
+    CORE_ADDR banner_addr = ADDR (LINUX_BANNER);
+    asection* data = bfd_get_section_by_name (exec_bfd, ".rodata");
+
+    if (data == NULL)
+	return NULL;
+
+    if (banner_addr < bfd_get_section_vma (exec_bfd, data)
+	|| banner_addr >= bfd_get_section_vma (exec_bfd,data)+bfd_get_section_size(data))
+	return NULL;
+
+    bfd_seek (exec_bfd, data->filepos + banner_addr - bfd_get_section_vma (exec_bfd, data), SEEK_SET);
+
+    while (i<256) {
+	bfd_bread (banner + i, 1, exec_bfd);
+	if (banner[i++] == '\0')
+	    break;
+    }
+
+    return banner;
+}
+
+static char*
+get_banner ()
+{
+    if (loaded) {
+	static char banner[256];
+
+	read_memory_string (ADDR (LINUX_BANNER), banner, 256);
+	banner[255] = '\0';
+
+	return banner;
+    }
+
+    return get_banner_from_file ();
+}
+
+static unsigned long
+get_buffered_ram (unsigned long *buffered_pages, unsigned long *swapcache_pages)
+{
+    int address_space__nrpages_size = 0;
+    int address_space__nrpages_offset = 0;
+    struct field_container *container;
+    struct type *type;
+    char *error_msg = NULL;
+    int i;
+    CORE_ADDR all_bdevs = 0;
+    CORE_ADDR next;
+
+    if (! HAS_ADDR (ALL_BDEVS)) {
+	error_msg = "Can't find the all_bdevs variable";
+	goto error;
+    }
+    all_bdevs = ADDR (ALL_BDEVS);
+
+    error_msg = "Can't find the struct address_space definition";
+
+    /* GCC generates the description of ``struct address_space'' only
+       in function scopes, which means it won't be put in GDB's global
+       struct type list. We have to get it's description by some other
+       way. */
+    container = search_field_container ("inode", "i_mapping");
+
+    if (container == NULL || container->type == NULL)
+	goto error;
+
+    type = SYMBOL_TYPE (container->type);
+
+    /* Type is struct inode.  */
+    CHECK_TYPEDEF (type);
+
+    for (i=0; i<TYPE_NFIELDS (type); ++i)
+	if (! strcmp (FIELD_NAME (TYPE_FIELDS (type)[i]), "i_mapping"))
+	    break;
+
+    if (i >= TYPE_NFIELDS (type))
+	goto error;
+
+    type = FIELD_TYPE (TYPE_FIELDS (type)[i]);
+    CHECK_TYPEDEF (type);
+
+    /* Type should be ptr to struct address_space.  */
+    if (TYPE_CODE (type) != TYPE_CODE_PTR)
+	goto error;
+
+    type = TYPE_TARGET_TYPE (type);
+    CHECK_TYPEDEF (type);
+
+    /* Type should be struct address_space.  */
+    if (TYPE_CODE (type) != TYPE_CODE_STRUCT)
+	goto error;
+
+    for (i=0; i<TYPE_NFIELDS (type); ++i)
+	if (! strcmp (FIELD_NAME(TYPE_FIELDS (type)[i]), "nrpages"))
+	    break;
+
+    if (i >= TYPE_NFIELDS (type))
+	goto error;
+
+    address_space__nrpages_offset = FIELD_BITPOS (TYPE_FIELDS (type)[i])/TARGET_CHAR_BIT;
+    address_space__nrpages_size = TYPE_LENGTH (check_typedef (TYPE_FIELDS (type)[i].type));
+
+    for (next = read_pointer_field (all_bdevs, LIST_HEAD__NEXT);
+	 next != all_bdevs;
+	 next = read_pointer_field (next, LIST_HEAD__NEXT)) {
+	CORE_ADDR bdev = next - FIELD_OFFSET (BLOCK_DEVICE__BD_LIST);
+	CORE_ADDR inode = read_pointer_field (bdev, BLOCK_DEVICE__BD_INODE);
+	CORE_ADDR mapping = read_pointer_field (inode, INODE__I_MAPPING);
+	*buffered_pages += read_memory_unsigned_integer (mapping + address_space__nrpages_offset,
+							 address_space__nrpages_size);
+    }
+
+    if (HAS_ADDR (SWAPPER_SPACE)) {
+	*swapcache_pages = read_memory_unsigned_integer (ADDR (SWAPPER_SPACE) + address_space__nrpages_offset,
+							 address_space__nrpages_size);
+    }
+
+    return 1;
+ error:
+    warning ("%s. Buffers numbers won't be accurate.", error_msg);
+    return 0;
+}
+
+static void
+get_swap (unsigned long *totalswap, unsigned long *freeswap)
+{
+    unsigned int i;
+    unsigned long nr_swap_pages = 0;
+    unsigned long total_swap_pages = 0;
+    unsigned long nr_swapfiles = 0;
+    unsigned long nr_to_be_unused = 0;
+    unsigned long swap_info_size = 0;
+    struct field_container *container;
+    CORE_ADDR swap_info;
+
+    enum {
+	SWP_USED	= (1 << 0),	/* is slot in swap_info[] used? */
+	SWP_WRITEOK	= (1 << 1),	/* ok to write to this swap?	*/
+	SWP_ACTIVE	= (SWP_USED | SWP_WRITEOK),
+    };
+
+    if (!HAS_ADDR (NR_SWAP_PAGES)
+	|| !HAS_ADDR (TOTAL_SWAP_PAGES)
+	|| !HAS_ADDR (NR_SWAPFILES)
+	|| !HAS_ADDR (SWAP_INFO))
+	return;
+
+    nr_swap_pages = read_memory_unsigned_integer (ADDR (NR_SWAP_PAGES),
+						  TYPE_LENGTH (builtin_type_unsigned_long));
+    total_swap_pages = read_memory_unsigned_integer (ADDR (TOTAL_SWAP_PAGES),
+						     TYPE_LENGTH (builtin_type_long));
+    nr_swapfiles = read_memory_unsigned_integer (ADDR (NR_SWAPFILES),
+						 TYPE_LENGTH (builtin_type_unsigned_int));
+    swap_info = ADDR (SWAP_INFO);
+
+    container = search_field_container ("swap_info_struct", "flags");
+    if (container == NULL || container->type == NULL)
+	return;
+
+    swap_info_size = TYPE_LENGTH (SYMBOL_TYPE (container->type));
+
+    for (i = 0; i < nr_swapfiles; i++) {
+	unsigned long flags = read_unsigned_field (swap_info + i*swap_info_size,
+						   SWAP_INFO_STRUCT__FLAGS);
+	if (!(flags & SWP_USED) ||
+	    (flags & SWP_WRITEOK))
+	    continue;
+	nr_to_be_unused += read_unsigned_field (swap_info + i*swap_info_size,
+						SWAP_INFO_STRUCT__INUSE_PAGES);
+    }
+
+    *freeswap = nr_swap_pages + nr_to_be_unused;
+    *totalswap = total_swap_pages + nr_to_be_unused;
+}
+
+#define K(x) (unsigned long)((x) << (linux_awareness_ops->page_shift - 10))
+
+static void
+proc_meminfo_command (char *args, int from_tty)
+{
+    unsigned long totalram = 0;
+    unsigned long totalhigh = 0;
+    unsigned long free_pages = 0;
+    unsigned long active_pages = 0;
+    unsigned long inactive_pages = 0;
+    unsigned long free_highpages = 0;
+    unsigned long buffered_pages = 0;
+    unsigned long swapcache_pages = 0;
+    unsigned long pagecache_pages = 0;
+    unsigned long totalswap_pages = 0;
+    unsigned long freeswap_pages = 0;
+    unsigned long dirty_pages = 0;
+    unsigned long mapped_pages = 0;
+    unsigned long writeback_pages = 0;
+    unsigned long slab_pages = 0;
+    unsigned long pagetable_pages = 0;
+    unsigned long vm_committed_space = 0;
+    unsigned long sysctl_overcommit_ratio = 0;
+    unsigned long nr_huge_pages = 0;
+    unsigned long committed = 0;
+    unsigned long allowed = 0;
+    unsigned long vmalloc = 0;
+    CORE_ADDR vmlist = 0;
+    unsigned int struct_zone_size;
+    CORE_ADDR pgdat;
+    CORE_ADDR page_states = 0;
+    unsigned int max_nr_zones = 3;
+    unsigned int zone_highmem = 2;
+
+
+    if (HAS_ADDR (PGDAT_LIST))
+	/* Used for Linux 2.0 (2.6.11) kernels */
+	pgdat = read_memory_typed_address (ADDR (PGDAT_LIST),
+					   builtin_type_void_data_ptr);
+    else {
+	/* Used for Linux 2.2 (2.6.17) kernels */
+	pgdat = ADDR (CONTIG_PAGE_DATA);
+	max_nr_zones = 4;
+	zone_highmem = 3;
+    }
+
+    struct_zone_size = FIELD_SIZE (PGLIST_DATA__NODE_ZONES) / max_nr_zones;
+
+    if (HAS_ADDR (PER_CPU__PAGE_STATES))
+	page_states = ADDR (PER_CPU__PAGE_STATES);
+    else
+	warning("\
+Can't find the per_cpu__page_states  variable. Numbers won't be accurate.");
+
+    if (HAS_ADDR (TOTALRAM_PAGES))
+	totalram = read_memory_unsigned_integer (ADDR (TOTALRAM_PAGES),
+						 TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	warning("\
+Can't find the totalram_pages variable. Total memory won't be accurate.");
+
+    if (HAS_ADDR (TOTALHIGH_PAGES))
+	totalhigh = read_memory_unsigned_integer(ADDR (TOTALHIGH_PAGES),
+						 TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	warning("\
+Can't find the totalhigh_pages variable. Total high memory won't be accurate.");
+
+    if (HAS_ADDR (NR_PAGECACHE))
+	pagecache_pages = read_memory_unsigned_integer(ADDR (NR_PAGECACHE),
+						       TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	warning("\
+Can't find the nr_pagecache variable. Caches memory won't be accurate.");
+
+    if (HAS_ADDR (VM_COMMITTED_SPACE))
+	vm_committed_space = read_memory_unsigned_integer(ADDR (VM_COMMITTED_SPACE),
+							  TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	warning("\
+Can't find the vm_commited_space variable. Commited memory won't be accurate.");
+
+    if (HAS_ADDR (SYSCTL_OVERCOMMIT_RATIO))
+	sysctl_overcommit_ratio = read_memory_unsigned_integer(ADDR (SYSCTL_OVERCOMMIT_RATIO),
+							       TYPE_LENGTH(builtin_type_int));
+    else
+	warning("\
+Can't find the sysctl_overcommit_ratio variable. Commited memory won't be accurate.");
+
+    if (HAS_ADDR (VMLIST))
+	vmlist = ADDR (VMLIST);
+    else
+	warning("\
+Can't find the vmlist variable. Vmalloced memory won't be accurate.");
+
+    if (HAS_ADDR (NR_HUGE_PAGES))
+	nr_huge_pages = read_memory_unsigned_integer(ADDR (NR_HUGE_PAGES),
+						     TYPE_LENGTH(builtin_type_unsigned_long));
+    else
+	/* Might not be compiled in. */;
+
+    while (pgdat) {
+	CORE_ADDR zone = pgdat+FIELD_OFFSET (PGLIST_DATA__NODE_ZONES);
+	unsigned long i, free;
+
+	for (i = 0; i < max_nr_zones; ++i, zone += struct_zone_size) {
+	    active_pages += read_unsigned_field (zone, ZONE__NR_ACTIVE);
+	    inactive_pages += read_unsigned_field (zone, ZONE__NR_INACTIVE);
+	    free = read_unsigned_field (zone, ZONE__FREE_PAGES);
+	    free_pages += free;
+	    if (i == zone_highmem) free_highpages += free;
+	}
+
+	if (! HAS_FIELD (PGLIST_DATA__PGDAT_NEXT))
+	    /* It's not a list in linux 2.6.17 */
+	    break;
+	pgdat = read_pointer_field (pgdat, PGLIST_DATA__PGDAT_NEXT);
+    }
+
+    dirty_pages = read_unsigned_field (page_states, PAGE_STATE__NR_DIRTY);
+    mapped_pages = read_unsigned_field (page_states, PAGE_STATE__NR_MAPPED);
+    writeback_pages = read_unsigned_field (page_states,
+					   PAGE_STATE__NR_WRITEBACK);
+    slab_pages = read_unsigned_field (page_states, PAGE_STATE__NR_SLAB);
+    pagetable_pages = read_unsigned_field (page_states,
+					   PAGE_STATE__NR_PAGE_TABLE_PAGES);
+
+    get_buffered_ram (&buffered_pages, &swapcache_pages);
+    get_swap (&totalswap_pages, &freeswap_pages);
+
+    committed = vm_committed_space;
+    allowed = totalram * sysctl_overcommit_ratio / 100 + totalswap_pages;
+
+    for (vmlist = read_memory_typed_address (vmlist,
+					     builtin_type_void_data_ptr);
+	 vmlist != 0;
+	 vmlist = read_pointer_field (vmlist, VM_STRUCT__NEXT)) {
+	vmalloc += read_unsigned_field (vmlist, VM_STRUCT__SIZE);
+    }
+
+    printf_filtered ("MemTotal:     %8lu kB\n"
+		     "MemFree:      %8lu kB\n"
+		     "Buffers:      %8lu kB\n"
+		     "Cached:       %8lu kB\n"
+		     "SwapCached:   %8lu kB\n"
+		     "Active:       %8lu kB\n"
+		     "Inactive:     %8lu kB\n"
+		     "HighTotal:    %8lu kB\n"
+		     "HighFree:     %8lu kB\n"
+		     "LowTotal:     %8lu kB\n"
+		     "LowFree:      %8lu kB\n"
+		     "SwapTotal:    %8lu kB\n"
+		     "SwapFree:     %8lu kB\n"
+		     "Dirty:        %8lu kB\n"
+		     "Writeback:    %8lu kB\n"
+		     "Mapped:       %8lu kB\n"
+		     "Slab:         %8lu kB\n"
+		     "CommitLimit:  %8lu kB (minus %lu huge pages)\n"
+		     "Committed_AS: %8lu kB\n"
+		     "PageTables:   %8lu kB\n"
+		     "VmallocUsed:  %8lu kB\n",
+		     K (totalram),
+		     K (free_pages),
+		     K (buffered_pages),
+		     K (pagecache_pages-swapcache_pages-buffered_pages),
+		     K (swapcache_pages),
+		     K (active_pages),
+		     K (inactive_pages),
+		     K (totalhigh),
+		     K (free_highpages),
+		     K (totalram-totalhigh),
+		     K (free_pages-free_highpages),
+		     K (totalswap_pages),
+		     K (freeswap_pages),
+		     K (dirty_pages),
+		     K (writeback_pages),
+		     K (mapped_pages),
+		     K (slab_pages),
+		     K (allowed),
+		     K (nr_huge_pages * sysctl_overcommit_ratio / 100),
+		     K (committed),
+		     K (pagetable_pages),
+		     vmalloc >> 10
+		     );
+
+}
+
+#undef K
+#undef MAX_NR_ZONES
+#undef ZONE_HIGHMEM
+
+static void
+proc_version_command (char *args, int from_tty)
+{
+    printf_filtered ("%s", get_banner());
+}
+
+static void
+proc_cmdline_command (char *args, int from_tty)
+{
+    static char cmdline[1024];
+
+    read_memory_string (ADDR (SAVED_COMMAND_LINE), cmdline, 1024);
+    cmdline[1023] = '\0';
+
+    printf_filtered ("%s\n", cmdline);
+}
+
+static void
+proc_mounts_command (char *args, int from_tty)
+{
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task = ps->task_struct_address;
+    CORE_ADDR namespace = read_pointer_field (task, TASK_STRUCT__NAMESPACE);
+    CORE_ADDR list_head, next_vfs, vfs, tmp, tmp2, sb;
+    static char buf[256];
+    char *str;
+    unsigned int flags, len;
+
+#define MS_RDONLY	 1	/* Mount read-only */
+#define MS_SYNCHRONOUS	16	/* Writes are synced at once */
+#define MS_MANDLOCK	64	/* Allow mandatory locks on an FS */
+#define MS_DIRSYNC	128	/* Directory modifications are synchronous */
+#define MS_NOATIME	1024	/* Do not update access times. */
+#define MS_NODIRATIME	2048	/* Do not update directory access times */
+
+#define MNT_NOSUID	1
+#define MNT_NODEV	2
+#define MNT_NOEXEC	4
+
+    static struct proc_fs_info {
+	int flag;
+	char *str;
+    } fs_info[] = {
+	{ MS_SYNCHRONOUS, ",sync" },
+	{ MS_DIRSYNC, ",dirsync" },
+	{ MS_MANDLOCK, ",mand" },
+	{ MS_NOATIME, ",noatime" },
+	{ MS_NODIRATIME, ",nodiratime" },
+	{ 0, NULL }
+    };
+    static struct proc_fs_info mnt_info[] = {
+	{ MNT_NOSUID, ",nosuid" },
+	{ MNT_NODEV, ",nodev" },
+	{ MNT_NOEXEC, ",noexec" },
+	{ 0, NULL }
+    };
+    struct proc_fs_info *fs_infop;
+
+    buf[255] = '\0';
+
+    if (!namespace) {
+	printf_filtered ("\
+\tNo namespace for current process. Kernel thread?\n");
+	return;
+    }
+
+    list_head = namespace + FIELD_OFFSET (NAMESPACE__LIST);
+    next_vfs = read_pointer_field (list_head, LIST_HEAD__NEXT);
+
+    while (next_vfs != list_head) {
+	vfs = next_vfs - FIELD_OFFSET (VFSMOUNT__MNT_LIST);
+
+	tmp = read_pointer_field (vfs, VFSMOUNT__MNT_DEVNAME);
+	if (tmp)
+	    read_memory_string (tmp, buf, 255);
+	else
+	    strcpy(buf, "none");
+	printf_filtered ("%s ", buf);
+
+	tmp2 = vfs;
+	len = 0;
+	do {
+	    tmp = read_pointer_field (tmp2, VFSMOUNT__MNT_MOUNTPOINT);
+	    str = read_dentry (tmp);
+	    memmove (buf + strlen (str), buf, len);
+	    len += strlen (str);
+
+	    strcpy (buf, str);
+	    buf[strlen (str)] = '/';
+	    xfree (str);
+
+	    tmp = tmp2;
+	    tmp2 = read_pointer_field (tmp2, VFSMOUNT__MNT_PARENT);
+	} while (tmp != tmp2);
+
+	buf[len ? len : 1] = '\0';
+	printf_filtered ("%s ", buf);
+
+	sb = read_pointer_field (vfs, VFSMOUNT__MNT_SB);
+	tmp = read_pointer_field (sb, SUPER_BLOCK__S_TYPE);
+	tmp = read_pointer_field (tmp, FILE_SYSTEM_TYPE__NAME);
+	read_memory_string (tmp, buf, 255);
+	printf_filtered ("%s ", buf);
+
+	flags = read_unsigned_field (sb, SUPER_BLOCK__S_FLAGS);
+	if (flags & MS_RDONLY)
+	    printf_filtered ("ro");
+	else
+	    printf_filtered ("rw");
+
+	for (fs_infop = fs_info; fs_infop->flag; fs_infop++) {
+	    if (flags & fs_infop->flag)
+		printf_filtered ("%s", fs_infop->str);
+	}
+
+	flags = read_unsigned_field (vfs, VFSMOUNT__MNT_FLAGS);
+
+	for (fs_infop = mnt_info; fs_infop->flag; fs_infop++) {
+	    if (flags & fs_infop->flag)
+		printf_filtered ("%s", fs_infop->str);
+	}
+
+	printf_filtered ("\n");
+
+	next_vfs = read_pointer_field (next_vfs, LIST_HEAD__NEXT);
+    }
+
+}
+
+
+static void
+restore_caution (void *saved_caution)
+{
+    extern int caution;
+    caution = (int)saved_caution;
+}
+
+static void
+restore_inferior_ptid (void *saved_ptid)
+{
+    inferior_ptid = *(ptid_t*)saved_ptid;
+}
+
+static void
+check_exec_actions()
+{
+    char *execed;
+    struct process *ps;
+    struct waited_exe *exe = waited_exes, *prev = NULL;
+    struct command_line *cmd;
+    extern int caution;
+
+    ps = get_current_process();
+    if (ps->mm == 0)
+	return;
+
+    execed = get_proc_exe(ps->mm);
+    if (execed == NULL)
+	return;
+
+    DEBUG(USER, 2, "%s: The executable is : %s\n", __FUNCTION__, execed);
+
+    while (exe) {
+	struct cleanup *cleanup;
+	ptid_t saved_ptid = inferior_ptid;
+
+	DEBUG(USER, 3, "\tComparing to '%s'\n",exe->name);
+	if (strstr(execed, exe->name) != (execed + strlen(execed) - strlen(exe->name))) {
+	    prev = exe;
+	    exe = exe->next;
+	    continue;
+	}
+
+	cleanup = make_cleanup(restore_caution, (void*)caution);
+	make_cleanup(restore_inferior_ptid, &saved_ptid);
+	caution = 0;
+	inferior_ptid = current_ptid;
+
+	debug_process_command(NULL, 0);
+	cmd = exe->cmds;
+	while (cmd != NULL) {
+	    execute_control_command(cmd);
+	    cmd = cmd->next;
+	}
+	do_cleanups(cleanup);
+
+	if (prev != NULL)
+	    prev->next = exe->next;
+	else
+	    waited_exes = exe->next;
+
+	xfree(exe->name);
+	free_command_lines(&exe->cmds);
+	xfree(exe);
+	return;
+    }
+}
+
+static void
+delete_user_process (int thread_id)
+{
+    struct debugged_user_process *ups = user_processes;
+    struct debugged_user_process **prev;
+    struct objfile *objf, *next_objf;
+    struct breakpoint *bp, *tmp;
+    int first = 1;
+
+    prev = &user_processes;
+
+    while (ups) {
+	if (ups->gdb_thread_id != thread_id) {
+	    prev = &ups->next;
+	    ups = ups->next;
+	    continue;
+	}
+
+	objf = object_files;
+	object_files = ups->objfiles;
+	forget_cached_source_info ();
+	object_files = objf;
+
+	*prev = ups->next;
+
+	ALL_OBJFILES (objf)
+	    if (objf->next == ups->objfiles) {
+		objf->next = NULL;
+		break;
+	    }
+
+	objf = ups->objfiles;
+	while (objf) {
+	    next_objf = objf->next;
+	    objf->next = object_files;
+	    object_files = objf;
+	    free_objfile (objf);
+	    objf = next_objf;
+	}
+
+	ALL_BREAKPOINTS_SAFE (bp, tmp) {
+	    if (bp->thread == ups->gdb_thread_id) {
+		if (first)
+		    warning ("\
+Debugged user process (pid: %i) has finished. Removing breakpoints.", ups->pid);
+		first = 0;
+		delete_breakpoint (bp);
+	    }
+	}
+
+	if (current_user_process == ups)
+	    current_user_process = NULL;
+	xfree (ups);
+	break;
+    }
+}
+
+static void
+running_task_command (char *args, int from_tty)
+{
+    ptid_t ptid = linux_aware_pid_to_ptid (get_current_process ()->pid);
+    char *thread_id = xstrprintf ("%d", pid_to_thread_id (ptid));
+    gdb_thread_select (uiout, thread_id, NULL);
+    xfree (thread_id);
+}
+
+static void
+switch_to_user_process (struct process *ps)
+{
+    struct objfile *objf = NULL;
+    struct debugged_user_process *ups = user_processes;
+
+    if (stick_to_kernelspace)
+	return;
+
+    if (ps) {
+	DEBUG (USER, 4, "Asking to switch to %s %i\n", ps->comm, ps->pid);
+    } else {
+	DEBUG (USER, 4, "Switching to kernel\n");
+    }
+
+    if (current_user_process == NULL && ps != NULL && ps->mm == 0)
+	return;
+
+    last_warned = (CORE_ADDR)-1;
+
+    if (ps != NULL
+	&& current_user_process
+	&& current_user_process->pid == ps->pid
+	&& current_user_process->task_struct_address == ps->task_struct_address) {
+	ups = current_user_process;
+	symfile_objfile = ups->main_objfile;
+	set_main_name (NULL);
+    } else if (ps != NULL)
+	while (ups) {
+	    if (ups->pid == ps->pid
+		&& ups->task_struct_address == ps->task_struct_address) {
+		DEBUG (USER, 2, "Switching to user process %s\n", ps->comm);
+		symfile_objfile = ups->main_objfile;
+		set_main_name (NULL);
+		break;
+	    }
+	    ups = ups->next;
+	}
+    else
+	ups = NULL;
+
+    if (current_user_process != NULL) {
+	ALL_OBJFILES (objf)
+	    if (objf->next == current_user_process->objfiles) {
+		if (ups)
+		    objf->next = ups->objfiles;
+		else
+		    objf->next = NULL;
+		break;
+	    }
+    } else if (ups) {
+	ALL_OBJFILES (objf)
+	    if (objf->next == NULL)
+		break;
+	objf->next = ups->objfiles;
+    }
+
+    if (!ups) {
+	symfile_objfile = object_files;
+	set_main_name ("start_kernel");
+    }
+
+    current_user_process = ups;
+}
+
+struct bp_list {
+    struct bp_list *next;
+    struct breakpoint *b;
+};
+
+struct monitored_page {
+    struct monitored_page *next;
+    CORE_ADDR              addr;
+    CORE_ADDR              virt_addr;
+    int                    stop;
+    struct breakpoint     *watchpoint;
+    struct bp_list        *bps;
+};
+
+static struct monitored_page *monitored_pages;
+
+static void
+create_watchpoint_commands (struct monitored_page *page)
+{
+    struct command_line **cmds;
+    struct bp_list *bps = page->bps;
+
+    free_command_lines (&page->watchpoint->commands);
+
+    cmds = & page->watchpoint->commands;
+    *cmds = xmalloc (sizeof (struct command_line));
+    (*cmds)->line = xstrdup ("silent");
+    (*cmds)->control_type = simple_control;
+    (*cmds)->body_count = 0;
+    (*cmds)->next = NULL;
+
+    if (page->stop) {
+	cmds = &(*cmds)->next;
+	*cmds = xmalloc (sizeof (struct command_line));
+	(*cmds)->line = xstrprintf ("printf \"The page at address 0x%s has just been mapped to memory.\n\"",
+				    paddr (page->virt_addr));
+	(*cmds)->control_type = simple_control;
+	(*cmds)->body_count = 0;
+    }
+
+    if (bps != NULL)
+	do {
+	    cmds = &(*cmds)->next;
+	    *cmds = xmalloc (sizeof (struct command_line));
+	    (*cmds)->line = xstrprintf ("enable %i", bps->b->number);
+	    (*cmds)->control_type = simple_control;
+	    (*cmds)->body_count = 0;
+	    bps = bps->next;
+	} while (bps);
+
+    cmds = &(*cmds)->next;
+    *cmds = xmalloc (sizeof (struct command_line));
+    (*cmds)->line = xstrprintf ("delete %i", page->watchpoint->number);
+    (*cmds)->control_type = simple_control;
+    (*cmds)->body_count = 0;
+
+    if (! page->stop) {
+	cmds = &(*cmds)->next;
+	*cmds = xmalloc (sizeof (struct command_line));
+	(*cmds)->line = xstrdup ("continue");
+	(*cmds)->control_type = simple_control;
+	(*cmds)->body_count = 0;
+    }
+
+    (*cmds)->next = NULL;
+}
+
+static struct monitored_page *
+create_monitored_page (CORE_ADDR addr, struct breakpoint *bp)
+{
+    struct monitored_page *res = xmalloc (sizeof (struct monitored_page));
+    int bpnum, i, other_type_used, target_resources_ok;
+    struct symtab_and_line sal;
+    char *text, *exp_text;
+    struct expression *exp;
+    struct value *val, *mark;
+    struct breakpoint *b;
+
+    res->next = monitored_pages;
+    monitored_pages = res;
+
+    res->addr = addr;
+    if (bp != NULL) {
+	res->bps = xmalloc (sizeof (struct bp_list));
+	res->bps->next = NULL;
+	res->bps->b = bp;
+    } else
+	res->bps = NULL;
+
+    res->stop = 0;
+
+    init_sal (&sal);		/* initialize to zeroes */
+    text = xstrprintf ("*0x%s", paddr (addr));
+    exp_text = text;
+    exp = parse_exp_1 (&exp_text, 0, 0);
+    mark = value_mark ();
+    val = evaluate_expression (exp);
+    release_value (val);
+    if (value_lazy (val))
+	value_fetch_lazy (val);
+
+    i = hw_watchpoint_used_count (bp_hardware_watchpoint, &other_type_used);
+    target_resources_ok =
+	TARGET_CAN_USE_HARDWARE_WATCHPOINT (bp_hardware_watchpoint, i + 1,
+					    other_type_used);
+
+    if (target_resources_ok <= 0) {
+	/* FIXME : leaks */
+	warning ("\
+The hardware watchpoints are exhausted. The debugger can't monitor this\n\
+page's load.");
+	return NULL;
+    }
+
+    b = set_raw_breakpoint (sal, bp_hardware_watchpoint);
+    set_breakpoint_count (breakpoint_count + 1);
+    b->number = breakpoint_count;
+    b->disposition = disp_donttouch;
+    b->exp = exp;
+    b->exp_valid_block = NULL;
+    b->exp_string = savestring (text, exp_text - text);
+    xfree (text);
+    b->val = val;
+    b->cond = NULL;
+    if (bp != NULL)
+	b->thread = bp->thread;
+    else
+	b->thread = pid_to_thread_id (inferior_ptid);
+    b->commands = NULL;
+
+    res->watchpoint = b;
+
+    create_watchpoint_commands (res);
+    return res;
+}
+
+static void
+add_bpt_to_monitored_page (struct monitored_page *page, struct breakpoint *bpt)
+{
+    struct bp_list *list = xmalloc (sizeof (struct bp_list));
+    list->next = page->bps;
+    list->b = bpt;
+    page->bps = list;
+
+    create_watchpoint_commands (page);
+}
+
+static struct monitored_page *
+find_monitored_page (CORE_ADDR addr)
+{
+    struct monitored_page *page = monitored_pages;
+
+    while (page != NULL) {
+	if (page->addr == addr)
+	    break;
+	page = page->next;
+    }
+
+    return page;
+}
+
+static struct monitored_page *
+add_monitored_page (struct breakpoint *bpt, CORE_ADDR addr)
+{
+    CORE_ADDR faulty_addr;
+    struct monitored_page *res;
+    CORE_ADDR task = get_current_task_struct ();
+    faulty_addr = linux_awareness_ops->lo_translate_memory_watch_address (addr,
+									  task);
+    if (!faulty_addr) {
+	error ("Could not find a place to put the page watchpoint.");
+    }
+
+    res = find_monitored_page (faulty_addr);
+
+    if (res == NULL) {
+	if (yquery ("\
+The page where you tried to set a breakpoint isn't currently mapped to\n\
+memory. The debugger can monitor the page load and set the breakpoint when it\n\
+gets loaded. This will use a hardware watchpoint. Do you want the debugger to\n\
+monitor the page load? ")) {
+	    res = create_monitored_page (faulty_addr, bpt);
+	}
+	if (res == NULL)
+	    warning ("Your breakpoint has been disabled.");
+    } else {
+	add_bpt_to_monitored_page (res, bpt);
+    }
+    return res;
+}
+
+static void
+set_nopage_watchpoint (struct breakpoint *bpt, CORE_ADDR addr)
+{
+    add_monitored_page (bpt, addr);
+}
+
+static void
+wait_page_command(char *args, int from_tty)
+{
+    enum page_status stat;
+    CORE_ADDR addr = parse_and_eval_address(args);
+    CORE_ADDR orig_addr = addr;
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task_struct = ps->task_struct_address;
+    CORE_ADDR faulty_addr;
+    struct monitored_page *res;
+
+    stat = linux_awareness_ops->lo_translate_memory_address (&addr, task_struct);
+
+    if (stat == PAGE_PRESENT) {
+	printf_filtered("The page is already in memory!\n");
+	return;
+    }
+
+    faulty_addr = linux_awareness_ops->lo_translate_memory_watch_address (orig_addr,
+									  task_struct);
+
+    res = find_monitored_page (faulty_addr);
+
+    if (res == NULL) {
+	res = create_monitored_page (faulty_addr, NULL);
+    }
+
+    /* create_monitored_page will have emited a warning if needed.  */
+    if (res != NULL) {
+	res->stop = 1;
+	res->virt_addr = orig_addr;
+	create_watchpoint_commands(res);
+    }
+
+}
+
+static void
+wait_exe_command(char *args, int from_tty)
+{
+    struct command_line *cmds;
+    struct waited_exe   *res;
+    if (args == NULL) {
+	printf_filtered("You must supply an executable name.\n");
+	return;
+    }
+
+    res = xmalloc(sizeof(struct waited_exe));
+    res->next = waited_exes;
+    waited_exes = res;
+    res->name = xstrdup(args);
+
+    cmds = read_command_lines("\
+Type commands that will be executed the next time the binary is exec'd:", from_tty);
+
+    res->cmds = cmds;
+
+    if (thread_event_do_exec_return_bp == NULL)
+	thread_event_do_exec_bp = create_thread_event_breakpoint(ADDR(DO_EXECVE));
+}
+
+static void
+new_debugged_user_process (struct process *ps,
+			   struct objfile *objfiles,
+			   struct objfile *main_objfile)
+{
+    struct debugged_user_process *user_process;
+    ptid_t ptid = linux_aware_pid_to_ptid (ps->pid);
+
+    user_process = xmalloc (sizeof (struct debugged_user_process));
+    user_process->next = user_processes;
+    user_process->pid = ps->pid;
+    user_process->gdb_thread_id = pid_to_thread_id (ptid);
+    user_process->task_struct_address = ps->task_struct_address;
+    user_process->objfiles = objfiles;
+    user_process->main_objfile = main_objfile;
+
+    user_processes = user_process;
+
+    /* It's important to set current_user_process, otherwise the
+       objfile list won't be cleaned in switch_to_user_process and
+       we'll get duplicate entries.*/
+    current_user_process = user_process;
+    switch_to_user_process (ps);
+}
+
+static void restore_breakpoints (void *bps)
+{
+    breakpoint_chain = bps;
+}
+
+static void (*dwarf2_psymtab_to_symtab) (struct partial_symtab *pst);
+
+static void
+linux_aware_read_symtab(struct partial_symtab *pst)
+{
+    struct stat stat_struct;
+
+    if (! dwarf2_psymtab_to_symtab)
+	return;
+
+    dwarf2_psymtab_to_symtab (pst);
+
+    if (! pst->symtab)
+	return;
+
+    if (pst->symtab->dirname
+	&& stat (pst->symtab->dirname, &stat_struct) == -1) {
+	char *host_dir = xstrprintf ("%s/%s",
+				     *target_root_prefix,
+				     pst->symtab->dirname);
+
+	if (stat (host_dir, &stat_struct) == 0) {
+	    pst->symtab->dirname = (char *)
+		obstack_alloc (&pst->objfile->objfile_obstack,
+			       strlen (host_dir) + 1);
+	    strcpy (pst->symtab->dirname, host_dir);
+	}
+
+	xfree (host_dir);
+    }
+}
+
+static void
+debug_process_command (char *args, int from_tty)
+{
+    struct stat stat_struct;
+    struct partial_symtab *psymtab;
+    struct process *ps = get_gdb_process ();
+    CORE_ADDR task = ps->task_struct_address;
+    CORE_ADDR mm = ps->mm;
+    CORE_ADDR mmap, dentry;
+    char *filename;
+    bfd *abfd;
+    asection *sect;
+    struct objfile* objfiles = NULL, *objfile;
+    struct objfile* main_objfile = NULL;
+    struct section_addr_info addrs = { 1, {0, ".text", 0}};
+    struct cleanup *cleanup;
+
+    if (current_user_process != NULL) {
+	/* Process already debugged.  */
+	if (! from_tty)
+	    return;
+
+	/* Update the process information.  */
+	delete_user_process(current_user_process->gdb_thread_id);
+    }
+
+    cleanup = make_cleanup (restore_breakpoints, breakpoint_chain);
+    /* We don't won't bps to get reevaluated by the symbol_file_add().
+       It causes errors. because symbols aren't visible from one user
+       processto another. */
+    breakpoint_chain = NULL;
+
+    if (from_tty)
+	printf_filtered ("Comm: %s (pid %i)\n", ps->comm, ps->pid);
+
+    if (! mm) {
+	if (from_tty)
+	    printf_filtered ("This is a kernel thread.\n");
+	do_cleanups (cleanup);
+	return;
+    }
+
+    /* Remove trailing whitespaces.  */
+    sanitize_target_root_prefix();
+
+    if (**target_root_prefix == '\0')
+	error ("\
+You haven't set the prefix where to look for target binaries.\n\
+Use 'set target-root-prefix'.");
+
+    filename = get_proc_exe (mm);
+    if (filename == NULL) {
+	error ("Couldn't find the process executable path.");
+    }
+
+    filename = xrealloc (filename,
+			 strlen (filename) + strlen (*target_root_prefix) + 1);
+    memmove (filename + strlen (*target_root_prefix),
+	     filename,
+	     strlen (filename)+1);
+    memcpy (filename, *target_root_prefix, strlen(*target_root_prefix));
+    if (from_tty)
+	printf_filtered ("Target exe: %s\n", filename);
+
+    abfd = bfd_openr (filename, gnutarget);
+    if (!abfd) {
+	if (from_tty)
+	    printf_filtered ("Could not open `%s' as an executable file: %s",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	xfree (filename);
+	do_cleanups (cleanup);
+	return;
+    }
+    /* FIXME : use make_cleanup */
+    if (!bfd_check_format (abfd, bfd_object)) {
+	bfd_close (abfd);
+	if (from_tty)
+	    printf_filtered ("\"%s\": not in executable format: %s.",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	xfree (filename);
+	do_cleanups (cleanup);
+	return;
+    }
+
+    if (strcmp (bfd_get_target (abfd), bfd_get_target (exec_bfd))) {
+	bfd_close (abfd);
+	if (from_tty)
+	    printf_filtered ("\"%s\": wrong architecture (%s should be %s).",
+			     filename, bfd_get_target (abfd),
+			     bfd_get_target (exec_bfd));
+	xfree (filename);
+	do_cleanups (cleanup);
+	return;
+    }
+    bfd_close (abfd);
+    xfree (filename);
+    mmap = read_pointer_field (mm, MM_STRUCT__MMAP);
+
+    while (mmap) {
+	CORE_ADDR file;
+#define VM_EXEC		0x00000004
+
+	unsigned int flags;
+	CORE_ADDR start;
+
+	flags = read_unsigned_field (mmap, VM_AREA_STRUCT__VM_FLAGS);
+	start = read_pointer_field (mmap, VM_AREA_STRUCT__VM_START);
+	file = read_pointer_field (mmap, VM_AREA_STRUCT__VM_FILE);
+
+	if (! (flags & VM_EXEC))
+	    goto next;
+
+	file = read_pointer_field (mmap, VM_AREA_STRUCT__VM_FILE);
+	if (! file)
+	    goto next;
+
+	dentry = read_pointer_field (file, FILE__F_DENTRY);
+	filename = read_dentry (dentry);
+	if (filename == NULL)
+	    goto next;
+
+	/* FIXME copied from above */
+	filename = xrealloc (filename,
+			     strlen (filename)
+			     + strlen (*target_root_prefix) + 1);
+	memmove (filename + strlen(*target_root_prefix),
+		 filename,
+		 strlen (filename)+1);
+	memcpy (filename, *target_root_prefix, strlen (*target_root_prefix));
+
+	abfd = bfd_openr (filename, gnutarget);
+	if (!abfd) {
+	    printf_filtered ("Could not open `%s' as an executable file: %s",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	    do_cleanups (cleanup);
+	    return;
+	}
+
+	if (!bfd_check_format (abfd, bfd_object)) {
+	    printf_filtered ("\"%s\": not in executable format: %s.",
+			     filename, bfd_errmsg (bfd_get_error ()));
+	    do_cleanups (cleanup);
+	    return;
+	}
+
+	if (strcmp(bfd_get_target(abfd), bfd_get_target(exec_bfd))) {
+	    printf_filtered ("\"%s\": wrong architecture (%s should be %s).",
+			     filename, bfd_get_target(abfd),
+			     bfd_get_target(exec_bfd));
+	    do_cleanups (cleanup);
+	    return;
+	}
+
+	sect = bfd_get_section_by_name (abfd, ".text");
+
+	if (sect == NULL)
+	    goto next;
+
+	if (flags & VM_EXECUTABLE)
+	    start = 0;
+
+	addrs.other[0].addr = bfd_get_section_vma (abfd, sect) + start;
+	addrs.other[0].sectindex = sect->index;
+
+	DEBUG (USER, 2, "Addresses vma %s start %s  sum %s\n",
+	       paddr (bfd_get_section_vma (abfd, sect)),
+	       paddr (start),
+	       paddr (addrs.other[0].addr));
+
+	objfile = symbol_file_add (filename, from_tty,
+				   &addrs, 0, OBJF_USERLOADED);
+	if (objfiles == NULL)
+	    objfiles = objfile;
+
+	if (flags & VM_EXECUTABLE)
+	    main_objfile = objfile;
+
+	ALL_OBJFILE_PSYMTABS (objfile, psymtab) {
+	    if (!dwarf2_psymtab_to_symtab)
+		dwarf2_psymtab_to_symtab = psymtab->read_symtab;
+
+	    if (dwarf2_psymtab_to_symtab != psymtab->read_symtab)
+		warning ("Your kernel doesn't use Dwarf2 debug info ?!");
+	    else
+		psymtab->read_symtab = linux_aware_read_symtab;
+
+	    if (psymtab->dirname
+		&& stat(psymtab->dirname, &stat_struct) == -1) {
+		char *host_dir = xstrprintf ("%s/%s",
+					     *target_root_prefix,
+					     psymtab->dirname);
+
+		if (stat (host_dir, &stat_struct) == 0) {
+		    psymtab->dirname = (char *)
+			obstack_alloc (&objfile->objfile_obstack,
+				       strlen (host_dir) + 1);
+		    strcpy (psymtab->dirname, host_dir);
+		}
+
+		xfree (host_dir);
+	    }
+	}
+
+	bfd_close (abfd);
+	xfree (filename);
+
+    next:
+	mmap = read_pointer_field (mmap, VM_AREA_STRUCT__VM_NEXT);
+    }
+
+    /* We must restore the breakpoint_chain before adding the new
+       debugged_user_process, because that might add a breakpoint to
+       the chain. */
+    do_cleanups (cleanup);
+
+    new_debugged_user_process (ps, objfiles, main_objfile);
+
+    if (from_tty) {
+	flush_cached_frames ();
+	print_stack_frame (get_current_frame (), 1, SRC_AND_LOC);
+    }
+}
+
+void
+linux_read_process_symbols ()
+{
+    if (auto_debug_process)
+	debug_process_command (NULL, 0);
+}
+
+static void
+set_loaded (char *arg, int from_tty,
+	    struct cmd_list_element *c)
+{
+    static int currently_loaded = 0;
+
+    if (use_linux_awareness) {
+	if (loaded && loaded != currently_loaded) {
+	    char* banner1 = get_banner ();
+	    char* banner2 = get_banner_from_file ();
+	    struct process *ps;
+
+	    if (banner1 == NULL
+		|| banner2 == NULL
+		|| strcmp (banner1, banner2)) {
+		if (! nquery("\
+The debugger can't find the linux version string stored in your binary image\n\
+in the the current kernel's memory. The file claims to be: \n%s\n\
+Do you still want to continue (if the kernels don't match, it might crash the\n\
+debugger)? ", banner2)) {
+		    loaded = 0;
+		    error ("Aborted.");
+		}
+	    }
+
+	    /* Set current ptids. */
+	    ps = get_current_process ();
+	    current_ptid = linux_aware_pid_to_ptid (ps->pid);
+	    inferior_ptid = current_ptid;
+	    DEBUG (TASK, 2, "current_ptid: %i inferior_ptid: %i\n",
+		   PIDGET (current_ptid), PIDGET (inferior_ptid));
+
+	    if (!in_thread_list (current_ptid)) {
+		add_thread (current_ptid);
+	    }
+
+	    /* Read module list. */
+	    solib_add (NULL, from_tty, (struct target_ops *) 0, 1);
+	    /* Let the linux-awareness target part believe that we've run. */
+	    linux_awareness_ops->lo_clear_cache ();
+	}
+        currently_loaded = loaded;
+    }
+}
+
+static void
+linux_aware_create_breakpoint_hook (struct breakpoint *bpt)
+{
+    struct lm_info *info;
+    if (bpt->loc->address == ~(CORE_ADDR)0) {
+	if (! resetting_bps_after_init) {
+	    warning("\
+You've inserted a breakpoint on a location that isn't currently\n\
+mapped to memory (it's flagged as __init code and the initialization\n\
+phase of its module is over). The breakpoint will be re-set if you\n\
+reload that module.");
+	} else if (resetting_bps_after_init == 1) {
+	    warning("\
+Disabling breakpoints that are in .init section (they will be re-set if\n\
+you reload that module):");
+	    resetting_bps_after_init = 2;
+	}
+	/* This is certainly totally useless because enable states
+	   will be restored in breakpoint_re_set_one. I let it because
+	   it explains what wwe try to do, but we still have to ignore
+	   those bps in (insert,remove)_breakpoint */
+	bpt->enable_state = bp_shlib_disabled;
+    } else if (bpt->loc->address
+	       && bpt->loc->loc_type == bp_loc_software_breakpoint
+	       && linux_awareness_ops->lo_is_user_address (bpt->loc->address)) {
+	CORE_ADDR addr = bpt->loc->address;
+	bpt->thread = pid_to_thread_id (inferior_ptid);
+	if (! translate_memory_address_safe (&addr, 1)) {
+	    disable_breakpoint (bpt);
+	    set_nopage_watchpoint (bpt, addr);
+	}
+
+	if (HAS_ADDR (DO_EXIT)) {
+	    if (thread_event_do_exit_bp == NULL)
+		thread_event_do_exit_bp = create_thread_event_breakpoint (ADDR (DO_EXIT));
+	} else
+	    warning ("'do_exit' wasn't found.");
+
+	if (HAS_ADDR (TRY_TO_UNMAP)) {
+	    if (thread_event_low_mem_bp == NULL)
+		thread_event_low_mem_bp = create_thread_event_breakpoint (ADDR (TRY_TO_UNMAP));
+	} else
+	    warning ("'try_to_unmap' wasn't found.");
+    }
+
+    if (deprecated_create_breakpoint_chain)
+	deprecated_create_breakpoint_chain (bpt);
+}
+
+static void
+linux_aware_delete_breakpoint_hook (struct breakpoint *bpt)
+{
+    struct monitored_page **page = &monitored_pages, *p;
+    struct bp_list **bps, *bp;
+
+    while (*page) {
+	if ((*page)->watchpoint == bpt) {
+	    /* FIXME : we leak the bp_list */
+	    p = *page;
+	    *page = (*page)->next;
+	    xfree (p);
+	    break;
+	}
+
+	bps = &(*page)->bps;
+	while (*bps) {
+	    if ((*bps)->b == bpt) {
+		bp = *bps;
+		*bps = (*bps)->next;
+		xfree (bp);
+		create_watchpoint_commands (*page);
+		goto end;
+	    }
+	    bps = &(*bps)->next;
+	}
+
+	page = &(*page)->next;
+    }
+
+end:
+    if (deprecated_delete_breakpoint_chain)
+	deprecated_delete_breakpoint_chain (bpt);
+}
+
+static void
+find_min_load_addr (bfd *abfd, asection *sectp, void *addr)
+{
+    CORE_ADDR *min_addr = addr;
+    CORE_ADDR vma;
+
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_ALLOC))
+	return;
+    if (! (bfd_get_section_flags (abfd, sectp) & SEC_HAS_CONTENTS))
+	return;
+
+    vma = bfd_get_section_vma (abfd, sectp);
+    if (vma < *min_addr)
+	*min_addr = vma;
+}
+
+/*
+ * The functionalities that can be built as modules often have a
+ * cleanup routine (marked with module_exit). When the driver is built
+ * into the kernel (ie. not as a module), the cleanup routines aren't
+ * linked in, but their debug information remains... These routines
+ * all have very low addresses (as they haven't been relocated). This
+ * functions try to partially fix the debug info, so that the psymtabs
+ * don't adverise a too wide range of text addresses.
+ */
+static void
+linux_awareness_fix_debug_info ()
+{
+    CORE_ADDR min_load_addr = (CORE_ADDR)-1;
+    struct partial_symtab *pst;
+
+    if (!exec_bfd || !symfile_objfile)
+	return;
+
+    bfd_map_over_sections (exec_bfd, find_min_load_addr, &min_load_addr);
+
+    ALL_OBJFILE_PSYMTABS (symfile_objfile, pst) {
+	if (pst->textlow < min_load_addr)
+	    pst->textlow = min_load_addr;
+    }
+}
+
+static int
+linux_aware_inner_than (CORE_ADDR lhs, CORE_ADDR rhs)
+{
+    if (linux_awareness_ops->lo_is_kernel_address (rhs)
+	&& linux_awareness_ops->lo_is_user_address (lhs))
+	return 0;
+
+    return core_addr_lessthan (lhs, rhs);
+}
+
+static void
+add_module_search_path_command (char *args, int from_tty)
+{
+    mod_path (args, module_search_path);
+}
+
+static void
+linux_awareness_init ()
+{
+    int ret;
+    struct cmd_list_element *c;
+    static char solib_search_path_1[] = "solib-search-path";
+    char *solib_search_path = solib_search_path_1;
+    static char solib_absolute_prefix_1[] = "solib-absolute-prefix";
+    char *solib_absolute_prefix = solib_absolute_prefix_1;
+    static char linux_awareness_postinit_1[] = "linux-awareness-postinit";
+    char *linux_awareness_postinit = linux_awareness_postinit_1;
+
+    DEBUG (INIT, 1,"Initing linux-aware stratum.\n");
+
+    /* Make sure KGDB patches don't get in the way. */
+    extern int debugkernel;
+    debugkernel = 0;
+
+    linux_init_addresses (linux_addrs);
+    linux_awareness_ops->lo_init ();
+    init_linux_fields (linux_fields);
+
+    printf_filtered ("Enabling Linux kernel awareness layer [Build %s].\n",
+		     __DATE__);
+
+    linux_awareness_fix_debug_info ();
+
+    old_so_ops = current_target_so_ops;
+    current_target_so_ops = &linux_aware_so_ops;
+    linux_aware_solib_create_inferior_hook ();
+
+    if (target_has_registers) {
+	/* Forced load of the layer */
+	linux_aware_ops.to_has_registers = target_has_registers;
+	linux_aware_ops.to_has_execution = target_has_execution;
+	linux_aware_ops.to_has_stack = target_has_stack;
+	loaded = 1; set_loaded (0,0,0);
+    }
+
+    ret = push_target (&linux_aware_ops);
+    if (ret) {
+	warning ("The linux-aware stratum target wasn't pushed on the top !\n");
+    }
+
+    normal_stop_observer = observer_attach_normal_stop (normal_stop_callback);
+
+    set_main_name ("start_kernel");
+
+    /* Add single-stepping if needed */
+    if (!SOFTWARE_SINGLE_STEP_P ()
+	&& linux_awareness_ops->lo_single_step_destination) {
+	/* This isn;t very nice. See gdbarch.h:SOFTWARE_SINGLE_STEP for
+	   some comments which would make that easier/nicer */
+	set_gdbarch_software_single_step (current_gdbarch,
+					  linux_aware_software_single_step);
+    }
+
+    set_gdbarch_inner_than (current_gdbarch, linux_aware_inner_than);
+
+    c = lookup_cmd (&solib_search_path, setlist, "", 1, 1);
+    if (c != NULL) {
+	module_search_path = c->var;
+	if (*module_search_path == NULL) {
+	    /* mod_path will choke on it otherwise. */
+	    *module_search_path = xmalloc (1);
+	    **module_search_path = '\0';
+	}
+
+    } else {
+	warning ("Could not find 'set solib-search-path' command");
+    }
+    add_alias_cmd ("module-search-path", "solib-search-path",
+		   no_class, 0, &setlist);
+    add_alias_cmd ("module-search-path", "solib-search-path",
+		   no_class, 0, &showlist);
+
+    c = lookup_cmd (&solib_absolute_prefix, setlist, "", 1, 1);
+    if (c != NULL)
+	target_root_prefix = c->var;
+    else
+	warning ("Could not find 'set solib-absolute-prefix' command");
+
+    add_alias_cmd ("target-root-prefix", "solib-absolute-prefix",
+		   no_class, 0, &setlist);
+    add_alias_cmd ("target-root-prefix", "solib-absolute-prefix",
+		   no_class, 0, &showlist);
+
+    add_alias_cmd ("modules", "sharedlibrary", no_class, 0, &infolist);
+    add_alias_cmd ("tasks", "threads", no_class, 0, &infolist);
+    add_alias_cmd ("task", "thread", no_class, 0, &cmdlist);
+
+    add_cmd ("struct_definitions", class_obscure, struct_definitions,"\
+Print the list commands to setup the current struct definitions.\n\
+Takes the file to print to as an optional argument. The standard output is\n\
+used if no argument is provided.\n\
+This can be used to generate a script for the debug of a kernel without\n\
+debug information, but built with an identical set of options as the current\n\
+one.", &show_linux_awareness_cmd_list);
+
+    add_com ("running_task", class_obscure, running_task_command,
+	     "Switch to the currently running task.");
+
+    add_com ("dmesg", class_obscure, dmesg_command,
+	     "Print the contents of the linux log buffer.");
+
+    add_com ("process_info", class_obscure, process_info_command,
+	     "Print various info about the current process.");
+
+    add_com ("pmap", class_obscure, pmap_command,
+	     "Print the memory map of the current process.");
+
+    add_com ("vm_translate", class_obscure, vm_translate_command,
+	     "Translate a virtual address to a physical one.");
+
+    add_com ("ipcs", class_obscure, ipcs_command,
+	     "Print various info about the IPC structures.");
+
+    add_com ("proc_ioports", class_obscure, ioports_command,
+	     "Print the I/O ports map.");
+
+    add_com ("proc_iomem", class_obscure, iomem_command,
+	     "Print the I/O mem map.");
+
+    add_com ("proc_interrupts", class_obscure, interrupts_command,
+	     "Print interrupt statistics.");
+
+    add_com ("proc_version", class_obscure, proc_version_command,
+	     "Print the contents of /proc/version.");
+
+    add_com ("proc_cmdline", class_obscure, proc_cmdline_command,
+	     "Print the contents of /proc/cmdline.");
+
+    add_com ("proc_mounts", class_obscure, proc_mounts_command,
+	     "Print the contents of /proc/mounts.");
+
+    add_com ("proc_meminfo", class_obscure, proc_meminfo_command,
+	     "Print the contents of /proc/meminfo.");
+
+    add_com ("debug_process", class_obscure, debug_process_command,
+	     "Allow to debug the current userspace process. "
+	     "This will load the required symbols.");
+
+    add_com ("wait_exe", class_obscure, wait_exe_command,
+	     "Make the debugger execute a list of commands when a given "
+	     "executable is exec'd");
+
+    add_com ("wait_page", class_obscure, wait_page_command,
+	     "Make the debugger stop when a given page is mapped to memory.");
+
+    add_com ("add-module-search-path", no_class,
+	     add_module_search_path_command,
+	     "Append a module search path to the current one.");
+
+    add_setshow_uinteger_cmd ("log_chunk_size",
+			      class_obscure,
+			      &log_chunk_size,
+			      "Set the size of the chunks used while reading log_buf",
+			     "Show the size of the chunks used while reading log_buf",
+			      NULL, NULL, NULL,
+			      &set_linux_awareness_cmd_list,
+			      &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("loaded",
+			     class_obscure,
+			     &loaded,
+			     "Set the loaded state of the kernel image",
+			     "Show the loaded state of the kernel image",
+			     NULL, &set_loaded, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    deprecated_create_breakpoint_chain = deprecated_create_breakpoint_hook;
+    deprecated_create_breakpoint_hook = linux_aware_create_breakpoint_hook;
+    deprecated_delete_breakpoint_chain = deprecated_delete_breakpoint_hook;
+    deprecated_delete_breakpoint_hook = linux_aware_delete_breakpoint_hook;
+    deprecated_context_chain = deprecated_context_hook;
+    deprecated_context_hook = linux_aware_context_hook;
+
+    c = lookup_cmd (&linux_awareness_postinit, cmdlist, "", 1, 1);
+    if (c != NULL && c->class == class_user)
+	execute_user_command (c, 0);
+}
+
+static void
+linux_aware_close (int quitting)
+{
+    struct target_waitstatus dummy;
+    DEBUG (TARGET, 3,"Closing... (quitting = %i)\n", quitting);
+
+    /* We might be called by a signal handler */
+    if (running) {
+	target_stop ();
+	if (linux_aware_ops.beneath != NULL
+	    && linux_aware_ops.beneath->to_wait != NULL)
+	    linux_aware_ops.beneath->to_wait (minus_one_ptid, &dummy);
+    }
+
+    current_target_so_ops = old_so_ops;
+    old_so_ops = NULL;
+    use_linux_awareness = 0;
+    loaded = 0;
+
+    if (normal_stop_observer) {
+	observer_detach_normal_stop (normal_stop_observer);
+	normal_stop_observer = NULL;
+    }
+
+    delete_cmd ("module-search-path", &setlist);
+    delete_cmd ("module-search-path", &showlist);
+    delete_cmd ("target-root-prefix", &setlist);
+    delete_cmd ("target-root-prefix", &showlist);
+    delete_cmd ("modules", &infolist);
+    delete_cmd ("tasks", &infolist);
+    delete_cmd ("task", &cmdlist);
+    delete_cmd ("dmesg", &cmdlist);
+    delete_cmd ("process_info", &cmdlist);
+    delete_cmd ("pmap", &cmdlist);
+    delete_cmd ("vm_translate", &cmdlist);
+    delete_cmd ("ipcs", &cmdlist);
+    delete_cmd ("proc_ioports", &cmdlist);
+    delete_cmd ("proc_iomem", &cmdlist);
+    delete_cmd ("proc_interrupts", &cmdlist);
+    delete_cmd ("proc_mounts", &cmdlist);
+    delete_cmd ("proc_cmdline", &cmdlist);
+    delete_cmd ("proc_version", &cmdlist);
+    delete_cmd ("running_task", &cmdlist);
+
+    delete_cmd ("log_chunk_size", &set_linux_awareness_cmd_list);
+    delete_cmd ("log_chunk_size", &show_linux_awareness_cmd_list);
+    delete_cmd ("loaded", &set_linux_awareness_cmd_list);
+    delete_cmd ("loaded", &show_linux_awareness_cmd_list);
+
+    current_ptid = minus_one_ptid;
+    disable_breakpoint_at_pc = 0;
+    _inhibit_thread_register_awareness = 0;
+
+    init_module_return_resolved = 0;
+
+    if (shlib_event_load_bp) {
+	delete_breakpoint (shlib_event_load_bp);
+	shlib_event_load_bp = NULL;
+    }
+
+    if (shlib_event_init_bp) {
+	delete_breakpoint (shlib_event_init_bp);
+	shlib_event_init_bp = NULL;
+    }
+
+    if (shlib_event_free_bp) {
+	delete_breakpoint (shlib_event_free_bp);
+	shlib_event_free_bp = NULL;
+    }
+
+    if (thread_event_do_exit_bp) {
+	delete_breakpoint (thread_event_do_exit_bp);
+	thread_event_do_exit_bp = NULL;
+    }
+
+    if (thread_event_low_mem_bp) {
+	delete_breakpoint (thread_event_low_mem_bp);
+	thread_event_low_mem_bp = NULL;
+    }
+
+    if (linux_awareness_ops->lo_close)
+	linux_awareness_ops->lo_close ();
+
+    delete_temp_files ();
+
+    thread_list_clear_cache ();
+    reinit_linux_fields ();
+    linux_free_addresses (linux_addrs);
+
+    if (running) {
+	/* If we leave the board run, we'd better remove breakpoints
+	   so that it's functional. */
+	/* FIXME : we should do that before we reset
+	   disable_breakpoint_at_pc */
+	remove_breakpoints ();
+
+	if (linux_aware_ops.beneath != NULL
+	    && linux_aware_ops.beneath->to_resume != NULL)
+	    linux_aware_ops.beneath->to_resume (inferior_ptid, 0, 0);
+    }
+
+    if (quitting) {
+	if (current_target.to_mourn_inferior != noprocess) {
+	    target_mourn_inferior ();
+	    if (linux_aware_ops.beneath != NULL
+		&& linux_aware_ops.beneath->to_close != NULL)
+		linux_aware_ops.beneath->to_close (quitting);
+	}
+    }
+
+    running = 0;
+}
+
+static void
+linux_awareness_set (char *args, int from_tty,
+		     struct cmd_list_element *c)
+{
+    int ret;
+
+    static int active = 0;
+
+    if (use_linux_awareness == active)
+	return;
+
+    active = use_linux_awareness;
+
+    if (use_linux_awareness) {
+	/* calls push_target(&linux_aware_ops) after some more init */
+	linux_awareness_init ();
+    } else if (linux_aware_ops.beneath != NULL) {
+	/* The target hasn't been closed yet */
+	DEBUG (INIT, 1,"Unpushing linux-aware stratum.\n");
+	ret = unpush_target (&linux_aware_ops);
+	if (ret != 1) {
+	    warning ("\
+The linux-aware target wasn't unpushed from the target stack !\n");
+	}
+    }
+}
+
+static void
+linux_aware_call_command (struct cmd_list_element *c,
+			  char *arg, int from_tty)
+{
+    static char *quit = "quit";
+    static const struct cmd_list_element *quit_cmd;
+
+    if (quit_cmd == NULL)
+	quit_cmd = lookup_cmd (&quit, cmdlist, "", 1, 1);
+
+    if (from_tty && c != quit_cmd) {
+	warning ("\
+You seem to be trying to debug a Linux Kernel, but your binary is missing\n\
+debug information. The linux awareness layer didn't load itself. You can\n\
+force the load by issuing: 'set linux-awareness enabled on'.");
+	deprecated_call_command_hook = deprecated_call_command_chain;
+    }
+
+    if (deprecated_call_command_chain)
+	deprecated_call_command_chain (c, arg, from_tty);
+    else
+	cmd_func (c, arg, from_tty);
+}
+
+static int
+linux_awareness_auto_activate_lookup_symbol(const char *name)
+{
+    int found = lookup_minimal_symbol (name, NULL, NULL) != NULL;
+
+    if (!found)
+	DEBUG (INIT, 1, "Symbol '%s' not found\n", name);
+    else
+	DEBUG (INIT, 2, "Symbol '%s' found\n", name);
+
+    return found;
+}
+
+static int
+linux_awareness_auto_activate_lookup_symtab(const char *name)
+{
+    int found = lookup_symtab (name) != NULL;
+
+    if (!found)
+	DEBUG (INIT, 1, "Symtab '%s' not found\n", name);
+    else
+	DEBUG (INIT, 2, "Symtab '%s' found\n", name);
+
+    return found;
+}
+
+static void
+linux_awareness_auto_activate (struct objfile *objf)
+{
+    unsigned int i = 0;
+    asection *sect;
+
+    DEBUG (INIT, 2, "linux_awareness_auto_activate(%s)\n", objf ? objf->name : "null");
+
+    if (!linux_awareness_auto_activate_p
+	|| objf == NULL
+	|| objf != symfile_objfile)
+	return;
+
+    autodetection = NOT_LINUX;
+
+    sect = bfd_get_section_by_name (symfile_objfile->obfd, ".empty_zero_page");
+    if (!sect
+	||  bfd_get_section_size(sect) != (1<<linux_awareness_ops->page_shift)
+	|| ! linux_awareness_auto_activate_lookup_symbol ("schedule")
+	|| ! linux_awareness_auto_activate_lookup_symbol ("linux_banner")
+	|| ! linux_awareness_auto_activate_lookup_symbol ("system_utsname"))
+	return;
+
+    autodetection = LINUX_WITHOUT_DEBUGINFO;
+    lookup_symtab ("page_io.c");
+    /* load some data that GDB seems to loose otherwise */
+    if (linux_awareness_auto_activate_lookup_symtab ("mmap.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("fork.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("sched.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("block_dev.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("vmalloc.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("page_alloc.c")
+	&& linux_awareness_auto_activate_lookup_symtab ("fs/buffer.c")
+	&& linux_awareness_ops->lo_check ())
+	autodetection = LINUX_WITH_DEBUGINFO;
+
+    if (autodetection == LINUX_WITHOUT_DEBUGINFO) {
+	if (! deprecated_call_command_chain)
+	    deprecated_call_command_chain = deprecated_call_command_hook;
+	deprecated_call_command_hook = linux_aware_call_command;
+	return;
+    }
+
+    if (autodetection != LINUX_WITH_DEBUGINFO)
+	return;
+
+    use_linux_awareness = 1;
+    linux_awareness_set (0,0,0);
+}
+
+static void
+set_linux_awareness (char *arg, int from_tty)
+{
+  printf_unfiltered ("\
+'set linux-awareness' must be followed by the name of a print subcommand.\n");
+  help_list (set_linux_awareness_cmd_list,
+	     "set linux-awareness ", -1, gdb_stdout);
+}
+
+static void
+show_linux_awareness (char *args, int from_tty)
+{
+  cmd_show_list (show_linux_awareness_cmd_list, from_tty, "");
+}
+
+static void
+set_global_loglevel (char *arg, int from_tty,
+		     struct cmd_list_element *c)
+{
+    struct debug_domain* domain = linux_aware_debug_domains_info;
+
+    while (domain->name != NULL)
+	domain++->level = global_loglevel;
+}
+
+static void
+init_linux_aware_target ()
+{
+    DEBUG (INIT, 3, "Overloading %s\n", current_target.to_longname);
+
+    linux_aware_ops.to_shortname = "linux-aware";
+    linux_aware_ops.to_longname = "Linux-aware target interface";
+    linux_aware_ops.to_doc = linux_awareness_doc;
+    linux_aware_ops.to_stratum = thread_stratum;
+    linux_aware_ops.to_load = &linux_aware_load;
+    linux_aware_ops.to_close = &linux_aware_close;
+    linux_aware_ops.to_attach = &linux_aware_attach;
+    linux_aware_ops.to_can_run = &linux_aware_can_run;
+    linux_aware_ops.to_magic = OPS_MAGIC;
+
+    /* Breakpoints */
+    linux_aware_ops.to_insert_breakpoint = &linux_aware_insert_breakpoint;
+    linux_aware_ops.to_remove_breakpoint = &linux_aware_remove_breakpoint;
+    linux_aware_ops.to_insert_hw_breakpoint = &linux_aware_insert_hw_breakpoint;
+    linux_aware_ops.to_remove_hw_breakpoint = &linux_aware_remove_hw_breakpoint;
+
+    /* ?? Watchpoints ?? */
+
+    /* Memory */
+    linux_aware_ops.deprecated_xfer_memory = &linux_aware_deprecated_xfer_memory;
+
+    /* Registers */
+    linux_aware_ops.to_fetch_registers = &linux_aware_fetch_registers;
+    linux_aware_ops.to_store_registers = &linux_aware_store_registers;
+
+    /* Execution */
+    linux_aware_ops.to_resume = &linux_aware_resume;
+    linux_aware_ops.to_wait = &linux_aware_wait;
+
+    /* Threads */
+    linux_aware_ops.to_thread_alive = &linux_aware_thread_alive;
+    linux_aware_ops.to_find_new_threads = &linux_aware_find_new_threads;
+    linux_aware_ops.to_pid_to_str = &linux_aware_pid_to_str;
+    linux_aware_ops.to_extra_thread_info = &linux_aware_extra_thread_info;
+    linux_aware_ops.to_has_thread_control = tc_schedlock;
+}
+
+void
+_initialize_linux_awareness (void)
+{
+    static struct cmd_list_element *c;
+    struct debug_domain *domain;
+
+    tmpdir = getenv("TMPDIR");
+
+    deprecated_target_new_objfile_hook = linux_awareness_auto_activate;
+
+    init_linux_aware_target ();
+    add_target (&linux_aware_ops);
+    init_so_ops ();
+
+    add_prefix_cmd ("linux-awareness",
+		    class_obscure,
+		    set_linux_awareness,
+		    "Command for setting linux-awareness variables",
+		    &set_linux_awareness_cmd_list,
+		    "set linux-awareness ",
+		    0, &setlist);
+
+    add_prefix_cmd ("linux-awareness",
+		    class_obscure,
+		    show_linux_awareness,
+		    "Command for showing linux-awareness variables",
+		    &show_linux_awareness_cmd_list,
+		    "show linux-awareness ",
+		    0, &showlist);
+
+    add_setshow_boolean_cmd ("enabled",
+			     class_obscure,
+			     &use_linux_awareness,
+			     "Set the activation state of the the linux awareness layer",
+			     "Show the activation state of the the linux awareness layer",
+			     NULL, &linux_awareness_set, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    domain = linux_aware_debug_domains_info;
+
+    while (domain->name != NULL) {
+	static const char fmt[] = "%s the debug level of the linux awareness layer %s part.";
+	const char *name = domain->name + 6; /* Skip debug- */
+	char *help_set = xstrprintf (fmt, "Set", name);
+	char *help_show = xstrprintf (fmt, "Show", name);
+	add_setshow_zinteger_cmd ((char*)domain->name,
+				  class_obscure,
+				  &(domain->level),
+				  help_set,
+				  help_show,
+				  NULL,
+				  NULL, NULL,
+				  &set_linux_awareness_cmd_list,
+				  &show_linux_awareness_cmd_list);
+	xfree (help_set);
+	xfree (help_show);
+	++domain;
+    }
+
+    add_setshow_zinteger_cmd ("debug-all",
+			      class_obscure,
+			      &global_loglevel,
+			      "Set the debug level of the linux awareness layer",
+			      "Show the debug level of the linux awareness layer",
+			      NULL,
+			      &set_global_loglevel, NULL,
+			      &set_linux_awareness_cmd_list,
+			      &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("enable_vm_translation",
+			     class_obscure,
+			     &enable_vm_translation,
+			     "Set wether we try to translate virtual addresses into physical ones",
+			     "Show wether we try to translate virtual addresses into physical ones",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("enable_task_awareness",
+			     class_obscure,
+			     &enable_task_awareness,
+			     "Set wether we implement task awareness",
+			     "Show wether we implement task awareness",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("auto_activate",
+			     class_obscure,
+			     &linux_awareness_auto_activate_p,
+			     "Set wether we try to autodetect linux kernels.",
+			     "Show wether we try to autodetect linux kernels.",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+
+    add_setshow_boolean_cmd ("auto_debug_process",
+			     class_obscure,
+			     &auto_debug_process,
+			     "Set wether we try to automatically load information for userspace processes.",
+			     "Show wether we try to automatically load information for userspace processes.",
+			     NULL, NULL, NULL,
+			     &set_linux_awareness_cmd_list,
+			     &show_linux_awareness_cmd_list);
+}
Index: gdb-6.5/gdb/linux-awareness.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ gdb-6.5/gdb/linux-awareness.h	2007-10-24 16:22:45.000000000 +0100
@@ -0,0 +1,96 @@
+
+struct type;
+struct cmd_list_element;
+
+extern struct cmd_list_element *set_linux_awareness_cmd_list;
+extern struct cmd_list_element *show_linux_awareness_cmd_list;
+
+struct addr_info {
+    char *name;
+    struct minimal_symbol* sym;
+    CORE_ADDR* addr;
+};
+
+struct field_info {
+    char          *struct_name;
+    char          *field_name;
+    int            default_offset;
+    int            default_size;
+    struct symbol *type;
+    int           *offset;
+    int           *size;
+};
+
+enum page_status {
+    PAGE_PRESENT,
+    PAGE_SWAPPED,
+    PAGE_NOTMAPPED,
+    PAGE_NOPAGE,
+    PAGE_UNKNOWN
+};
+
+struct linux_awareness_ops {
+    const char *name;
+    int (*lo_check)();
+    int (*lo_init)();
+    void (*lo_close)();
+    int (*lo_address_needs_translation)(CORE_ADDR addr);
+    enum page_status (*lo_translate_memory_address)(CORE_ADDR *addr,
+						    CORE_ADDR task_struct);
+    CORE_ADDR (*lo_translate_memory_watch_address)(CORE_ADDR addr,
+						   CORE_ADDR task_struct);
+    int (*lo_can_write)(CORE_ADDR addr, CORE_ADDR task_struct);
+    int (*lo_is_user_address)(CORE_ADDR addr);
+    int (*lo_is_kernel_address)(CORE_ADDR addr);
+    void (*lo_flush_cache)(CORE_ADDR virtaddr, CORE_ADDR physaddr,
+			   int len, int write);
+    CORE_ADDR (*lo_single_step_destination)(CORE_ADDR pc);
+    void (*lo_clear_cache)();
+
+    CORE_ADDR (*lo_first_pointer_arg_value)();
+    CORE_ADDR (*lo_return_address_at_start_of_function)();
+    CORE_ADDR (*lo_current_task_struct_address)();
+    CORE_ADDR (*lo_current_thread_info_address)();
+    int (*lo_fetch_context_register)(int regno, CORE_ADDR task_struct);
+    int (*lo_store_context_register)(int regno, CORE_ADDR task_struct);
+
+    int page_shift;
+};
+
+extern struct linux_awareness_ops *linux_awareness_ops;
+
+struct debug_domain {
+    const char *name;
+    int         level;
+};
+
+extern struct debug_domain linux_aware_debug_domains_info[];
+
+enum linux_aware_debug_domain {
+    VM,
+    TASK,
+    MODULE,
+    TARGET,
+    INIT,
+    USER,
+    KEEP_LAST
+};
+
+#define DEBUG(domain, l, ...) \
+    ({if (domain < KEEP_LAST \
+        && linux_aware_debug_domains_info[domain].level >= l) \
+        fprintf_filtered(gdb_stdlog, "[linux] " __VA_ARGS__);})
+
+int linux_check_addresses (struct addr_info *addr);
+int linux_init_addresses (struct addr_info *addr);
+void linux_free_addresses (struct addr_info *info);
+CORE_ADDR linux_get_address (struct addr_info *addr);
+
+int linux_check_fields (struct field_info *field);
+int linux_init_fields (struct field_info *field);
+void linux_free_fields (struct field_info *field);
+unsigned int linux_get_field_offset (struct field_info *field);
+unsigned int linux_get_field_size (struct field_info *field);
+void linux_certify_field (struct field_info *field);
+
+void linux_read_process_symbols ();
Index: gdb-6.5/gdb/linux-awareness-sh4.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ gdb-6.5/gdb/linux-awareness-sh4.c	2007-10-24 16:22:45.000000000 +0100
@@ -0,0 +1,1846 @@
+
+#include "defs.h"
+#include "block.h"
+#include "command.h"
+#include "frame.h"
+#include "frame-unwind.h"
+#include "gdb_assert.h"
+#include "gdbarch.h"
+#include "gdbcore.h"
+#include "gdbtypes.h"
+#include "gdb_obstack.h"
+#include "inferior.h"
+#include "regcache.h"
+#include "user-regs.h"
+#include "symtab.h"
+#include "target.h"
+#include "value.h"
+
+#include "sh-tdep.h"
+
+#include "linux-awareness.h"
+
+static unsigned int last_pid;
+static unsigned int last_page;
+static unsigned int last_translation;
+static unsigned int last_can_write;
+
+static int try_cached_translation(CORE_ADDR *addr)
+{
+    if (last_page
+	&& last_pid == PIDGET(inferior_ptid)
+	&& last_page == (*addr & ~0xfff)) {
+	*addr = last_translation | (*addr & 0xfff);
+	return 1;
+    }
+
+    return 0;
+}
+
+static int thread_info_regnum;
+static struct obstack linux_sh4_obstack;
+static unsigned int cache_used;
+static unsigned int has_started;
+static int skip_schedule_frame = 1;
+
+enum stlinux_version {
+    VERSION_UNKNOWN,
+    VERSION_2_6_11,
+    VERSION_2_6_17
+} detected_version;
+
+enum {
+    SWAPPER_PG_DIR,
+    INIT_THREAD_UNION,
+    RET_FROM_FORK,
+    DO_PAGE_FAULT,
+    _DO_PAGE_FAULT,
+    DO_ADDRESS_ERROR,
+    _DO_IRQ,
+    DO_IRQ,
+    HANDLE_UNALIGNED_ACCESS,
+    DO_EXCEPTION_ERROR,
+    DO_ILLEGAL_SLOT_INST,
+    DO_RESERVED_INST,
+    DO_SIGNAL,
+    SYSCALL_CALL,
+    WORK_RESCHED,
+    MEM_MAP,
+    CONTIG_PAGE_DATA,
+    SWAPPER_SPACE
+};
+
+struct addr_info sh4_linux_addrs[] = {
+    [SWAPPER_PG_DIR]          = { "swapper_pg_dir" },
+    [INIT_THREAD_UNION]       = { "init_thread_union" },
+    [RET_FROM_FORK]           = { "ret_from_fork" },
+    [DO_PAGE_FAULT]           = { "do_page_fault" },
+    [_DO_PAGE_FAULT]          = { "__do_page_fault" },
+    [DO_ADDRESS_ERROR]        = { "do_address_error" },
+    [_DO_IRQ]                 = { "__do_IRQ" },
+    [DO_IRQ]                  = { "do_IRQ" },
+    [HANDLE_UNALIGNED_ACCESS] = { "handle_unaligned_access" },
+    [DO_EXCEPTION_ERROR]      = { "do_exception_error" },
+    [DO_ILLEGAL_SLOT_INST]    = { "do_illegal_slot_inst" },
+    [DO_RESERVED_INST]        = { "do_reserved_inst" },
+    [DO_SIGNAL]               = { "do_signal" },
+    [SYSCALL_CALL]            = { "syscall_call" },
+    [WORK_RESCHED]            = { "work_resched" },
+    [MEM_MAP]                 = { "mem_map" },
+    [CONTIG_PAGE_DATA]        = { "contig_page_data" },
+    [SWAPPER_SPACE]           = { "swapper_space" },
+    {0}
+};
+
+
+enum linux_fundamental_fields {
+    THREAD_INFO__TASK,
+    THREAD_INFO__PREEMPT_COUNT,
+    TASK_STRUCT__THREAD_INFO,
+    TASK_STRUCT__THREAD,
+    TASK_STRUCT__MM,
+    THREAD_STRUCT__PC,
+    THREAD_STRUCT__SP,
+    MM_STRUCT__PGD,
+    LIST_HEAD__NEXT,
+    TASK_STRUCT__CHILDREN,
+    TASK_STRUCT__SIBLING,
+    TASK_STRUCT__PID,
+    TASK_STRUCT__TGID,
+    TASK_STRUCT__COMM,
+    TASK_STRUCT__NAMESPACE
+};
+
+struct field_info sh4_fundamental_linux_fields[] = {
+    /*                             struct_name     field_name   offset  size */
+    /* SH4 specific fields */
+    [THREAD_INFO__TASK]         = { "thread_info",   "task",          0,   4 },
+    [THREAD_INFO__PREEMPT_COUNT]= { "thread_info",    "preempt_count", 16, 4 },
+    [TASK_STRUCT__THREAD_INFO]  = { "task_struct",   "thread_info",   4,   4 },
+    [TASK_STRUCT__THREAD]       = { "task_struct",   "thread",      448, 168 },
+    [TASK_STRUCT__MM]           = { "task_struct",   "mm",          108,   4 },
+    [THREAD_STRUCT__PC]         = { "thread_struct", "pc",            4,   4 },
+    [THREAD_STRUCT__SP]         = { "thread_struct", "sp",            0,   4 },
+    [MM_STRUCT__PGD]            = { "mm_struct",     "pgd",          28,   4 },
+    /* Fields used by the generic part and their default values for SH4 */
+    [LIST_HEAD__NEXT]           = { "list_head",      "next",         0,   4 },
+    [TASK_STRUCT__CHILDREN]     = { "task_struct",    "children",   160,   8 },
+    [TASK_STRUCT__SIBLING]      = { "task_struct",    "sibling" ,   168,   8 },
+    [TASK_STRUCT__PID]          = { "task_struct",    "pid",        144,   4 },
+    [TASK_STRUCT__TGID]         = { "task_struct",    "tgid",       148,   4 },
+    [TASK_STRUCT__COMM]         = { "task_struct",    "comm",       420,  16 },
+    [TASK_STRUCT__NAMESPACE]    = { "task_struct",    "namespace",  624,   4 },
+    {0}
+};
+
+enum linux_fields {
+    MODULE__LIST,
+    MODULE__NAME,
+    MODULE__INIT,
+    MODULE__MODULE_INIT,
+    MODULE__MODULE_CORE,
+    MODULE__INIT_SIZE,
+    MODULE__CORE_SIZE,
+    PGLIST_DATA__NODE_START_PFN,
+    PGLIST_DATA__NODE_ZONES,
+    PGLIST_DATA__PGDAT_NEXT,
+    PAGE__MAPPING,
+    MM_STRUCT__MMAP,
+    MM_STRUCT__ARG_START,
+    MM_STRUCT__ARG_END,
+    MM_STRUCT__ENV_START,
+    MM_STRUCT__ENV_END,
+    DENTRY__D_PARENT,
+    DENTRY__D_NAME,
+    DENTRY__D_FLAGS,
+    IPC_IDS__IN_USE,
+    IPC_IDS__ENTRIES,
+    SEM_ARRAY__SEM_NSEMS,
+    MSG_QUEUE__Q_CBYTES,
+    MSG_QUEUE__Q_QNUM,
+    SUPER_BLOCK__S_TYPE,
+    SUPER_BLOCK__S_FLAGS,
+    ZONE__FREE_PAGES,
+    ZONE__NR_ACTIVE,
+    ZONE__NR_INACTIVE,
+    INODE__I_MAPPING,
+    SWAP_INFO_STRUCT__FLAGS,
+    SWAP_INFO_STRUCT__INUSE_PAGES
+};
+
+struct field_info sh4_linux_fields[] = {
+    /* struct_name     field_name   offset  size */
+    /* Non fundamental fields */
+    [MODULE__LIST] = { "module",            "list",           4,    8 },
+    [MODULE__NAME] = { "module",            "name",           12,  60 },
+    [MODULE__INIT] = { "module",            "init",           164,  4 },
+    [MODULE__MODULE_INIT] = { "module",            "module_init",    168,  4 },
+    [MODULE__MODULE_CORE] = { "module",            "module_core",    172,  4 },
+    [MODULE__INIT_SIZE] = { "module",            "init_size",      176,  4 },
+    [MODULE__CORE_SIZE] = { "module",            "core_size",      180,  4 },
+    [PGLIST_DATA__NODE_START_PFN] = { "pglist_data", "node_start_pfn", 936, 4 },
+    [PGLIST_DATA__NODE_ZONES] = { "pglist_data",       "node_zones",     0,  876 },
+    [PGLIST_DATA__PGDAT_NEXT] = { "pglist_data",       "pgdat_next",     952,  4 },
+    [PAGE__MAPPING] = { "page", "mapping", 16, 4 },
+    [MM_STRUCT__MMAP] = { "mm_struct",         "mmap",           0,    4 },
+    [MM_STRUCT__ARG_START] = { "mm_struct",         "arg_start",      92,   4 },
+    [MM_STRUCT__ARG_END] = { "mm_struct",         "arg_end",        96,   4 },
+    [MM_STRUCT__ENV_START] = { "mm_struct",         "env_start",      100,  4 },
+    [MM_STRUCT__ENV_END] = { "mm_struct",         "env_end",        104,  4 },
+    [DENTRY__D_PARENT] = { "dentry",            "d_parent",       12,   4 },
+    [DENTRY__D_NAME] = { "dentry",            "d_name",         16,  12 },
+    [DENTRY__D_FLAGS] = { "dentry",            "d_flags",        4,    4 },
+    [IPC_IDS__IN_USE] = { "ipc_ids",           "in_use",         0,    4 },
+    [IPC_IDS__ENTRIES] = { "ipc_ids",           "entries",        32,   4 },
+    [SEM_ARRAY__SEM_NSEMS] = { "sem_array",         "sem_nsems",      60,   4 },
+    [MSG_QUEUE__Q_CBYTES] = { "msg_queue",         "q_cbytes",       48,   4 },
+    [MSG_QUEUE__Q_QNUM] = { "msg_queue",         "q_qnum",         52,   4 },
+    [SUPER_BLOCK__S_TYPE] = { "super_block",       "s_type",         32,   4 },
+    [SUPER_BLOCK__S_FLAGS] = { "super_block",       "s_flags",        52,   4 },
+    [ZONE__FREE_PAGES] = { "zone",              "free_pages",     0,    4 },
+    [ZONE__NR_ACTIVE] = { "zone",              "nr_active",      232,  4 },
+    [ZONE__NR_INACTIVE] = { "zone",              "nr_inactive",    236,  4 },
+    [INODE__I_MAPPING] = { "inode",             "i_mapping",      156,  4 },
+    [SWAP_INFO_STRUCT__FLAGS] = { "swap_info_struct",  "flags",          0,    4 },
+    [SWAP_INFO_STRUCT__INUSE_PAGES] = { "swap_info_struct",  "inuse_pages",    64,   4 },
+    { "vm_area_struct",    "vm_next",        12,   4 },
+    { "vm_area_struct",    "vm_file",        76,   4 },
+    { "vm_area_struct",    "vm_flags",       20,   4 },
+    { "vm_area_struct",    "vm_start",       4,    4 },
+    { "vm_area_struct",    "vm_end",         8,    4 },
+    { "vm_area_struct",    "vm_pgoff",       72,   4 },
+    { "file",              "f_dentry",       8,    4 },
+    { "qstr",              "len",            4,    4 },
+    { "qstr",              "name",           8,    4 },
+    { "ipc_id_ary",        "size",           0,    4 },
+    { "ipc_id_ary",        "p",              4,    0 },
+    { "kern_ipc_perm",     "deleted",        0,    4 },
+    { "kern_ipc_perm",     "key",            4,    4 },
+    { "kern_ipc_perm",     "uid",            8,    4 },
+    { "kern_ipc_perm",     "gid",            12,   4 },
+    { "kern_ipc_perm",     "cuid",           16,   4 },
+    { "kern_ipc_perm",     "cgid",           20,   4 },
+    { "kern_ipc_perm",     "mode",           24,   2 },
+    { "kern_ipc_perm",     "seq",            28,   4 },
+    { "shmid_kernel",      "shm_nattch",     44,   4 },
+    { "shmid_kernel",      "shm_segsz",      48,   4 },
+    { "resource",          "name",           0,    4 },
+    { "resource",          "start",          4,    4 },
+    { "resource",          "end",            8,    4 },
+    { "resource",          "parent",         16,   4 },
+    { "resource",          "child",          24,   4 },
+    { "resource",          "sibling",        20,   4 },
+    { "hw_interrupt_type", "typename",       0,    4 },
+    { "irq_desc",          "action",         8,    4 },
+    { "irq_desc",          "handler",        0,    4 },
+    { "irq_desc",          "irq_count",      20,   4 },
+    { "irqaction",         "name",           12,   4 },
+    { "irqaction",         "next",           20,   4 },
+    { "kernel_stat",       "irqs",           64, 704 },
+    { "namespace",         "list",           8,    8 },
+    { "vfsmount",          "mnt_list",       56,   8 },
+    { "vfsmount",          "mnt_parent",     8,    4 },
+    { "vfsmount",          "mnt_devname",    52,   4 },
+    { "vfsmount",          "mnt_mountpoint", 12,   4 },
+    { "vfsmount",          "mnt_flags",      44,   4 },
+    { "vfsmount",          "mnt_sb",         20,   4 },
+    { "file_system_type",  "name",           0,    4 },
+    { "block_device",      "bd_list",        84,   8 },
+    { "block_device",      "bd_inode",       4,    4 },
+    { "page_state",        "nr_dirty",       0,    4 },
+    { "page_state",        "nr_mapped",      16,   4 },
+    { "page_state",        "nr_writeback",   4,    4 },
+    { "page_state",        "nr_slab",        20,   4 },
+    { "page_state",        "nr_page_table_pages", 12, 4 },
+    { "vm_struct",         "next",           24,   4 },
+    { "vm_struct",         "size",           4,    4 },
+    {0}
+};
+
+#define SH4_HAS_ADDR(symb) (sh4_linux_addrs[symb].sym != NULL)
+#define SH4_ADDR(sym) linux_get_address(&sh4_linux_addrs[sym])
+#define SH4_FIELD_OFFSET(sym) linux_get_field_offset(&sh4_fundamental_linux_fields[sym])
+#define SH4_FIELD_SIZE(sym) linux_get_field_size(&sh4_fundamental_linux_fields[sym])
+
+
+/* Struct pt_regs information */
+static int pt_regs_size;
+
+#define CACHE_ALLOC(size) ({ \
+          void* mem = obstack_alloc(&linux_sh4_obstack, (size)); \
+          memset(mem, 0, size); \
+          cache_used = 1; \
+          mem; })
+
+typedef struct pte {
+    CORE_ADDR address;
+    CORE_ADDR pages[1024];
+} pte_t;
+
+typedef struct pgd {
+    CORE_ADDR address;
+    pte_t*    ptes[1024];
+} pgd_t;
+
+typedef struct user_pgd {
+    CORE_ADDR task_struct;
+    pgd_t pgd;
+    struct user_pgd* next;
+} user_pgd_t;
+
+struct vm_cache
+{
+    pgd_t *kernel_pgd;
+    user_pgd_t *user_pgds;
+} linux_sh4_cache;
+
+user_pgd_t* current_user_pgd;
+
+#define mem_mask  0xE0000000
+#define P0_mask   0x00000000
+#define P1_mask   0x80000000
+#define P2_mask   0xA0000000
+#define P3_mask   0xC0000000
+#define P4_mask   0xE0000000
+
+#define _PAGE_PRESENT 0x100
+#define _PAGE_RW      0x020
+
+enum registers {
+    R0, R1, R2, R3, R4, R5, R6, R7, R8, R9, R10, R11, R12, R13, R14, R15,
+    PC, PR, GBR, VBR, MACH, MACL, SR,
+    R7B1 = 58
+};
+
+struct pt_regs {
+	unsigned long regs[16];
+	unsigned long pc;
+	unsigned long pr;
+	unsigned long sr;
+	unsigned long gbr;
+	unsigned long mach;
+	unsigned long macl;
+	long tra;
+};
+
+static void
+exception_frame_this_id (struct frame_info *next_frame, void **this_cache,
+			  struct frame_id *this_id)
+{
+    *this_id = frame_id_build_special (frame_sp_unwind(next_frame), /* was : cache->regs[15], */
+				       frame_func_unwind(next_frame),
+				       0);
+}
+
+static struct pt_regs *
+exception_frame_cache(struct frame_info *next_frame, void **this_cache)
+{
+    struct frame_info* this_frame;
+    CORE_ADDR pc;
+    CORE_ADDR regs_addr;
+    struct block* b;
+    struct symbol* sym;
+    struct value* val;
+    struct pt_regs* regs;
+    int i;
+    unsigned long* my_regs;
+
+    if (*this_cache)
+	return *this_cache;
+
+    this_frame = get_prev_frame(next_frame);
+    pc = frame_pc_unwind(next_frame);
+
+    b = block_for_pc(pc);
+    if (b == NULL) return 0;
+
+    sym = lookup_symbol("regs", b, VAR_DOMAIN, NULL, NULL);
+    if (sym == NULL) return 0;
+
+    val = read_var_value(sym, this_frame);
+
+    if (val == 0) return 0;
+
+    if (TYPE_CODE(check_typedef(value_type(val))) != TYPE_CODE_STRUCT)
+	val = value_ind(val);
+
+    gdb_assert(TYPE_CODE(check_typedef(value_type(val))) == TYPE_CODE_STRUCT);
+
+    regs_addr = VALUE_ADDRESS(val);
+    *this_cache = FRAME_OBSTACK_ZALLOC(struct pt_regs);
+    regs = *this_cache;
+    memset(regs, 0, sizeof(struct pt_regs));
+
+    i = 0;
+    my_regs = (unsigned long*)regs;
+    while (i<sizeof(struct pt_regs)/sizeof(unsigned long)) {
+	*my_regs = read_memory_unsigned_integer(regs_addr, 4);
+	regs_addr += 4; ++my_regs; ++i;
+    }
+
+    return regs;
+}
+
+static void
+exception_frame_prev_register (struct frame_info *next_frame,
+				void **this_cache,
+				int regnum, int *optimizedp,
+				enum lval_type *lvalp, CORE_ADDR *addrp,
+				int *realnump, gdb_byte *valuep)
+{
+    struct pt_regs *cache = exception_frame_cache(next_frame, this_cache);
+
+    if (! cache)
+	error("Can't unwind exception frame.");
+
+    *optimizedp = 0;
+    *lvalp = not_lval;
+    *addrp = 0;
+    *realnump = -1;
+
+    switch (regnum) {
+    case R0:
+    case R1:
+    case R2:
+    case R3:
+    case R4:
+    case R5:
+    case R6:
+    case R7:
+    case R8:
+    case R9:
+    case R10:
+    case R11:
+    case R12:
+    case R13:
+    case R14:
+    case R15:
+	store_unsigned_integer (valuep, 4, cache->regs[regnum-R0]);
+	break;
+    case PC:
+	store_unsigned_integer (valuep, 4, cache->pc);
+	break;
+    case PR:
+	store_unsigned_integer (valuep, 4, cache->pr);
+	break;
+    case SR:
+	store_unsigned_integer (valuep, 4, cache->sr);
+	break;
+    case GBR:
+	store_unsigned_integer (valuep, 4, cache->gbr);
+	break;
+    case MACH:
+	store_unsigned_integer (valuep, 4, cache->mach);
+	break;
+    case MACL:
+	store_unsigned_integer (valuep, 4, cache->macl);
+	break;
+    default:
+	*optimizedp = 1;
+	*lvalp = not_lval;
+	*addrp = 0;
+	*realnump = -1;
+	get_frame_register(next_frame, regnum, valuep);
+    }
+}
+
+static int
+exception_frame_sniffer (const struct frame_unwind *self,
+			  struct frame_info *next_frame,
+			  void **this_cache)
+{
+    CORE_ADDR func = frame_func_unwind(next_frame);
+
+    if ((SH4_HAS_ADDR(DO_PAGE_FAULT) && func == SH4_ADDR(DO_PAGE_FAULT))
+	|| (SH4_HAS_ADDR(_DO_PAGE_FAULT) && func == SH4_ADDR(_DO_PAGE_FAULT))
+	|| (SH4_HAS_ADDR(_DO_IRQ) && func == SH4_ADDR(_DO_IRQ))
+	|| (SH4_HAS_ADDR(DO_IRQ) && func == SH4_ADDR(DO_IRQ))
+	|| (SH4_HAS_ADDR(HANDLE_UNALIGNED_ACCESS) && func == SH4_ADDR(HANDLE_UNALIGNED_ACCESS))
+	|| (SH4_HAS_ADDR(DO_ADDRESS_ERROR) && func == SH4_ADDR(DO_ADDRESS_ERROR))
+	|| (SH4_HAS_ADDR(DO_EXCEPTION_ERROR) && func == SH4_ADDR(DO_EXCEPTION_ERROR))
+	|| (SH4_HAS_ADDR(DO_ILLEGAL_SLOT_INST) && func == SH4_ADDR(DO_ILLEGAL_SLOT_INST))
+	|| (SH4_HAS_ADDR(DO_RESERVED_INST) && func == SH4_ADDR(DO_RESERVED_INST))
+	|| (SH4_HAS_ADDR(DO_SIGNAL) && func == SH4_ADDR(DO_SIGNAL))) {
+	linux_read_process_symbols();
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind exception_frame_unwind = {
+  NORMAL_FRAME,
+  exception_frame_this_id,
+  exception_frame_prev_register,
+  NULL,
+  exception_frame_sniffer
+};
+
+static void
+interrupt_frame_this_id (struct frame_info *next_frame, void **this_cache,
+			  struct frame_id *this_id)
+{
+    /* Use a dummy code_addr so that we don't get identical ids. */
+    *this_id = frame_id_build (get_frame_id(next_frame).stack_addr, 0);
+}
+
+
+static void
+interrupt_frame_prev_register (struct frame_info *next_frame,
+				void **this_cache,
+				int regnum, int *optimizedp,
+				enum lval_type *lvalp, CORE_ADDR *addrp,
+				int *realnump, gdb_byte *valuep)
+{
+    *optimizedp = 0;
+    *lvalp = not_lval;
+    *addrp = 0;
+    *realnump = -1;
+
+    /* No need to worry about the PC. Using a SIGTRAMP frame has the
+       advantage that PC won't be modified in a stupid way in the
+       prvious frame. */
+    frame_unwind_register(next_frame, regnum, valuep);
+}
+
+static int
+interrupt_frame_sniffer (const struct frame_unwind *self,
+			 struct frame_info *next_frame,
+			 void **this_cache)
+{
+    return get_frame_id(next_frame).special_addr_p
+	&& get_frame_id(next_frame).special_addr == 0;
+}
+
+static const struct frame_unwind interrupt_frame_unwind = {
+  SIGTRAMP_FRAME,
+  interrupt_frame_this_id,
+  interrupt_frame_prev_register,
+  NULL,
+  interrupt_frame_sniffer
+};
+
+
+
+
+
+static struct pt_regs *
+syscall_frame_cache(struct frame_info *next_frame, void **this_cache)
+{
+    struct frame_info* this_frame = get_prev_frame(next_frame);
+    ULONGEST sp, stack_top;
+    CORE_ADDR regs_addr;
+    struct pt_regs* regs;
+    unsigned long* my_regs;
+    int i;
+
+    if (*this_cache)
+	return *this_cache;
+
+    sp = get_frame_register_unsigned(next_frame, R15);
+    /* SP should be near the top of the stack which is on a page
+       boundary. In fact, SP should certainly be pointing at the saved
+       registers, but this seems more flexible if the asm in entry.S
+       changes. */
+    stack_top = (sp + 4096) & ~0xFFF;
+    regs_addr = stack_top - sizeof(struct pt_regs);
+
+    /* The location of struct pt_regs upon syscall has changed between
+       STLinux 2.0 and STLinux 2.2. */
+    if (detected_version == VERSION_2_6_11)
+	regs_addr -= 4;
+
+    this_frame = get_prev_frame(next_frame);
+    *this_cache = FRAME_OBSTACK_ZALLOC(struct pt_regs);
+    regs = *this_cache;
+    memset(regs, 0, sizeof(struct pt_regs));
+
+    i = 0;
+    my_regs = (unsigned long*)regs;
+    while (i<sizeof(struct pt_regs)/sizeof(unsigned long)) {
+	*my_regs = read_memory_unsigned_integer(regs_addr, 4);
+	regs_addr += 4; ++my_regs; ++i;
+    }
+
+    return regs;
+}
+
+static void
+syscall_frame_this_id (struct frame_info *next_frame, void **this_cache,
+		       struct frame_id *this_id)
+{
+    struct pt_regs *cache = syscall_frame_cache(next_frame, this_cache);
+
+    *this_id = frame_id_build (frame_sp_unwind(next_frame), /* was : cache->regs[15], */
+			       frame_func_unwind(next_frame));
+}
+
+static void
+syscall_frame_prev_register (struct frame_info *next_frame,
+			     void **this_cache,
+			     int regnum, int *optimizedp,
+			     enum lval_type *lvalp, CORE_ADDR *addrp,
+			     int *realnump, gdb_byte *valuep)
+{
+    struct pt_regs *cache = syscall_frame_cache(next_frame, this_cache);
+
+    if (! cache)
+	error("Can't unwind exception frame.");
+
+    *optimizedp = 0;
+    *lvalp = not_lval;
+    *addrp = 0;
+    *realnump = -1;
+
+    switch (regnum) {
+    case R0:
+    case R1:
+    case R2:
+    case R3:
+    case R4:
+    case R5:
+    case R6:
+    case R7:
+    case R8:
+    case R9:
+    case R10:
+    case R11:
+    case R12:
+    case R13:
+    case R14:
+    case R15:
+	store_unsigned_integer (valuep, 4, cache->regs[regnum-R0]);
+	break;
+    case PC:
+	store_unsigned_integer (valuep, 4, cache->pc);
+	break;
+    case PR:
+	store_unsigned_integer (valuep, 4, cache->pr);
+	break;
+    case SR:
+	store_unsigned_integer (valuep, 4, cache->sr);
+	break;
+    case GBR:
+	store_unsigned_integer (valuep, 4, cache->gbr);
+	break;
+    case MACH:
+	store_unsigned_integer (valuep, 4, cache->mach);
+	break;
+    case MACL:
+	store_unsigned_integer (valuep, 4, cache->macl);
+	break;
+    default:
+	*optimizedp = 1;
+	*lvalp = not_lval;
+	*addrp = 0;
+	*realnump = -1;
+	get_frame_register(next_frame, regnum, valuep);
+    }
+}
+
+static int
+syscall_frame_sniffer (const struct frame_unwind *self,
+		       struct frame_info *next_frame,
+		       void **this_cache)
+{
+    if ((frame_relative_level (next_frame) != -1)
+	&& ((SH4_HAS_ADDR(WORK_RESCHED)  && get_frame_func (next_frame) == SH4_ADDR(WORK_RESCHED))
+	    || (SH4_HAS_ADDR(RET_FROM_FORK) && get_frame_func (next_frame) == SH4_ADDR(RET_FROM_FORK))
+	    || (SH4_HAS_ADDR(SYSCALL_CALL) && get_frame_func (next_frame) == SH4_ADDR(SYSCALL_CALL)))) {
+	/* Do that here because.... it should work. :-/  */
+	linux_read_process_symbols();
+    }
+
+    CORE_ADDR func = frame_func_unwind(next_frame);
+
+    if ((SH4_HAS_ADDR(SYSCALL_CALL) && func == SH4_ADDR(SYSCALL_CALL))
+	|| (SH4_HAS_ADDR(RET_FROM_FORK) && func == SH4_ADDR(RET_FROM_FORK))) {
+	return 1;
+    }
+
+    return 0;
+}
+
+static const struct frame_unwind syscall_frame_unwind = {
+  NORMAL_FRAME,
+  syscall_frame_this_id,
+  syscall_frame_prev_register,
+  NULL,
+  syscall_frame_sniffer
+};
+
+static int sh4_linux_awareness_check()
+{
+    /* Don't include address check here, because most of the addresses
+       aren't fundamental for the awareness layer.  */
+    return linux_check_fields(sh4_fundamental_linux_fields);
+}
+
+static void detect_cache_layout();
+
+static void fix_default_offsets_2_6_17()
+{
+    sh4_fundamental_linux_fields[TASK_STRUCT__THREAD].default_offset = 416;
+    sh4_fundamental_linux_fields[TASK_STRUCT__MM].default_offset = 124;
+    sh4_fundamental_linux_fields[TASK_STRUCT__CHILDREN].default_offset = 176;
+    sh4_fundamental_linux_fields[TASK_STRUCT__SIBLING].default_offset = 184;
+    sh4_fundamental_linux_fields[TASK_STRUCT__PID].default_offset = 160;
+    sh4_fundamental_linux_fields[TASK_STRUCT__TGID].default_offset = 164;
+    sh4_fundamental_linux_fields[TASK_STRUCT__COMM].default_offset = 388;
+    sh4_fundamental_linux_fields[TASK_STRUCT__NAMESPACE].default_offset = 592;
+    sh4_fundamental_linux_fields[MM_STRUCT__PGD].default_offset = 36;
+
+    sh4_linux_fields[MODULE__INIT].default_offset = 196;
+    sh4_linux_fields[MODULE__MODULE_INIT].default_offset = 200;
+    sh4_linux_fields[MODULE__MODULE_CORE].default_offset = 204;
+    sh4_linux_fields[MODULE__INIT_SIZE].default_offset = 208;
+    sh4_linux_fields[MODULE__CORE_SIZE].default_offset = 212;
+
+    sh4_linux_fields[PGLIST_DATA__NODE_START_PFN].default_offset = 1280;
+    sh4_linux_fields[PGLIST_DATA__NODE_ZONES].default_size = 1168;
+
+    sh4_linux_fields[MM_STRUCT__ARG_START].default_offset = 148;
+    sh4_linux_fields[MM_STRUCT__ARG_END].default_offset = 152;
+    sh4_linux_fields[MM_STRUCT__ENV_START].default_offset = 156;
+    sh4_linux_fields[MM_STRUCT__ENV_END].default_offset = 160;
+
+    sh4_linux_fields[DENTRY__D_PARENT].default_offset = 20;
+    sh4_linux_fields[DENTRY__D_NAME].default_offset = 24;
+
+    sh4_linux_fields[IPC_IDS__ENTRIES].default_offset = 28;
+
+    sh4_linux_fields[SEM_ARRAY__SEM_NSEMS].default_offset = 64;
+
+    sh4_linux_fields[MSG_QUEUE__Q_CBYTES].default_offset = 52;
+    sh4_linux_fields[MSG_QUEUE__Q_QNUM].default_offset = 56;
+
+    sh4_linux_fields[SUPER_BLOCK__S_TYPE].default_offset = 28;
+    sh4_linux_fields[SUPER_BLOCK__S_FLAGS].default_offset = 48;
+
+    sh4_linux_fields[ZONE__NR_ACTIVE].default_offset = 228;
+    sh4_linux_fields[ZONE__NR_INACTIVE].default_offset = 232;
+
+    sh4_linux_fields[INODE__I_MAPPING].default_offset = 152;
+
+    sh4_linux_fields[SWAP_INFO_STRUCT__INUSE_PAGES].default_offset = 60;
+}
+
+static void fix_offsets_with_options_2_6_17()
+{
+    int has_schedstats = 0, has_keys = 0, has_debug_spinlocks = 0;;
+
+    has_debug_spinlocks = lookup_minimal_symbol("_spin_trylock",
+						NULL, NULL) != NULL;
+    has_schedstats = lookup_minimal_symbol("proc_schedstat_operations",
+					   NULL, NULL) != NULL;
+    has_keys = lookup_minimal_symbol("key_user_lookup",
+				     NULL, NULL) != NULL;
+
+    /* struct task_struct contains a conditionnal part at the
+       beginning which depends on defined(CONFIG_SMP) &&
+       defined(__ARCH_WANT_UNLOCKED_CTXSW), but this will never be
+       enabled for SH. */
+
+    if (has_schedstats) {
+	printf_filtered("Detected CONFIG_SCHEDSTATS option.\n");
+	*sh4_fundamental_linux_fields[TASK_STRUCT__THREAD].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__MM].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__CHILDREN].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__SIBLING].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__PID].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__TGID].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__COMM].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__NAMESPACE].offset += 20;
+    }
+
+    if (has_debug_spinlocks) {
+	printf_filtered("Detected CONFIG_DEBUG_SPINLOCKS option.\n");
+	*sh4_linux_fields[MODULE__INIT].offset += 16;
+	*sh4_linux_fields[MODULE__MODULE_INIT].offset += 16;
+	*sh4_linux_fields[MODULE__MODULE_CORE].offset += 16;
+	*sh4_linux_fields[MODULE__INIT_SIZE].offset += 16;
+	*sh4_linux_fields[MODULE__CORE_SIZE].offset += 16;
+    }
+
+    if (has_keys) {
+	printf_filtered("Detected CONFIG_KEYS option.\n");
+	*sh4_fundamental_linux_fields[TASK_STRUCT__THREAD].offset += 12;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__COMM].offset += 12;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__NAMESPACE].offset += 12;
+    }
+
+}
+
+static void fix_offsets_with_options_2_6_11()
+{
+    int has_schedstats = 0, has_kgdb = 0, has_keys = 0;
+
+    has_schedstats = lookup_minimal_symbol("proc_schedstat_operations",
+					   NULL, NULL) != NULL;
+    has_kgdb = lookup_minimal_symbol("kgdb_handle_exception",
+				     NULL, NULL) != NULL;
+    has_keys = lookup_minimal_symbol("key_user_lookup",
+				     NULL, NULL) != NULL;
+
+    if (has_schedstats) {
+	printf_filtered("Detected CONFIG_SCHEDSTATS option.\n");
+	*sh4_fundamental_linux_fields[TASK_STRUCT__THREAD].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__MM].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__CHILDREN].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__SIBLING].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__PID].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__TGID].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__COMM].offset += 20;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__NAMESPACE].offset += 20;
+    }
+
+    if (has_kgdb) {
+	printf_filtered("Detected CONFIG_KGDB option.\n");
+	*sh4_linux_fields[MODULE__INIT].offset += 8;
+	*sh4_linux_fields[MODULE__MODULE_INIT].offset += 8;
+	*sh4_linux_fields[MODULE__MODULE_CORE].offset += 8;
+	*sh4_linux_fields[MODULE__INIT_SIZE].offset += 8;
+	*sh4_linux_fields[MODULE__CORE_SIZE].offset += 8;
+    }
+
+    if (has_keys) {
+	printf_filtered("Detected CONFIG_KEYS option.\n");
+	*sh4_fundamental_linux_fields[TASK_STRUCT__THREAD].offset += 12;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__COMM].offset += 12;
+	*sh4_fundamental_linux_fields[TASK_STRUCT__NAMESPACE].offset += 12;
+    }
+
+}
+
+#define CERTIFY(f) linux_certify_field(&sh4_linux_fields[f])
+static void check_certified_version()
+{
+    printf_filtered("\
+You're loading the linux-awareness layer on a kernel with missing debug\n\
+information. Your kernel seems to be supported, thus basic functionality\n\
+(info tasks, info modules) should work anyway. You will be notified that the\n\
+debugger will use untrusted default values for more advanced uses.\n");
+
+    printf_filtered("\
+It is safer to use a kernel built with debug information if possible.\n");
+
+    CERTIFY(LIST_HEAD__NEXT);
+    CERTIFY(THREAD_INFO__TASK);
+    CERTIFY(TASK_STRUCT__THREAD_INFO);
+    CERTIFY(TASK_STRUCT__THREAD);
+    CERTIFY(TASK_STRUCT__MM);
+    CERTIFY(TASK_STRUCT__CHILDREN);
+    CERTIFY(TASK_STRUCT__SIBLING);
+    CERTIFY(TASK_STRUCT__PID);
+    CERTIFY(TASK_STRUCT__COMM);
+    CERTIFY(TASK_STRUCT__NAMESPACE);
+    CERTIFY(THREAD_STRUCT__PC);
+    CERTIFY(THREAD_STRUCT__SP);
+    CERTIFY(MM_STRUCT__PGD);
+    CERTIFY(MODULE__LIST);
+    CERTIFY(MODULE__NAME);
+    CERTIFY(MODULE__INIT);
+    CERTIFY(MODULE__MODULE_INIT);
+    CERTIFY(MODULE__MODULE_CORE);
+    CERTIFY(MODULE__INIT_SIZE);
+    CERTIFY(MODULE__CORE_SIZE);
+}
+
+static int sh4_linux_awareness_init()
+{
+    obstack_init(&linux_sh4_obstack);
+
+    linux_init_addresses(sh4_linux_addrs);
+
+    if (lookup_minimal_symbol("Version_132619", NULL, NULL)) {
+	/* 2.6.11 version */
+	detected_version = VERSION_2_6_11;
+    } else if (lookup_minimal_symbol("Version_132625", NULL, NULL)) {
+	/* 2.6.17 version */
+	detected_version = VERSION_2_6_17;
+    } else {
+	detected_version = VERSION_UNKNOWN;
+    }
+
+    if (detected_version == VERSION_2_6_17)
+	fix_default_offsets_2_6_17 ();
+
+    linux_init_fields(sh4_linux_fields);
+
+    if (!linux_init_fields(sh4_fundamental_linux_fields)) {
+	/* Certainly no debug information */
+	if (detected_version == VERSION_2_6_11 )
+	    fix_offsets_with_options_2_6_11();
+	else if (detected_version == VERSION_2_6_17)
+	    fix_offsets_with_options_2_6_17();
+	else {
+	    printf_filtered("\
+Your kernel version seems not to be supported. You'll get warnings about the\n\
+use of default values for data structures. You'll be notified only once per\n\
+value.\n");
+	    return 0;
+	}
+
+	check_certified_version();
+    }
+
+    thread_info_regnum = user_reg_map_name_to_regnum(current_gdbarch,
+						     "r7b1", 4);
+    DEBUG(INIT, 5, "The current_thread_info regnum is %i\n", thread_info_regnum);
+
+    frame_unwind_prepend_unwinder(current_gdbarch, &exception_frame_unwind);
+    frame_unwind_prepend_unwinder(current_gdbarch, &interrupt_frame_unwind);
+    frame_unwind_prepend_unwinder(current_gdbarch, &syscall_frame_unwind);
+
+    add_setshow_boolean_cmd("skip_schedule_frame",
+			    class_obscure,
+			    &skip_schedule_frame,
+			    "Set whether the debugger should hide the schedule() frame for sleeping tasks",
+			    "Show whether the debugger should hide the schedule() frame for sleeping tasks",
+			    NULL, NULL, NULL,
+			    &set_linux_awareness_cmd_list,
+			    &show_linux_awareness_cmd_list);
+
+    return thread_info_regnum != -1;
+}
+
+void translate_memory_address_clear_cache()
+{
+    if (cache_used) {
+	obstack_free(&linux_sh4_obstack, 0);
+	obstack_init(&linux_sh4_obstack);
+	linux_sh4_cache.kernel_pgd = NULL;
+	linux_sh4_cache.user_pgds = NULL;
+	current_user_pgd = NULL;
+	cache_used = 0;
+    }
+}
+
+static int
+get_start_pfn(unsigned int *start_pfn)
+{
+    CORE_ADDR pagedata = SH4_HAS_ADDR(CONTIG_PAGE_DATA) ?
+	SH4_ADDR(CONTIG_PAGE_DATA) : (CORE_ADDR)-1;
+
+    if (pagedata == (CORE_ADDR)-1)
+	return 0;
+
+    *start_pfn = read_memory_unsigned_integer(pagedata + *sh4_linux_fields[PGLIST_DATA__NODE_START_PFN].offset,
+					      *sh4_linux_fields[PGLIST_DATA__NODE_START_PFN].size);
+    return 1;
+}
+
+static CORE_ADDR
+struct_page_from_phys_addr(CORE_ADDR addr)
+{
+    unsigned int pfn = (addr & ~P1_mask) >> 12;
+    unsigned int start_pfn;
+
+    if (! SH4_HAS_ADDR(MEM_MAP)
+	|| ! get_start_pfn(&start_pfn))
+	return (CORE_ADDR)-1;
+
+    return read_memory_typed_address(SH4_ADDR(MEM_MAP) + 4*(pfn-start_pfn),
+				     builtin_type_void_data_ptr);
+}
+
+static unsigned int get_address_pte_value(CORE_ADDR addr,
+					  pte_t *pte)
+{
+    unsigned int offset;
+    unsigned int page_addr;
+
+    gdb_assert(pte != NULL);
+
+    offset = ((unsigned int)addr << 10) >> 22;
+    page_addr = pte->pages[offset];
+
+    if (page_addr == 0) {
+	page_addr = read_memory_unsigned_integer(pte->address+offset*4, 4);
+	DEBUG(VM, 3,
+	      "Reading page address for %x ( *(unsigned int*)0x%s ) -> %x\n",
+	      (unsigned int)addr, paddr (pte->address+offset*4),
+	      (unsigned int)page_addr);
+
+	pte->pages[offset] = page_addr;
+    }
+
+    return page_addr;
+}
+
+static pte_t *get_address_pte(CORE_ADDR addr,
+			     pgd_t *pgd)
+{
+    unsigned int  offset;
+    pte_t        *pte = NULL;
+
+    gdb_assert(pgd != NULL);
+
+    offset = ((unsigned int)addr) >> 22;
+    pte = pgd->ptes[offset];
+
+    if (pte == NULL) {
+	pte = CACHE_ALLOC(sizeof(pte_t));
+
+	pte->address = read_memory_unsigned_integer(pgd->address+offset*4, 4);
+	DEBUG(VM, 3,
+	      "Reading PTE address for %x ( *(unsigned int*)%s ) -> %x\n",
+	      (unsigned int)addr, paddr (pgd->address+offset*4),
+	      (unsigned int)pte->address);
+
+	/* When using the TLB optimization patch
+	   ( https://bugzilla.stlinux.com/attachment.cgi?id=334 ) the
+	   PTE doesn't contain the PAGE_PRESENT flag and it is directly a
+	   P1 address. */
+
+	if ((pte->address & P1_mask) != P1_mask)
+	    if (! (pte->address & _PAGE_PRESENT) )
+		return NULL;
+
+	pte->address &= ~0xFFF;
+	pte->address |= P1_mask;
+
+	pgd->ptes[offset] = pte;
+    }
+
+    return pte;
+}
+
+static enum page_status translate_address_through_pte(CORE_ADDR *addr,
+						      pte_t *pte)
+{
+    unsigned int page_addr;
+    unsigned int page_offset;
+    enum page_status res = PAGE_UNKNOWN;
+    page_offset = ((unsigned int)*addr) & 0xFFF;
+    page_addr = get_address_pte_value(*addr, pte);
+    page_addr += P1_mask;
+
+    if (page_addr & _PAGE_PRESENT)
+	res = PAGE_PRESENT;
+    else if (page_addr == P1_mask) {
+	res = PAGE_NOPAGE;
+    } else {
+	CORE_ADDR struct_page;
+	struct_page = struct_page_from_phys_addr(page_addr);
+
+	if (struct_page == (CORE_ADDR)-1
+	    || !SH4_HAS_ADDR(SWAPPER_SPACE))
+	    res = PAGE_UNKNOWN;
+	else if (read_memory_unsigned_integer(struct_page + *sh4_linux_fields[PAGE__MAPPING].offset,
+					      *sh4_linux_fields[PAGE__MAPPING].size) == SH4_ADDR(SWAPPER_SPACE))
+	    res = PAGE_SWAPPED;
+	else
+	    res = PAGE_NOTMAPPED;
+    }
+
+    page_addr &= ~0xFFF;
+
+    DEBUG(VM, 2, "addr = %x => P1 address : %x (%s)\n",
+	  (unsigned int)*addr,
+	  page_addr + page_offset,
+	  res == PAGE_PRESENT ? "PAGE_PRESENT"
+	  : ( res == PAGE_NOPAGE ? "PAGE_NOPAGE"
+	      : ( res == PAGE_SWAPPED ? "PAGE_SWAPPED"
+		  : ( res == PAGE_NOPAGE ? "PAGE_NOTMAPPED"
+		      : ( res == PAGE_UNKNOWN ? "PAGE_UNKNOWN" : "??" ))))
+	  );
+
+    *addr = page_addr + page_offset;
+
+    return res;
+}
+
+static enum page_status translate_address_through_pgd(CORE_ADDR *addr,
+						      pgd_t *pgd)
+{
+    unsigned int      offset;
+    pte_t            *pte;
+    enum page_status  res;
+    CORE_ADDR         orig = *addr;
+
+    DEBUG(VM, 2, "Trying to translate %x\n", (unsigned int)*addr);
+
+    pte = get_address_pte(*addr, pgd);
+
+    if (pte == NULL) {
+	return PAGE_NOPAGE;
+    }
+
+    res = translate_address_through_pte(addr, pte);
+
+    if (res == PAGE_PRESENT) {
+	last_page = orig & ~0xfff;
+	last_pid  = PIDGET(inferior_ptid);
+	last_translation = *addr & ~0xfff;
+	last_can_write = get_address_pte_value(orig, pte) & _PAGE_RW;
+    }
+
+    return res;
+}
+
+static pgd_t* get_kernel_pgd()
+{
+    if (linux_sh4_cache.kernel_pgd == NULL) {
+	linux_sh4_cache.kernel_pgd = CACHE_ALLOC(sizeof(pgd_t));
+	linux_sh4_cache.kernel_pgd->address = SH4_ADDR(SWAPPER_PG_DIR);
+    }
+
+    return linux_sh4_cache.kernel_pgd;
+}
+
+static pgd_t* find_user_pgd(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    user_pgd_t* u_pgd = linux_sh4_cache.user_pgds;
+    unsigned int mm_struct_address;
+    unsigned int pgd_address;
+
+    if (current_user_pgd && current_user_pgd->task_struct == task_struct)
+	return &current_user_pgd->pgd;
+
+    while (u_pgd != NULL) {
+	if (u_pgd->task_struct == task_struct)
+	    break;
+
+	u_pgd = u_pgd->next;
+    }
+
+    if (u_pgd != NULL) {
+	current_user_pgd = u_pgd;
+	return &current_user_pgd->pgd;
+    }
+
+    if ( (task_struct & mem_mask) != P1_mask) {
+	DEBUG(VM, 1, "Task struct should be at a P1 address.");
+	return NULL;
+    }
+    mm_struct_address = read_memory_unsigned_integer(task_struct+SH4_FIELD_OFFSET(TASK_STRUCT__MM), 4);
+    if (mm_struct_address == 0) {
+	DEBUG(VM, 1, "No userspace address allowed in a kernel thread.");
+	return NULL;
+    }
+    if ( (mm_struct_address & mem_mask) != P1_mask) {
+	DEBUG(VM, 1, "mm struct should be at a P1 address.");
+	return NULL;
+    }
+    pgd_address = read_memory_unsigned_integer(mm_struct_address+SH4_FIELD_OFFSET(MM_STRUCT__PGD), 4);
+    if ( (pgd_address & mem_mask) != P1_mask) {
+	DEBUG(VM, 1, "pgd should be at a P1 address.");
+	return NULL;
+    }
+
+    /* Allocate new cache */
+    u_pgd = CACHE_ALLOC(sizeof(user_pgd_t));
+    u_pgd->task_struct = task_struct;
+    u_pgd->pgd.address = pgd_address;
+    current_user_pgd = u_pgd;
+
+    u_pgd->next = linux_sh4_cache.user_pgds;
+    linux_sh4_cache.user_pgds = u_pgd;
+
+    return &current_user_pgd->pgd;
+}
+
+static pgd_t* get_address_pgd(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    switch (addr & mem_mask) {
+    case P3_mask:
+	return get_kernel_pgd();
+    case P1_mask:
+    case P2_mask:
+    case P4_mask:
+	gdb_assert(0 && "No pgd for non-translatable addresses.");
+    default:
+	return find_user_pgd(addr, task_struct);
+    }
+
+    return NULL;
+}
+
+static int linux_sh4_address_needs_translation(CORE_ADDR addr)
+{
+    addr &= mem_mask;
+    return addr != P1_mask
+	&& addr != P2_mask
+	&& addr != P4_mask;
+}
+
+enum page_status translate_memory_address(CORE_ADDR *addr, CORE_ADDR task_struct)
+{
+    pgd_t *pgd;
+
+    DEBUG(VM, 3, "Asking to translate %x (mem %x)\n",
+	  (unsigned int)*addr, (unsigned int)(*addr) & mem_mask);
+
+    if (! linux_sh4_address_needs_translation(*addr))
+	return PAGE_PRESENT;
+
+    if (try_cached_translation(addr)) {
+	DEBUG(VM, 3, "Cached translation: %s\n", paddr (*addr));
+	return PAGE_PRESENT;
+    }
+
+    pgd = get_address_pgd(*addr, task_struct);
+
+    if (pgd == NULL)
+	return PAGE_UNKNOWN;;
+
+    return translate_address_through_pgd(addr, pgd);
+}
+
+static CORE_ADDR translate_watch_address_pgd(CORE_ADDR addr,
+					     pgd_t *pgd)
+{
+    unsigned int  offset;
+    pte_t        *pte;
+    CORE_ADDR    res;
+
+    pte = get_address_pte(addr, pgd);
+
+    if (pte != NULL) {
+	offset = ((unsigned int)addr << 10) >> 22;
+	return pte->address+offset*4;
+    }
+
+    /* The PTE isn't mapped */
+    offset = ((unsigned int)addr) >> 22;
+    return pgd->address+offset*4;
+}
+
+static CORE_ADDR translate_memory_watch_address(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    pgd_t *pgd;
+
+    if (! linux_sh4_address_needs_translation(addr))
+	return 0;
+
+    if (try_cached_translation(&addr))
+	return 0;
+
+    pgd = get_address_pgd(addr, task_struct);
+
+    if (pgd == NULL)
+	return 0;
+
+    return translate_watch_address_pgd(addr, pgd);
+}
+
+static int sh4_linux_can_write(CORE_ADDR addr, CORE_ADDR task_struct)
+{
+    pgd_t *pgd;
+    pte_t *pte;
+
+    if (! linux_sh4_address_needs_translation(addr))
+	return 1;
+
+    if (try_cached_translation(&addr))
+	return last_can_write;
+
+    pgd = get_address_pgd(addr, task_struct);
+
+    if (pgd == NULL)
+	return 0;
+
+    pte = get_address_pte(addr, pgd);
+
+    if (pte == NULL)
+	return 0;
+
+    if (get_address_pte_value(addr, pte) & _PAGE_RW)
+	return 1;
+
+    return 0;
+}
+
+static int sh4_linux_is_user_address(CORE_ADDR addr)
+{
+    return !(addr & 0x80000000);
+}
+
+static int sh4_linux_is_kernel_address(CORE_ADDR addr)
+{
+    return !sh4_linux_is_user_address(addr);
+}
+
+static int cache_layout_known = 0;
+
+struct cache_info {
+	unsigned int ways;
+	unsigned int sets;
+	unsigned int linesz;
+	unsigned int way_incr;
+	unsigned int entry_shift;
+	unsigned int entry_mask;
+} i_cache_info, o_cache_info;
+
+static void print_cache_info(const char* name, const struct cache_info* info)
+{
+    DEBUG(VM, 3,
+	  "%s info:\n"
+	  "sets: %i\tlinesz: %i\n"
+	  "ways: %i\tway_incr: 0x%x\n"
+	  "entry_shift: %i\tentry_mask: 0x%x\n",
+	  name, info->sets, info->linesz,
+	  info->ways, info->way_incr,
+	  info->entry_shift, info->entry_mask);
+}
+
+static unsigned int cache_size(unsigned int s)
+{
+    switch (s) {
+    case 0x1: return (1<<12);
+    case 0x2: return (1<<13);
+    case 0x4: return (1<<14);
+    case 0x8: return (1<<15);
+    case 0x9: return (1<<16);
+    default: error("Invalid cache size : 0x%x", s);
+    };
+}
+
+static void detect_cache_layout()
+{
+    unsigned int PVR, CVR, CCR;
+    unsigned int size;
+
+    enum { SH4_1XX, SH4_2XX, SH4_3XX } variant;
+
+    PVR = read_memory_unsigned_integer(0xff000030, 4);
+    CVR = read_memory_unsigned_integer(0xff000040, 4);
+    CCR = read_memory_unsigned_integer(0xFF00001C, 4);
+
+    PVR >>= 16; PVR &= 0xFF;
+
+    switch (PVR) {
+    case 0x80:
+    case 0x81:
+	variant = SH4_1XX;
+	break;
+    case 0x06:
+	variant = SH4_2XX;
+	break;
+    default:
+	error("Couldn't detect the ST40 vatriant, got 0x%x.", PVR);
+    }
+
+    /* FIXME : hardcoded cachecline size ? */
+    o_cache_info.linesz = i_cache_info.linesz = 32;
+    o_cache_info.entry_shift = i_cache_info.entry_shift = 5;
+    o_cache_info.ways = i_cache_info.ways = 1;
+
+    if (variant == SH4_2XX
+	&& CCR >> 31)
+	o_cache_info.ways = i_cache_info.ways = 2;
+
+    i_cache_info.sets = cache_size((CVR>>20) & 0xF) / i_cache_info.linesz;
+    o_cache_info.sets = cache_size((CVR>>16) & 0xF) / o_cache_info.linesz;
+
+    i_cache_info.sets /= i_cache_info.ways;
+    o_cache_info.sets /= o_cache_info.ways;
+
+    i_cache_info.entry_mask = (i_cache_info.sets-1) << i_cache_info.entry_shift;
+    o_cache_info.entry_mask = (o_cache_info.sets-1) << o_cache_info.entry_shift;
+
+    i_cache_info.way_incr = i_cache_info.sets << i_cache_info.entry_shift;
+    o_cache_info.way_incr = o_cache_info.sets << o_cache_info.entry_shift;
+
+    cache_layout_known = 1;
+
+    print_cache_info("O-Cache", &o_cache_info);
+    print_cache_info("I-Cache", &i_cache_info);
+}
+
+/* This flushing routine is called only for virtual memory adresses.
+   If we pass access_addr == phys_addr, it means that we want to
+   suppress the alias we may have introduced through our direct access
+   to this physical address.
+
+   Precondition :
+   [access_addr..access_addr+len[ lies on the same physical page. */
+
+static void linux_sh4_flush_cache_for_region(CORE_ADDR access_addr,
+					     CORE_ADDR phys_addr,
+					     int len,
+					     int write)
+{
+    unsigned long start_addr, end_addr, cur_phys_addr, val;
+    unsigned int i;
+
+    if (!cache_layout_known)
+	detect_cache_layout();
+
+    DEBUG(VM, 4, "Asking to flush O-Cache for access=%llx phys=%llx (+%d)\n",
+	  (ULONGEST)access_addr, (ULONGEST)phys_addr, len);
+
+    start_addr = access_addr & ~(o_cache_info.linesz-1);
+    end_addr = (access_addr+len) & ~(o_cache_info.linesz-1);
+    cur_phys_addr = phys_addr & ~(o_cache_info.linesz-1);
+
+    /* OCache */
+    while (start_addr <= end_addr) {
+	unsigned long cache_addr = 0xF4000000 | (start_addr & o_cache_info.entry_mask);
+	unsigned long cache_data;
+	for (i=0; i < o_cache_info.ways; ++i) {
+	    cache_data = read_memory_unsigned_integer(cache_addr, 4);
+
+	    DEBUG(VM, 4, "Cache address : %lx => %lx\n",
+		  cache_addr, cache_data);
+
+	    if ((cache_data & 0x1) /* valid */
+		&& (write
+		    || (cache_data & 0x2) /* dirty */
+		    || (phys_addr == access_addr) /* Aliased cachelines */)
+		&& ((cache_data & ~0x3FF) == (cur_phys_addr & 0x1FFFFC00))) {
+		DEBUG(VM, 3, "Flushing O-Cache for access=%llx phys=%llx\n",
+		      (ULONGEST)start_addr, (ULONGEST)cur_phys_addr);
+		write_memory_unsigned_integer(cache_addr, 4, 0);
+	    }
+
+	    cache_addr += o_cache_info.way_incr;
+	}
+
+	start_addr += o_cache_info.linesz;
+	cur_phys_addr += o_cache_info.linesz;
+    }
+
+#if 0
+    /* ICache */
+    /* The I-Cache is cleared for each write by the SHDEBUG layer. No
+       need to fiddle with it for now. */
+
+#define CCR		0xff00001c	/* Address of Cache Control Register */
+#define CCR_CACHE_OCE	0x0001	/* Operand Cache Enable */
+#define CCR_CACHE_WT	0x0002	/* Write-Through (for P0,U0,P3) (else writeback)*/
+#define CCR_CACHE_CB	0x0004	/* Copy-Back (for P1) (else writethrough) */
+#define CCR_CACHE_OCI	0x0008	/* OC Invalidate */
+#define CCR_CACHE_ORA	0x0020	/* OC RAM Mode */
+#define CCR_CACHE_OIX	0x0080	/* OC Index Enable */
+#define CCR_CACHE_ICE	0x0100	/* Instruction Cache Enable */
+#define CCR_CACHE_ICI	0x0800	/* IC Invalidate */
+#define CCR_CACHE_IIX	0x8000	/* IC Index Enable */
+#define CCR_CACHE_EMODE	0x80000000	/* EMODE Enable */
+
+    val = read_memory_unsigned_integer(CCR, 4);
+    val |= CCR_CACHE_ICI;
+    write_memory_unsigned_integer(CCR, 4, val);
+#endif
+}
+
+CORE_ADDR first_pointer_arg_value()
+{
+    return read_register(ARG0_REGNUM);
+}
+
+CORE_ADDR return_address_at_start_of_function()
+{
+    return read_register(PR_REGNUM);
+}
+
+static CORE_ADDR current_task_struct;
+static CORE_ADDR current_thread_info;
+
+void thread_clear_cache()
+{
+    current_task_struct = 0;
+    current_thread_info = 0;
+}
+
+static CORE_ADDR
+current_thread_info_address()
+{
+    if (! current_thread_info) {
+	if (has_started)
+	    current_thread_info = read_register(thread_info_regnum);
+	else
+	    current_thread_info = SH4_ADDR(INIT_THREAD_UNION);
+	DEBUG(VM, 3,"current_thread_info : %x\n", (unsigned int)current_thread_info);
+    }
+
+    return current_thread_info;
+}
+
+static CORE_ADDR
+current_task_struct_address()
+{
+    if (! current_task_struct) {
+	CORE_ADDR task_field_addr = current_thread_info_address();
+	task_field_addr += SH4_FIELD_OFFSET(THREAD_INFO__TASK);
+	current_task_struct = read_memory_unsigned_integer(task_field_addr,4);
+	DEBUG(VM, 3,"current_task_struct : %x\n", (unsigned int)current_task_struct);
+    }
+
+    return current_task_struct;
+}
+
+static int new_regcache;
+
+static CORE_ADDR  fetch_context_register_real(CORE_ADDR task_struct)
+{
+    gdb_byte *thread_info_buffer;
+    gdb_byte *stack_buffer;
+    gdb_byte *thread_struct_buffer;
+    struct cleanup *clean;
+    int offset = 0, val, i;
+    CORE_ADDR pc;
+
+    thread_struct_buffer = xmalloc(SH4_FIELD_SIZE(TASK_STRUCT__THREAD));
+    thread_info_buffer = xmalloc(SH4_FIELD_SIZE(TASK_STRUCT__THREAD_INFO));
+    stack_buffer = xmalloc(9*4);
+
+    clean = make_cleanup(xfree, thread_struct_buffer);
+    make_cleanup(xfree, thread_info_buffer);
+    make_cleanup(xfree, stack_buffer);
+
+    read_memory(task_struct+SH4_FIELD_OFFSET(TASK_STRUCT__THREAD),
+		thread_struct_buffer, SH4_FIELD_SIZE(TASK_STRUCT__THREAD));
+    read_memory(task_struct+SH4_FIELD_OFFSET(TASK_STRUCT__THREAD_INFO),
+		thread_info_buffer, SH4_FIELD_SIZE(TASK_STRUCT__THREAD_INFO));
+
+    /* We supply all registers at once since what's costly is the
+       number of memory accesses, not the size of the accesses. */
+
+    read_memory(extract_unsigned_integer(thread_struct_buffer+SH4_FIELD_OFFSET(THREAD_STRUCT__SP),4),
+		stack_buffer, 36);
+
+    new_regcache = 1;
+
+    /* The frame info for schedule doesn't take into account the SP
+       modifications in the switch_to macro (see asm/system.h). Thus
+       we need to point SP to its value after the macro has finished
+       to get correct backtracing. */
+    /* R15 - SP */
+    val = extract_unsigned_integer(thread_struct_buffer+SH4_FIELD_OFFSET(THREAD_STRUCT__SP), 4);
+    val += 9*4;
+    store_unsigned_integer(thread_struct_buffer+SH4_FIELD_OFFSET(THREAD_STRUCT__SP), 4, val);
+    regcache_raw_supply(current_regcache, R15, thread_struct_buffer+SH4_FIELD_OFFSET(THREAD_STRUCT__SP));
+    /* PC */
+    regcache_raw_supply(current_regcache, PC, thread_struct_buffer+SH4_FIELD_OFFSET(THREAD_STRUCT__PC));
+    pc = extract_typed_address (thread_struct_buffer+SH4_FIELD_OFFSET(THREAD_STRUCT__PC),
+				builtin_type_void_data_ptr);
+
+    regcache_raw_supply(current_regcache, R14, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, R13, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, R12, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, R11, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, R10, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, R9, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, R8, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, PR, stack_buffer+offset);
+    offset += 4;
+    regcache_raw_supply(current_regcache, GBR, stack_buffer+offset);
+    offset += 4;
+
+    /* R7B1 */
+    regcache_raw_supply(current_regcache, R7B1, thread_info_buffer);
+
+    for (i = 0; i < NUM_REGS; i++)
+	if (! register_cached (i))
+	    /* Mark other registers as unavailable.  */
+	    set_register_cached(i, -1);
+
+    do_cleanups(clean);
+
+    return pc;
+}
+
+static int doing_something_silly = 0;
+
+static int fetch_context_register(int regno, CORE_ADDR task_struct)
+{
+    struct frame_info *f;
+    CORE_ADDR pc;
+
+    DEBUG(TASK, 3,"fetch_context_register(%i,%x)\n",
+	  regno, (unsigned int)task_struct);
+
+    gdb_assert( ! doing_something_silly );
+
+    if (! regcache_valid_p(current_regcache, PC))
+	pc = fetch_context_register_real(task_struct);
+    else
+	pc = read_register (PC);
+
+    /* Don't skip the frames beginning in ret_from_fork. These frames
+       will be handled by the syscall unwinder. */
+    if (skip_schedule_frame && new_regcache
+	&& !(SH4_HAS_ADDR (RET_FROM_FORK) && pc == SH4_ADDR (RET_FROM_FORK))) {
+	new_regcache = 0;
+
+	doing_something_silly = 1;
+	f = get_current_frame();
+
+	if (f != NULL) {
+	    int i;
+	    gdb_byte buf[4];
+	    int optimized;
+	    CORE_ADDR addr;
+	    int realnum;
+	    enum lval_type lval;
+	    unsigned long *new_registers = xcalloc(NUM_REGS, sizeof(unsigned long));
+	    char *new_registers_valid = xcalloc(NUM_REGS, 1);
+
+	    for (i = 0; i<NUM_REGS; ++i) {
+		frame_register_unwind(f, i, &optimized, &lval, &addr,
+				      &realnum, buf);
+		if (!optimized) {
+		    memcpy(&new_registers[i], buf, 4);
+		    new_registers_valid[i] = 1;
+		}
+	    }
+
+	    regcache_raw_collect(current_regcache, R7B1, &new_registers[R7B1]);
+	    new_registers_valid[R7B1] = 1;
+
+	    registers_changed();
+	    flush_cached_frames();
+
+	    for (i = 0; i<NUM_REGS; ++i) {
+		if (new_registers_valid[i])
+		    regcache_raw_supply(current_regcache, i,&new_registers[i]);
+		else
+		    /* Mark other registers as unavailable. */
+		    set_register_cached(i, -1);
+	    }
+
+	    xfree(new_registers);
+	    xfree(new_registers_valid);
+	}
+
+	doing_something_silly = 0;
+    }
+
+    return 1;
+}
+
+
+
+static int store_context_register_real(int regno, CORE_ADDR task_struct)
+{
+    gdb_byte buf[4];
+    int offset = 0;
+
+    /* A new fork has pt_regs on the stack from a fork() call (?????) */
+    /* if (p->thread.pc == (unsigned long)ret_from_fork) { */
+    /* 	kregs = (struct pt_regs*)p->thread.sp; */
+    /* 	for (count = 0; count < 16; count++) */
+    /* 	    *(gdb_regs++) = kregs->regs[count]; */
+
+    /* 	*(gdb_regs++) = kregs->pc; */
+    /* 	*(gdb_regs++) = kregs->pr; */
+    /* 	*(gdb_regs++) = kregs->gbr; */
+    /* 	*(gdb_regs++) = vbr_val; */
+    /* 	*(gdb_regs++) = kregs->mach; */
+    /* 	*(gdb_regs++) = kregs->macl; */
+    /* 	*(gdb_regs++) = kregs->sr; */
+    /* 	return; */
+    /*     } */
+
+    /*
+     * Otherwise we have to collect the thread registers from the stack
+     * built by switch function (see include/asm-sh/system.h)
+     */
+
+    if (skip_schedule_frame)
+	return 0;
+
+    switch (regno) {
+    case GBR:
+	offset -= 4;
+    case PR:
+	offset -= 4;
+    case R8:
+	offset -= 4;
+    case R9:
+	offset -= 4;
+    case R10:
+	offset -= 4;
+    case R11:
+	offset -= 4;
+    case R12:
+	offset -= 4;
+    case R13:
+	offset -= 4;
+    case R14:
+	offset += read_memory_unsigned_integer(task_struct+SH4_FIELD_OFFSET(TASK_STRUCT__THREAD)+SH4_FIELD_OFFSET(THREAD_STRUCT__SP), 4);
+	break;
+    default:
+	return 0;
+    }
+
+    regcache_raw_collect(current_regcache, regno, buf);
+    target_write_memory(offset, buf, 4);
+    return 1;
+}
+
+static int store_context_register(int regno, CORE_ADDR task_struct)
+{
+    DEBUG(TASK, 3,"fetch_context_register(%i,%x)\n",
+	  regno, (unsigned int)task_struct);
+
+    if (regno == -1) {
+	for (regno = R8; regno <= GBR; ++regno)
+	    store_context_register_real(regno, task_struct);
+    }
+
+    if (regno < R8 || regno > GBR)
+	return 0;
+
+    return store_context_register_real(regno, task_struct);
+}
+
+
+/* Macros for single step instruction identification */
+#define OPCODE_BT(op)         (((op) & 0xff00) == 0x8900)
+#define OPCODE_BF(op)         (((op) & 0xff00) == 0x8b00)
+#define OPCODE_BTF_DISP(op)   (((op) & 0x80) ? (((op) | 0xffffff80) << 1) : \
+			      (((op) & 0x7f ) << 1))
+#define OPCODE_BFS(op)        (((op) & 0xff00) == 0x8f00)
+#define OPCODE_BTS(op)        (((op) & 0xff00) == 0x8d00)
+#define OPCODE_BRA(op)        (((op) & 0xf000) == 0xa000)
+#define OPCODE_BRA_DISP(op)   (((op) & 0x800) ? (((op) | 0xfffff800) << 1) : \
+			      (((op) & 0x7ff) << 1))
+#define OPCODE_BRAF(op)       (((op) & 0xf0ff) == 0x0023)
+#define OPCODE_BRAF_REG(op)   (((op) & 0x0f00) >> 8)
+#define OPCODE_BSR(op)        (((op) & 0xf000) == 0xb000)
+#define OPCODE_BSR_DISP(op)   (((op) & 0x800) ? (((op) | 0xfffff800) << 1) : \
+			      (((op) & 0x7ff) << 1))
+#define OPCODE_BSRF(op)       (((op) & 0xf0ff) == 0x0003)
+#define OPCODE_BSRF_REG(op)   (((op) >> 8) & 0xf)
+#define OPCODE_JMP(op)        (((op) & 0xf0ff) == 0x402b)
+#define OPCODE_JMP_REG(op)    (((op) >> 8) & 0xf)
+#define OPCODE_JSR(op)        (((op) & 0xf0ff) == 0x400b)
+#define OPCODE_JSR_REG(op)    (((op) >> 8) & 0xf)
+#define OPCODE_RTS(op)        ((op) == 0xb)
+#define OPCODE_RTE(op)        ((op) == 0x2b)
+
+#define SR_T_BIT_MASK           0x1
+
+
+static CORE_ADDR sh4_linux_single_step_destination(CORE_ADDR pc)
+{
+    short op = read_memory_unsigned_integer(pc, 2);
+
+    CORE_ADDR addr;
+
+    /* BT */
+    if (OPCODE_BT(op)) {
+	if (read_register(SR) & SR_T_BIT_MASK)
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 2;
+    }
+
+    /* BTS */
+    else if (OPCODE_BTS(op)) {
+	if (read_register(SR) & SR_T_BIT_MASK)
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 4;	/* Not in delay slot */
+    }
+
+    /* BF */
+    else if (OPCODE_BF(op)) {
+	if (!(read_register(SR) & SR_T_BIT_MASK))
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 2;
+    }
+
+    /* BFS */
+    else if (OPCODE_BFS(op)) {
+	if (!(read_register(SR) & SR_T_BIT_MASK))
+	    addr = pc + 4 + OPCODE_BTF_DISP(op);
+	else
+	    addr = pc + 4;	/* Not in delay slot */
+    }
+
+    /* BRA */
+    else if (OPCODE_BRA(op))
+	addr = pc + 4 + OPCODE_BRA_DISP(op);
+
+    /* BRAF */
+    else if (OPCODE_BRAF(op))
+	addr = pc + 4 + read_register(OPCODE_BRAF_REG(op));
+
+    /* BSR */
+    else if (OPCODE_BSR(op))
+	addr = pc + 4 + OPCODE_BSR_DISP(op);
+
+    /* BSRF */
+    else if (OPCODE_BSRF(op))
+	addr = pc + 4 + read_register(OPCODE_BSRF_REG(op));
+
+    /* JMP */
+    else if (OPCODE_JMP(op))
+	addr = read_register(OPCODE_JMP_REG(op));
+
+    /* JSR */
+    else if (OPCODE_JSR(op))
+	addr = read_register(OPCODE_JSR_REG(op));
+
+    /* RTS */
+    else if (OPCODE_RTS(op))
+	addr = read_register(PR);
+
+    /* RTE */
+    else if (OPCODE_RTE(op))
+	addr = read_register(R15);
+
+    /* Other */
+    else
+	addr = pc + 2;
+
+    return addr & 0xFFFFFFFF;
+}
+
+static void sh4_linux_clear_cache()
+{
+    thread_clear_cache();
+    translate_memory_address_clear_cache();
+    has_started = 1;
+}
+
+static void
+sh4_linux_awareness_close()
+{
+    sh4_linux_clear_cache();
+    linux_free_fields(sh4_linux_fields);
+    linux_free_addresses(sh4_linux_addrs);
+    cache_layout_known = 0;
+    has_started = 0;
+}
+
+struct linux_awareness_ops sh4_linux_awareness_ops = {
+    .name = "SH4",
+    .lo_check = sh4_linux_awareness_check,
+    .lo_init = sh4_linux_awareness_init,
+    .lo_close = sh4_linux_awareness_close,
+    .lo_address_needs_translation = linux_sh4_address_needs_translation,
+    .lo_translate_memory_address = translate_memory_address,
+    .lo_translate_memory_watch_address = translate_memory_watch_address,
+    .lo_can_write = sh4_linux_can_write,
+    .lo_is_user_address = sh4_linux_is_user_address,
+    .lo_is_kernel_address = sh4_linux_is_kernel_address,
+    .lo_flush_cache = linux_sh4_flush_cache_for_region,
+    .lo_single_step_destination = sh4_linux_single_step_destination,
+    .lo_clear_cache = sh4_linux_clear_cache,
+    .lo_first_pointer_arg_value = first_pointer_arg_value,
+    .lo_return_address_at_start_of_function = return_address_at_start_of_function,
+    .lo_current_task_struct_address = current_task_struct_address,
+    .lo_current_thread_info_address = current_thread_info_address,
+    .lo_fetch_context_register = fetch_context_register,
+    .lo_store_context_register = store_context_register,
+    .page_shift = 12 /* Page shift */
+};
+
+void
+_initialize_linux_awareness_sh4 (void)
+{
+    linux_awareness_ops = &sh4_linux_awareness_ops;
+}
Index: gdb-6.5/gdb/Makefile.in
===================================================================
--- gdb-6.5.orig/gdb/Makefile.in	2007-10-24 16:22:01.000000000 +0100
+++ gdb-6.5/gdb/Makefile.in	2007-10-24 16:22:45.000000000 +0100
@@ -737,6 +737,7 @@
 language_h = language.h
 libunwind_frame_h = libunwind-frame.h $(libunwind_h)
 linespec_h = linespec.h
+linux_awareness_h = linux-awareness.h observer.h
 linux_fork_h = linux-fork.h
 linux_nat_h = linux-nat.h $(target_h)
 m2_lang_h = m2-lang.h
@@ -2193,6 +2194,8 @@
 language.o: language.c $(defs_h) $(gdb_string_h) $(symtab_h) $(gdbtypes_h) \
 	$(value_h) $(gdbcmd_h) $(expression_h) $(language_h) $(target_h) \
 	$(parser_defs_h) $(jv_lang_h) $(demangle_h)
+linux-awareness.o : $(linux_awareness_h)
+linux-awareness-sh4.o : $(linux_awareness_h)
 libunwind-frame.o: libunwind-frame.c $(defs_h) $(inferior_h) $(frame_h) \
 	$(frame_base_h) $(frame_unwind_h) $(gdbcore_h) $(gdbtypes_h) \
 	$(symtab_h) $(objfiles_h) $(regcache_h) $(gdb_assert_h) \
Index: gdb-6.5/gdb/target.c
===================================================================
--- gdb-6.5.orig/gdb/target.c	2007-10-24 16:22:01.000000000 +0100
+++ gdb-6.5/gdb/target.c	2007-10-24 16:22:45.000000000 +0100
@@ -2191,10 +2191,10 @@
 {
   int retval;
 
-  retval = debug_target.to_insert_watchpoint (addr, len, type);
+  retval = debug_target.to_remove_watchpoint (addr, len, type);
 
   fprintf_unfiltered (gdb_stdlog,
-		      "target_insert_watchpoint (0x%lx, %d, %d) = %ld\n",
+		      "target_remove_watchpoint (0x%lx, %d, %d) = %ld\n",
 		      (unsigned long) addr, len, type, (unsigned long) retval);
   return retval;
 }
